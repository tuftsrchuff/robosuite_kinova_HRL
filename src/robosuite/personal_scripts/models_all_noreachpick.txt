What policy would you like to train?
	1. Reach-pick
	2. Pick
	3. Drop
	4. Reach-drop
	5. All
Training for 1000000 steps
Training all
Training Pick
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to ./logs/SAC_30
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 4        |
|    fps             | 75       |
|    time_elapsed    | 26       |
|    total_timesteps | 2000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 8        |
|    fps             | 84       |
|    time_elapsed    | 47       |
|    total_timesteps | 4000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 12       |
|    fps             | 87       |
|    time_elapsed    | 68       |
|    total_timesteps | 6000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 16       |
|    fps             | 87       |
|    time_elapsed    | 91       |
|    total_timesteps | 8000     |
---------------------------------
{'grasped(cube3)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 89       |
|    time_elapsed    | 109      |
|    total_timesteps | 9786     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.0833   |
| time/              |          |
|    episodes        | 24       |
|    fps             | 60       |
|    time_elapsed    | 189      |
|    total_timesteps | 11412    |
| train/             |          |
|    actor_loss      | -15.9    |
|    critic_loss     | 0.0401   |
|    ent_coef        | 0.655    |
|    ent_coef_loss   | -2.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 1411     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0714   |
| time/              |          |
|    episodes        | 28       |
|    fps             | 60       |
|    time_elapsed    | 221      |
|    total_timesteps | 13412    |
| train/             |          |
|    actor_loss      | -24.8    |
|    critic_loss     | 0.101    |
|    ent_coef        | 0.36     |
|    ent_coef_loss   | -6.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 3411     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 60       |
|    time_elapsed    | 253      |
|    total_timesteps | 15412    |
| train/             |          |
|    actor_loss      | -27.4    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.198    |
|    ent_coef_loss   | -10.6    |
|    learning_rate   | 0.0003   |
|    n_updates       | 5411     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.0556   |
| time/              |          |
|    episodes        | 36       |
|    fps             | 60       |
|    time_elapsed    | 288      |
|    total_timesteps | 17412    |
| train/             |          |
|    actor_loss      | -27.6    |
|    critic_loss     | 2.86     |
|    ent_coef        | 0.11     |
|    ent_coef_loss   | -13.4    |
|    learning_rate   | 0.0003   |
|    n_updates       | 7411     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 60       |
|    time_elapsed    | 319      |
|    total_timesteps | 19412    |
| train/             |          |
|    actor_loss      | -26.6    |
|    critic_loss     | 0.187    |
|    ent_coef        | 0.0625   |
|    ent_coef_loss   | -15      |
|    learning_rate   | 0.0003   |
|    n_updates       | 9411     |
---------------------------------
Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -26      |
|    critic_loss     | 0.201    |
|    ent_coef        | 0.0531   |
|    ent_coef_loss   | -14.8    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.0455   |
| time/              |          |
|    episodes        | 44       |
|    fps             | 52       |
|    time_elapsed    | 404      |
|    total_timesteps | 21412    |
| train/             |          |
|    actor_loss      | -25.1    |
|    critic_loss     | 2.04     |
|    ent_coef        | 0.0364   |
|    ent_coef_loss   | -12.3    |
|    learning_rate   | 0.0003   |
|    n_updates       | 11411    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.0417   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 53       |
|    time_elapsed    | 437      |
|    total_timesteps | 23412    |
| train/             |          |
|    actor_loss      | -24      |
|    critic_loss     | 3.89     |
|    ent_coef        | 0.0227   |
|    ent_coef_loss   | -6.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 13411    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.0385   |
| time/              |          |
|    episodes        | 52       |
|    fps             | 53       |
|    time_elapsed    | 470      |
|    total_timesteps | 25412    |
| train/             |          |
|    actor_loss      | -23.1    |
|    critic_loss     | 0.12     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -4.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 15411    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.0357   |
| time/              |          |
|    episodes        | 56       |
|    fps             | 54       |
|    time_elapsed    | 503      |
|    total_timesteps | 27412    |
| train/             |          |
|    actor_loss      | -22.1    |
|    critic_loss     | 0.103    |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -5.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 17411    |
---------------------------------
{'grasped(cube2)': True}
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.0667   |
| time/              |          |
|    episodes        | 60       |
|    fps             | 54       |
|    time_elapsed    | 524      |
|    total_timesteps | 28608    |
| train/             |          |
|    actor_loss      | -21.6    |
|    critic_loss     | 0.122    |
|    ent_coef        | 0.00993  |
|    ent_coef_loss   | -0.00291 |
|    learning_rate   | 0.0003   |
|    n_updates       | 18607    |
---------------------------------
{'grasped(cube2)': True}
Eval num_timesteps=30000, episode_reward=0.10 +/- 0.30
Episode length: 455.00 +/- 135.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -20.6    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.00869  |
|    ent_coef_loss   | -0.365   |
|    learning_rate   | 0.0003   |
|    n_updates       | 19999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 64       |
|    fps             | 49       |
|    time_elapsed    | 613      |
|    total_timesteps | 30608    |
| train/             |          |
|    actor_loss      | -20.2    |
|    critic_loss     | 0.1      |
|    ent_coef        | 0.00825  |
|    ent_coef_loss   | -0.386   |
|    learning_rate   | 0.0003   |
|    n_updates       | 20607    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.0588   |
| time/              |          |
|    episodes        | 68       |
|    fps             | 50       |
|    time_elapsed    | 645      |
|    total_timesteps | 32608    |
| train/             |          |
|    actor_loss      | -19.2    |
|    critic_loss     | 0.0967   |
|    ent_coef        | 0.00786  |
|    ent_coef_loss   | -1.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 22607    |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0694   |
| time/              |          |
|    episodes        | 72       |
|    fps             | 51       |
|    time_elapsed    | 676      |
|    total_timesteps | 34489    |
| train/             |          |
|    actor_loss      | -18.1    |
|    critic_loss     | 0.085    |
|    ent_coef        | 0.00729  |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 24488    |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.0789   |
| time/              |          |
|    episodes        | 76       |
|    fps             | 51       |
|    time_elapsed    | 707      |
|    total_timesteps | 36169    |
| train/             |          |
|    actor_loss      | -16.9    |
|    critic_loss     | 0.0739   |
|    ent_coef        | 0.00655  |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 26168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.075    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 51       |
|    time_elapsed    | 739      |
|    total_timesteps | 38169    |
| train/             |          |
|    actor_loss      | -15.8    |
|    critic_loss     | 0.0582   |
|    ent_coef        | 0.00653  |
|    ent_coef_loss   | -0.799   |
|    learning_rate   | 0.0003   |
|    n_updates       | 28168    |
---------------------------------
Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -15      |
|    critic_loss     | 0.234    |
|    ent_coef        | 0.00603  |
|    ent_coef_loss   | -4.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.0714   |
| time/              |          |
|    episodes        | 84       |
|    fps             | 48       |
|    time_elapsed    | 825      |
|    total_timesteps | 40169    |
| train/             |          |
|    actor_loss      | -15.1    |
|    critic_loss     | 0.0591   |
|    ent_coef        | 0.00586  |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 30168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0682   |
| time/              |          |
|    episodes        | 88       |
|    fps             | 49       |
|    time_elapsed    | 859      |
|    total_timesteps | 42169    |
| train/             |          |
|    actor_loss      | -14.1    |
|    critic_loss     | 0.0347   |
|    ent_coef        | 0.00485  |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 0.0003   |
|    n_updates       | 32168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.0652   |
| time/              |          |
|    episodes        | 92       |
|    fps             | 49       |
|    time_elapsed    | 894      |
|    total_timesteps | 44169    |
| train/             |          |
|    actor_loss      | -12.9    |
|    critic_loss     | 0.0541   |
|    ent_coef        | 0.00429  |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 34168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 96       |
|    fps             | 49       |
|    time_elapsed    | 926      |
|    total_timesteps | 46169    |
| train/             |          |
|    actor_loss      | -12.2    |
|    critic_loss     | 0.026    |
|    ent_coef        | 0.00449  |
|    ent_coef_loss   | -0.391   |
|    learning_rate   | 0.0003   |
|    n_updates       | 36168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 50       |
|    time_elapsed    | 958      |
|    total_timesteps | 48169    |
| train/             |          |
|    actor_loss      | -11.5    |
|    critic_loss     | 0.0182   |
|    ent_coef        | 0.00415  |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 38168    |
---------------------------------
Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -10.8    |
|    critic_loss     | 0.0871   |
|    ent_coef        | 0.00357  |
|    ent_coef_loss   | 0.467    |
|    learning_rate   | 0.0003   |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 47       |
|    time_elapsed    | 1049     |
|    total_timesteps | 50169    |
| train/             |          |
|    actor_loss      | -10.8    |
|    critic_loss     | 0.151    |
|    ent_coef        | 0.00357  |
|    ent_coef_loss   | 0.122    |
|    learning_rate   | 0.0003   |
|    n_updates       | 40168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 48       |
|    time_elapsed    | 1082     |
|    total_timesteps | 52169    |
| train/             |          |
|    actor_loss      | -9.97    |
|    critic_loss     | 0.0231   |
|    ent_coef        | 0.00326  |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 42168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 48       |
|    time_elapsed    | 1116     |
|    total_timesteps | 54169    |
| train/             |          |
|    actor_loss      | -9.37    |
|    critic_loss     | 0.013    |
|    ent_coef        | 0.00299  |
|    ent_coef_loss   | 0.978    |
|    learning_rate   | 0.0003   |
|    n_updates       | 44168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 48       |
|    time_elapsed    | 1149     |
|    total_timesteps | 56169    |
| train/             |          |
|    actor_loss      | -8.53    |
|    critic_loss     | 0.03     |
|    ent_coef        | 0.0028   |
|    ent_coef_loss   | 0.434    |
|    learning_rate   | 0.0003   |
|    n_updates       | 46168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 49       |
|    time_elapsed    | 1180     |
|    total_timesteps | 58169    |
| train/             |          |
|    actor_loss      | -7.93    |
|    critic_loss     | 0.0127   |
|    ent_coef        | 0.00244  |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 48168    |
---------------------------------
Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -7.45    |
|    critic_loss     | 0.00881  |
|    ent_coef        | 0.00217  |
|    ent_coef_loss   | -0.665   |
|    learning_rate   | 0.0003   |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 47       |
|    time_elapsed    | 1275     |
|    total_timesteps | 60169    |
| train/             |          |
|    actor_loss      | -7.3     |
|    critic_loss     | 0.00925  |
|    ent_coef        | 0.00214  |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 50168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 47       |
|    time_elapsed    | 1307     |
|    total_timesteps | 62169    |
| train/             |          |
|    actor_loss      | -6.9     |
|    critic_loss     | 0.0066   |
|    ent_coef        | 0.00188  |
|    ent_coef_loss   | 1.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 52168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 47       |
|    time_elapsed    | 1345     |
|    total_timesteps | 64169    |
| train/             |          |
|    actor_loss      | -6.32    |
|    critic_loss     | 0.00632  |
|    ent_coef        | 0.00185  |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 54168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 48       |
|    time_elapsed    | 1376     |
|    total_timesteps | 66169    |
| train/             |          |
|    actor_loss      | -5.77    |
|    critic_loss     | 0.0439   |
|    ent_coef        | 0.0016   |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 56168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 48       |
|    time_elapsed    | 1410     |
|    total_timesteps | 68169    |
| train/             |          |
|    actor_loss      | -5.41    |
|    critic_loss     | 0.0139   |
|    ent_coef        | 0.00156  |
|    ent_coef_loss   | 0.227    |
|    learning_rate   | 0.0003   |
|    n_updates       | 58168    |
---------------------------------
Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -4.86    |
|    critic_loss     | 0.0653   |
|    ent_coef        | 0.00145  |
|    ent_coef_loss   | 0.848    |
|    learning_rate   | 0.0003   |
|    n_updates       | 59999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 46       |
|    time_elapsed    | 1501     |
|    total_timesteps | 70169    |
| train/             |          |
|    actor_loss      | -5.04    |
|    critic_loss     | 0.0298   |
|    ent_coef        | 0.00142  |
|    ent_coef_loss   | -0.317   |
|    learning_rate   | 0.0003   |
|    n_updates       | 60168    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 47       |
|    time_elapsed    | 1532     |
|    total_timesteps | 72169    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.0111   |
|    ent_coef        | 0.00129  |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 0.0003   |
|    n_updates       | 62168    |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 47       |
|    time_elapsed    | 1559     |
|    total_timesteps | 73937    |
| train/             |          |
|    actor_loss      | -4.26    |
|    critic_loss     | 0.00279  |
|    ent_coef        | 0.00115  |
|    ent_coef_loss   | 0.239    |
|    learning_rate   | 0.0003   |
|    n_updates       | 63936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 47       |
|    time_elapsed    | 1591     |
|    total_timesteps | 75937    |
| train/             |          |
|    actor_loss      | -3.86    |
|    critic_loss     | 0.006    |
|    ent_coef        | 0.000966 |
|    ent_coef_loss   | -3.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 65936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 48       |
|    time_elapsed    | 1623     |
|    total_timesteps | 77937    |
| train/             |          |
|    actor_loss      | -3.47    |
|    critic_loss     | 0.0391   |
|    ent_coef        | 0.000935 |
|    ent_coef_loss   | -0.184   |
|    learning_rate   | 0.0003   |
|    n_updates       | 67936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 48       |
|    time_elapsed    | 1656     |
|    total_timesteps | 79937    |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 0.0014   |
|    ent_coef        | 0.000859 |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 69936    |
---------------------------------
Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 0.0646   |
|    ent_coef        | 0.000844 |
|    ent_coef_loss   | -0.94    |
|    learning_rate   | 0.0003   |
|    n_updates       | 69999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 46       |
|    time_elapsed    | 1747     |
|    total_timesteps | 81937    |
| train/             |          |
|    actor_loss      | -2.93    |
|    critic_loss     | 0.002    |
|    ent_coef        | 0.000814 |
|    ent_coef_loss   | -0.346   |
|    learning_rate   | 0.0003   |
|    n_updates       | 71936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 47       |
|    time_elapsed    | 1779     |
|    total_timesteps | 83937    |
| train/             |          |
|    actor_loss      | -2.66    |
|    critic_loss     | 0.00142  |
|    ent_coef        | 0.00068  |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 73936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 47       |
|    time_elapsed    | 1812     |
|    total_timesteps | 85937    |
| train/             |          |
|    actor_loss      | -2.47    |
|    critic_loss     | 0.000722 |
|    ent_coef        | 0.000541 |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 75936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 47       |
|    time_elapsed    | 1842     |
|    total_timesteps | 87937    |
| train/             |          |
|    actor_loss      | -2.27    |
|    critic_loss     | 0.0007   |
|    ent_coef        | 0.000528 |
|    ent_coef_loss   | -3       |
|    learning_rate   | 0.0003   |
|    n_updates       | 77936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 47       |
|    time_elapsed    | 1876     |
|    total_timesteps | 89937    |
| train/             |          |
|    actor_loss      | -2.02    |
|    critic_loss     | 0.000672 |
|    ent_coef        | 0.000455 |
|    ent_coef_loss   | -3.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 79936    |
---------------------------------
Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -2.01    |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.000446 |
|    ent_coef_loss   | -2.49    |
|    learning_rate   | 0.0003   |
|    n_updates       | 79999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 46       |
|    time_elapsed    | 1962     |
|    total_timesteps | 91937    |
| train/             |          |
|    actor_loss      | -1.84    |
|    critic_loss     | 0.000604 |
|    ent_coef        | 0.000428 |
|    ent_coef_loss   | 7.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 81936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 47       |
|    time_elapsed    | 1998     |
|    total_timesteps | 93937    |
| train/             |          |
|    actor_loss      | -1.69    |
|    critic_loss     | 0.000484 |
|    ent_coef        | 0.000352 |
|    ent_coef_loss   | 0.777    |
|    learning_rate   | 0.0003   |
|    n_updates       | 83936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 47       |
|    time_elapsed    | 2030     |
|    total_timesteps | 95937    |
| train/             |          |
|    actor_loss      | -1.5     |
|    critic_loss     | 0.000314 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 85936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 47       |
|    time_elapsed    | 2062     |
|    total_timesteps | 97937    |
| train/             |          |
|    actor_loss      | -1.38    |
|    critic_loss     | 0.0103   |
|    ent_coef        | 0.000219 |
|    ent_coef_loss   | 0.718    |
|    learning_rate   | 0.0003   |
|    n_updates       | 87936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 47       |
|    time_elapsed    | 2094     |
|    total_timesteps | 99937    |
| train/             |          |
|    actor_loss      | -1.26    |
|    critic_loss     | 0.00122  |
|    ent_coef        | 0.000199 |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 89936    |
---------------------------------
Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -1.25    |
|    critic_loss     | 0.000247 |
|    ent_coef        | 0.000198 |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 89999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 46       |
|    time_elapsed    | 2183     |
|    total_timesteps | 101937   |
| train/             |          |
|    actor_loss      | -1.11    |
|    critic_loss     | 0.0103   |
|    ent_coef        | 0.000168 |
|    ent_coef_loss   | -4.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 91936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 46       |
|    time_elapsed    | 2220     |
|    total_timesteps | 103937   |
| train/             |          |
|    actor_loss      | -1.01    |
|    critic_loss     | 0.00027  |
|    ent_coef        | 0.000164 |
|    ent_coef_loss   | 0.131    |
|    learning_rate   | 0.0003   |
|    n_updates       | 93936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 46       |
|    time_elapsed    | 2255     |
|    total_timesteps | 105937   |
| train/             |          |
|    actor_loss      | -0.943   |
|    critic_loss     | 0.000336 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | -4.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 95936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 47       |
|    time_elapsed    | 2289     |
|    total_timesteps | 107937   |
| train/             |          |
|    actor_loss      | -0.827   |
|    critic_loss     | 0.00269  |
|    ent_coef        | 0.000139 |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 97936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 47       |
|    time_elapsed    | 2324     |
|    total_timesteps | 109937   |
| train/             |          |
|    actor_loss      | -0.754   |
|    critic_loss     | 0.000187 |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 99936    |
---------------------------------
Eval num_timesteps=110000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -0.767   |
|    critic_loss     | 0.000366 |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | -1.88    |
|    learning_rate   | 0.0003   |
|    n_updates       | 99999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 46       |
|    time_elapsed    | 2415     |
|    total_timesteps | 111937   |
| train/             |          |
|    actor_loss      | -0.688   |
|    critic_loss     | 0.000215 |
|    ent_coef        | 0.000148 |
|    ent_coef_loss   | 0.555    |
|    learning_rate   | 0.0003   |
|    n_updates       | 101936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 46       |
|    time_elapsed    | 2450     |
|    total_timesteps | 113937   |
| train/             |          |
|    actor_loss      | -0.628   |
|    critic_loss     | 0.000119 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -5.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 103936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 46       |
|    time_elapsed    | 2485     |
|    total_timesteps | 115937   |
| train/             |          |
|    actor_loss      | -0.562   |
|    critic_loss     | 0.00105  |
|    ent_coef        | 9.68e-05 |
|    ent_coef_loss   | 5.84     |
|    learning_rate   | 0.0003   |
|    n_updates       | 105936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 46       |
|    time_elapsed    | 2521     |
|    total_timesteps | 117937   |
| train/             |          |
|    actor_loss      | -0.517   |
|    critic_loss     | 0.000546 |
|    ent_coef        | 8.82e-05 |
|    ent_coef_loss   | -0.639   |
|    learning_rate   | 0.0003   |
|    n_updates       | 107936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 46       |
|    time_elapsed    | 2557     |
|    total_timesteps | 119937   |
| train/             |          |
|    actor_loss      | -0.471   |
|    critic_loss     | 0.0014   |
|    ent_coef        | 7.14e-05 |
|    ent_coef_loss   | -0.882   |
|    learning_rate   | 0.0003   |
|    n_updates       | 109936   |
---------------------------------
Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -0.463   |
|    critic_loss     | 0.000115 |
|    ent_coef        | 7.15e-05 |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 109999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 45       |
|    time_elapsed    | 2655     |
|    total_timesteps | 121937   |
| train/             |          |
|    actor_loss      | -0.423   |
|    critic_loss     | 0.000302 |
|    ent_coef        | 7.57e-05 |
|    ent_coef_loss   | -0.213   |
|    learning_rate   | 0.0003   |
|    n_updates       | 111936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 252      |
|    fps             | 46       |
|    time_elapsed    | 2690     |
|    total_timesteps | 123937   |
| train/             |          |
|    actor_loss      | -0.385   |
|    critic_loss     | 0.000316 |
|    ent_coef        | 7.18e-05 |
|    ent_coef_loss   | -3.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 113936   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 256      |
|    fps             | 46       |
|    time_elapsed    | 2718     |
|    total_timesteps | 125513   |
| train/             |          |
|    actor_loss      | -0.346   |
|    critic_loss     | 0.000119 |
|    ent_coef        | 6.83e-05 |
|    ent_coef_loss   | 0.00686  |
|    learning_rate   | 0.0003   |
|    n_updates       | 115512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 260      |
|    fps             | 46       |
|    time_elapsed    | 2750     |
|    total_timesteps | 127513   |
| train/             |          |
|    actor_loss      | -0.315   |
|    critic_loss     | 0.000138 |
|    ent_coef        | 6.32e-05 |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 117512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 264      |
|    fps             | 46       |
|    time_elapsed    | 2785     |
|    total_timesteps | 129513   |
| train/             |          |
|    actor_loss      | -0.3     |
|    critic_loss     | 0.000643 |
|    ent_coef        | 9.71e-05 |
|    ent_coef_loss   | 0.325    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119512   |
---------------------------------
Eval num_timesteps=130000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -0.285   |
|    critic_loss     | 0.000165 |
|    ent_coef        | 8.55e-05 |
|    ent_coef_loss   | -6.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 268      |
|    fps             | 45       |
|    time_elapsed    | 2877     |
|    total_timesteps | 131513   |
| train/             |          |
|    actor_loss      | -0.271   |
|    critic_loss     | 3.71e-05 |
|    ent_coef        | 7.65e-05 |
|    ent_coef_loss   | -0.792   |
|    learning_rate   | 0.0003   |
|    n_updates       | 121512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 272      |
|    fps             | 45       |
|    time_elapsed    | 2912     |
|    total_timesteps | 133513   |
| train/             |          |
|    actor_loss      | -0.276   |
|    critic_loss     | 4.16e-05 |
|    ent_coef        | 8.06e-05 |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 123512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 276      |
|    fps             | 45       |
|    time_elapsed    | 2946     |
|    total_timesteps | 135513   |
| train/             |          |
|    actor_loss      | -0.237   |
|    critic_loss     | 0.000124 |
|    ent_coef        | 9.6e-05  |
|    ent_coef_loss   | -0.134   |
|    learning_rate   | 0.0003   |
|    n_updates       | 125512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 46       |
|    time_elapsed    | 2980     |
|    total_timesteps | 137513   |
| train/             |          |
|    actor_loss      | -0.243   |
|    critic_loss     | 4.28e-05 |
|    ent_coef        | 9.5e-05  |
|    ent_coef_loss   | -0.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 127512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 46       |
|    time_elapsed    | 3014     |
|    total_timesteps | 139513   |
| train/             |          |
|    actor_loss      | -0.235   |
|    critic_loss     | 0.000473 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 129512   |
---------------------------------
Eval num_timesteps=140000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -0.226   |
|    critic_loss     | 3.65e-05 |
|    ent_coef        | 0.000121 |
|    ent_coef_loss   | -4.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 129999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 45       |
|    time_elapsed    | 3106     |
|    total_timesteps | 141513   |
| train/             |          |
|    actor_loss      | -0.232   |
|    critic_loss     | 3.18e-05 |
|    ent_coef        | 0.000118 |
|    ent_coef_loss   | 3.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 131512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 45       |
|    time_elapsed    | 3139     |
|    total_timesteps | 143513   |
| train/             |          |
|    actor_loss      | -0.207   |
|    critic_loss     | 3.66e-05 |
|    ent_coef        | 0.000103 |
|    ent_coef_loss   | 0.294    |
|    learning_rate   | 0.0003   |
|    n_updates       | 133512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 45       |
|    time_elapsed    | 3174     |
|    total_timesteps | 145513   |
| train/             |          |
|    actor_loss      | -0.212   |
|    critic_loss     | 5.4e-05  |
|    ent_coef        | 9.83e-05 |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 135512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 45       |
|    time_elapsed    | 3207     |
|    total_timesteps | 147513   |
| train/             |          |
|    actor_loss      | -0.182   |
|    critic_loss     | 8.86e-05 |
|    ent_coef        | 0.000109 |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 137512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 46       |
|    time_elapsed    | 3244     |
|    total_timesteps | 149513   |
| train/             |          |
|    actor_loss      | -0.196   |
|    critic_loss     | 2.87e-05 |
|    ent_coef        | 0.000105 |
|    ent_coef_loss   | 4.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 139512   |
---------------------------------
Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -0.186   |
|    critic_loss     | 0.000131 |
|    ent_coef        | 0.000104 |
|    ent_coef_loss   | 0.709    |
|    learning_rate   | 0.0003   |
|    n_updates       | 139999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 45       |
|    time_elapsed    | 3332     |
|    total_timesteps | 151513   |
| train/             |          |
|    actor_loss      | -0.188   |
|    critic_loss     | 7.69e-05 |
|    ent_coef        | 0.000118 |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 141512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 45       |
|    time_elapsed    | 3365     |
|    total_timesteps | 153513   |
| train/             |          |
|    actor_loss      | -0.169   |
|    critic_loss     | 0.000604 |
|    ent_coef        | 0.000116 |
|    ent_coef_loss   | 0.232    |
|    learning_rate   | 0.0003   |
|    n_updates       | 143512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 45       |
|    time_elapsed    | 3398     |
|    total_timesteps | 155513   |
| train/             |          |
|    actor_loss      | -0.18    |
|    critic_loss     | 5.66e-05 |
|    ent_coef        | 0.000118 |
|    ent_coef_loss   | 2.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 145512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 320      |
|    fps             | 45       |
|    time_elapsed    | 3432     |
|    total_timesteps | 157513   |
| train/             |          |
|    actor_loss      | -0.174   |
|    critic_loss     | 7.64e-05 |
|    ent_coef        | 0.000112 |
|    ent_coef_loss   | -2.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 147512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 46       |
|    time_elapsed    | 3466     |
|    total_timesteps | 159513   |
| train/             |          |
|    actor_loss      | -0.183   |
|    critic_loss     | 3.69e-05 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -5.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 149512   |
---------------------------------
Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -0.18    |
|    critic_loss     | 5.91e-05 |
|    ent_coef        | 0.000115 |
|    ent_coef_loss   | 0.759    |
|    learning_rate   | 0.0003   |
|    n_updates       | 149999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 45       |
|    time_elapsed    | 3555     |
|    total_timesteps | 161513   |
| train/             |          |
|    actor_loss      | -0.163   |
|    critic_loss     | 2.75e-05 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -1.98    |
|    learning_rate   | 0.0003   |
|    n_updates       | 151512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 45       |
|    time_elapsed    | 3587     |
|    total_timesteps | 163513   |
| train/             |          |
|    actor_loss      | -0.172   |
|    critic_loss     | 4.53e-05 |
|    ent_coef        | 0.00013  |
|    ent_coef_loss   | -0.289   |
|    learning_rate   | 0.0003   |
|    n_updates       | 153512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 45       |
|    time_elapsed    | 3621     |
|    total_timesteps | 165513   |
| train/             |          |
|    actor_loss      | -0.183   |
|    critic_loss     | 0.000576 |
|    ent_coef        | 0.000131 |
|    ent_coef_loss   | 0.426    |
|    learning_rate   | 0.0003   |
|    n_updates       | 155512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 45       |
|    time_elapsed    | 3653     |
|    total_timesteps | 167513   |
| train/             |          |
|    actor_loss      | -0.179   |
|    critic_loss     | 3.41e-05 |
|    ent_coef        | 0.000123 |
|    ent_coef_loss   | 2.68     |
|    learning_rate   | 0.0003   |
|    n_updates       | 157512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 344      |
|    fps             | 46       |
|    time_elapsed    | 3684     |
|    total_timesteps | 169513   |
| train/             |          |
|    actor_loss      | -0.188   |
|    critic_loss     | 4.08e-05 |
|    ent_coef        | 0.00012  |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 159512   |
---------------------------------
Eval num_timesteps=170000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -0.177   |
|    critic_loss     | 3.14e-05 |
|    ent_coef        | 0.000122 |
|    ent_coef_loss   | -0.706   |
|    learning_rate   | 0.0003   |
|    n_updates       | 159999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 348      |
|    fps             | 45       |
|    time_elapsed    | 3768     |
|    total_timesteps | 171513   |
| train/             |          |
|    actor_loss      | -0.183   |
|    critic_loss     | 6.29e-05 |
|    ent_coef        | 0.000106 |
|    ent_coef_loss   | -1.54    |
|    learning_rate   | 0.0003   |
|    n_updates       | 161512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 352      |
|    fps             | 45       |
|    time_elapsed    | 3800     |
|    total_timesteps | 173513   |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 3.58e-05 |
|    ent_coef        | 0.00011  |
|    ent_coef_loss   | -1.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 163512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 356      |
|    fps             | 45       |
|    time_elapsed    | 3832     |
|    total_timesteps | 175513   |
| train/             |          |
|    actor_loss      | -0.166   |
|    critic_loss     | 0.00026  |
|    ent_coef        | 8.92e-05 |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 165512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 360      |
|    fps             | 45       |
|    time_elapsed    | 3864     |
|    total_timesteps | 177513   |
| train/             |          |
|    actor_loss      | -0.153   |
|    critic_loss     | 6.7e-05  |
|    ent_coef        | 9.43e-05 |
|    ent_coef_loss   | 1.96     |
|    learning_rate   | 0.0003   |
|    n_updates       | 167512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 364      |
|    fps             | 46       |
|    time_elapsed    | 3896     |
|    total_timesteps | 179513   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 4.97e-05 |
|    ent_coef        | 0.000102 |
|    ent_coef_loss   | 3.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 169512   |
---------------------------------
{'grasped(cube1)': True}
Eval num_timesteps=180000, episode_reward=0.10 +/- 0.30
Episode length: 458.20 +/- 125.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 458      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -0.157   |
|    critic_loss     | 4.67e-05 |
|    ent_coef        | 9.74e-05 |
|    ent_coef_loss   | -0.995   |
|    learning_rate   | 0.0003   |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 368      |
|    fps             | 45       |
|    time_elapsed    | 3983     |
|    total_timesteps | 181513   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 3.91e-05 |
|    ent_coef        | 9.51e-05 |
|    ent_coef_loss   | 2.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 171512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 372      |
|    fps             | 45       |
|    time_elapsed    | 4015     |
|    total_timesteps | 183513   |
| train/             |          |
|    actor_loss      | -0.145   |
|    critic_loss     | 3.86e-05 |
|    ent_coef        | 9.83e-05 |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 173512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 376      |
|    fps             | 45       |
|    time_elapsed    | 4049     |
|    total_timesteps | 185513   |
| train/             |          |
|    actor_loss      | -0.138   |
|    critic_loss     | 2.87e-05 |
|    ent_coef        | 0.000107 |
|    ent_coef_loss   | 0.225    |
|    learning_rate   | 0.0003   |
|    n_updates       | 175512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 380      |
|    fps             | 45       |
|    time_elapsed    | 4080     |
|    total_timesteps | 187513   |
| train/             |          |
|    actor_loss      | -0.145   |
|    critic_loss     | 7.11e-05 |
|    ent_coef        | 0.000114 |
|    ent_coef_loss   | -3.53    |
|    learning_rate   | 0.0003   |
|    n_updates       | 177512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 384      |
|    fps             | 46       |
|    time_elapsed    | 4113     |
|    total_timesteps | 189513   |
| train/             |          |
|    actor_loss      | -0.152   |
|    critic_loss     | 7.28e-05 |
|    ent_coef        | 0.000124 |
|    ent_coef_loss   | 0.105    |
|    learning_rate   | 0.0003   |
|    n_updates       | 179512   |
---------------------------------
{'grasped(cube1)': True}
{'grasped(cube1)': True}
{'grasped(cube1)': True}
Eval num_timesteps=190000, episode_reward=0.30 +/- 0.46
Episode length: 382.40 +/- 182.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 382      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -0.14    |
|    critic_loss     | 0.000136 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | 2.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 179999   |
---------------------------------
New best mean reward!
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 388      |
|    fps             | 45       |
|    time_elapsed    | 4189     |
|    total_timesteps | 191062   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 8.44e-05 |
|    ent_coef        | 0.000115 |
|    ent_coef_loss   | 1.23     |
|    learning_rate   | 0.0003   |
|    n_updates       | 181061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 45       |
|    time_elapsed    | 4222     |
|    total_timesteps | 193062   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 9.74e-05 |
|    ent_coef        | 0.0001   |
|    ent_coef_loss   | -8.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 183061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 396      |
|    fps             | 45       |
|    time_elapsed    | 4257     |
|    total_timesteps | 195062   |
| train/             |          |
|    actor_loss      | -0.129   |
|    critic_loss     | 4.79e-05 |
|    ent_coef        | 0.000104 |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 185061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 400      |
|    fps             | 45       |
|    time_elapsed    | 4291     |
|    total_timesteps | 197062   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 6.38e-05 |
|    ent_coef        | 0.00011  |
|    ent_coef_loss   | 0.921    |
|    learning_rate   | 0.0003   |
|    n_updates       | 187061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 404      |
|    fps             | 45       |
|    time_elapsed    | 4329     |
|    total_timesteps | 199062   |
| train/             |          |
|    actor_loss      | -0.119   |
|    critic_loss     | 0.000109 |
|    ent_coef        | 0.000126 |
|    ent_coef_loss   | 0.912    |
|    learning_rate   | 0.0003   |
|    n_updates       | 189061   |
---------------------------------
Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -0.14    |
|    critic_loss     | 0.000321 |
|    ent_coef        | 0.000129 |
|    ent_coef_loss   | 7.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 189999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 45       |
|    time_elapsed    | 4425     |
|    total_timesteps | 201062   |
| train/             |          |
|    actor_loss      | -0.136   |
|    critic_loss     | 5.52e-05 |
|    ent_coef        | 0.000139 |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 191061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 45       |
|    time_elapsed    | 4462     |
|    total_timesteps | 203062   |
| train/             |          |
|    actor_loss      | -0.151   |
|    critic_loss     | 8.89e-05 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | 3.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 193061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 416      |
|    fps             | 45       |
|    time_elapsed    | 4496     |
|    total_timesteps | 205062   |
| train/             |          |
|    actor_loss      | -0.129   |
|    critic_loss     | 8.4e-05  |
|    ent_coef        | 0.000127 |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 195061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 420      |
|    fps             | 45       |
|    time_elapsed    | 4530     |
|    total_timesteps | 207062   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 7.84e-05 |
|    ent_coef        | 0.000135 |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 197061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 424      |
|    fps             | 45       |
|    time_elapsed    | 4564     |
|    total_timesteps | 209062   |
| train/             |          |
|    actor_loss      | -0.162   |
|    critic_loss     | 6.68e-05 |
|    ent_coef        | 0.000124 |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 199061   |
---------------------------------
Eval num_timesteps=210000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 0.000115 |
|    ent_coef        | 0.000122 |
|    ent_coef_loss   | -0.979   |
|    learning_rate   | 0.0003   |
|    n_updates       | 199999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 428      |
|    fps             | 45       |
|    time_elapsed    | 4655     |
|    total_timesteps | 211062   |
| train/             |          |
|    actor_loss      | -0.135   |
|    critic_loss     | 0.000129 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -3.69    |
|    learning_rate   | 0.0003   |
|    n_updates       | 201061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 45       |
|    time_elapsed    | 4690     |
|    total_timesteps | 213062   |
| train/             |          |
|    actor_loss      | -0.152   |
|    critic_loss     | 7.08e-05 |
|    ent_coef        | 0.000129 |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 203061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 436      |
|    fps             | 45       |
|    time_elapsed    | 4727     |
|    total_timesteps | 215062   |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 9.9e-05  |
|    ent_coef        | 0.000114 |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 205061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 440      |
|    fps             | 45       |
|    time_elapsed    | 4761     |
|    total_timesteps | 217062   |
| train/             |          |
|    actor_loss      | -0.145   |
|    critic_loss     | 9.72e-05 |
|    ent_coef        | 0.000113 |
|    ent_coef_loss   | 0.412    |
|    learning_rate   | 0.0003   |
|    n_updates       | 207061   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 444      |
|    fps             | 45       |
|    time_elapsed    | 4797     |
|    total_timesteps | 219062   |
| train/             |          |
|    actor_loss      | -0.146   |
|    critic_loss     | 9.99e-05 |
|    ent_coef        | 0.000113 |
|    ent_coef_loss   | -0.375   |
|    learning_rate   | 0.0003   |
|    n_updates       | 209061   |
---------------------------------
{'grasped(cube1)': True}
Eval num_timesteps=220000, episode_reward=0.10 +/- 0.30
Episode length: 456.30 +/- 131.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 6.75e-05 |
|    ent_coef        | 0.000113 |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 209999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 448      |
|    fps             | 45       |
|    time_elapsed    | 4884     |
|    total_timesteps | 221062   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 0.000104 |
|    ent_coef        | 0.000111 |
|    ent_coef_loss   | 0.374    |
|    learning_rate   | 0.0003   |
|    n_updates       | 211061   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 452      |
|    fps             | 45       |
|    time_elapsed    | 4914     |
|    total_timesteps | 222622   |
| train/             |          |
|    actor_loss      | -0.144   |
|    critic_loss     | 7.29e-05 |
|    ent_coef        | 0.000115 |
|    ent_coef_loss   | 0.00195  |
|    learning_rate   | 0.0003   |
|    n_updates       | 212621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 456      |
|    fps             | 45       |
|    time_elapsed    | 4949     |
|    total_timesteps | 224622   |
| train/             |          |
|    actor_loss      | -0.129   |
|    critic_loss     | 0.000131 |
|    ent_coef        | 0.000108 |
|    ent_coef_loss   | 0.121    |
|    learning_rate   | 0.0003   |
|    n_updates       | 214621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 460      |
|    fps             | 45       |
|    time_elapsed    | 4984     |
|    total_timesteps | 226622   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 4.79e-05 |
|    ent_coef        | 0.000111 |
|    ent_coef_loss   | -1.82    |
|    learning_rate   | 0.0003   |
|    n_updates       | 216621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 464      |
|    fps             | 45       |
|    time_elapsed    | 5017     |
|    total_timesteps | 228622   |
| train/             |          |
|    actor_loss      | -0.119   |
|    critic_loss     | 6.65e-05 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | 0.383    |
|    learning_rate   | 0.0003   |
|    n_updates       | 218621   |
---------------------------------
{'grasped(cube1)': True}
Eval num_timesteps=230000, episode_reward=0.10 +/- 0.30
Episode length: 454.90 +/- 135.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -0.125   |
|    critic_loss     | 9.05e-05 |
|    ent_coef        | 0.000164 |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 219999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 468      |
|    fps             | 45       |
|    time_elapsed    | 5109     |
|    total_timesteps | 230622   |
| train/             |          |
|    actor_loss      | -0.16    |
|    critic_loss     | 0.000116 |
|    ent_coef        | 0.000172 |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 220621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 472      |
|    fps             | 45       |
|    time_elapsed    | 5142     |
|    total_timesteps | 232622   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.000482 |
|    ent_coef        | 0.000176 |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 222621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 476      |
|    fps             | 45       |
|    time_elapsed    | 5177     |
|    total_timesteps | 234622   |
| train/             |          |
|    actor_loss      | -0.217   |
|    critic_loss     | 0.000207 |
|    ent_coef        | 0.00021  |
|    ent_coef_loss   | 0.879    |
|    learning_rate   | 0.0003   |
|    n_updates       | 224621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 480      |
|    fps             | 45       |
|    time_elapsed    | 5213     |
|    total_timesteps | 236622   |
| train/             |          |
|    actor_loss      | -0.193   |
|    critic_loss     | 0.000127 |
|    ent_coef        | 0.000201 |
|    ent_coef_loss   | -0.468   |
|    learning_rate   | 0.0003   |
|    n_updates       | 226621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 484      |
|    fps             | 45       |
|    time_elapsed    | 5246     |
|    total_timesteps | 238622   |
| train/             |          |
|    actor_loss      | -0.199   |
|    critic_loss     | 8.64e-05 |
|    ent_coef        | 0.00017  |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 228621   |
---------------------------------
Eval num_timesteps=240000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -0.184   |
|    critic_loss     | 6.42e-05 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | 2.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 229999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 488      |
|    fps             | 45       |
|    time_elapsed    | 5335     |
|    total_timesteps | 240622   |
| train/             |          |
|    actor_loss      | -0.215   |
|    critic_loss     | 0.000202 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | 4.96     |
|    learning_rate   | 0.0003   |
|    n_updates       | 230621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 492      |
|    fps             | 45       |
|    time_elapsed    | 5367     |
|    total_timesteps | 242622   |
| train/             |          |
|    actor_loss      | -0.204   |
|    critic_loss     | 0.000119 |
|    ent_coef        | 0.000162 |
|    ent_coef_loss   | -1.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 232621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 496      |
|    fps             | 45       |
|    time_elapsed    | 5402     |
|    total_timesteps | 244622   |
| train/             |          |
|    actor_loss      | -0.227   |
|    critic_loss     | 0.000125 |
|    ent_coef        | 0.00016  |
|    ent_coef_loss   | -0.818   |
|    learning_rate   | 0.0003   |
|    n_updates       | 234621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 500      |
|    fps             | 45       |
|    time_elapsed    | 5433     |
|    total_timesteps | 246622   |
| train/             |          |
|    actor_loss      | -0.198   |
|    critic_loss     | 0.000234 |
|    ent_coef        | 0.000161 |
|    ent_coef_loss   | -4.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 236621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 504      |
|    fps             | 45       |
|    time_elapsed    | 5466     |
|    total_timesteps | 248622   |
| train/             |          |
|    actor_loss      | -0.198   |
|    critic_loss     | 9.71e-05 |
|    ent_coef        | 0.000154 |
|    ent_coef_loss   | -0.269   |
|    learning_rate   | 0.0003   |
|    n_updates       | 238621   |
---------------------------------
Eval num_timesteps=250000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -0.241   |
|    critic_loss     | 0.000131 |
|    ent_coef        | 0.000162 |
|    ent_coef_loss   | 0.54     |
|    learning_rate   | 0.0003   |
|    n_updates       | 239999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 508      |
|    fps             | 45       |
|    time_elapsed    | 5556     |
|    total_timesteps | 250622   |
| train/             |          |
|    actor_loss      | -0.256   |
|    critic_loss     | 0.000149 |
|    ent_coef        | 0.00016  |
|    ent_coef_loss   | 0.776    |
|    learning_rate   | 0.0003   |
|    n_updates       | 240621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 512      |
|    fps             | 45       |
|    time_elapsed    | 5589     |
|    total_timesteps | 252622   |
| train/             |          |
|    actor_loss      | -0.235   |
|    critic_loss     | 0.000201 |
|    ent_coef        | 0.000178 |
|    ent_coef_loss   | 7.55     |
|    learning_rate   | 0.0003   |
|    n_updates       | 242621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 516      |
|    fps             | 45       |
|    time_elapsed    | 5621     |
|    total_timesteps | 254622   |
| train/             |          |
|    actor_loss      | -0.271   |
|    critic_loss     | 0.000509 |
|    ent_coef        | 0.000204 |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 244621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 520      |
|    fps             | 45       |
|    time_elapsed    | 5656     |
|    total_timesteps | 256622   |
| train/             |          |
|    actor_loss      | -0.291   |
|    critic_loss     | 0.000502 |
|    ent_coef        | 0.000203 |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 246621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 524      |
|    fps             | 45       |
|    time_elapsed    | 5691     |
|    total_timesteps | 258622   |
| train/             |          |
|    actor_loss      | -0.3     |
|    critic_loss     | 0.000331 |
|    ent_coef        | 0.000229 |
|    ent_coef_loss   | 1.05     |
|    learning_rate   | 0.0003   |
|    n_updates       | 248621   |
---------------------------------
Eval num_timesteps=260000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -0.205   |
|    critic_loss     | 0.000469 |
|    ent_coef        | 0.000221 |
|    ent_coef_loss   | 0.162    |
|    learning_rate   | 0.0003   |
|    n_updates       | 249999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 528      |
|    fps             | 45       |
|    time_elapsed    | 5782     |
|    total_timesteps | 260622   |
| train/             |          |
|    actor_loss      | -0.26    |
|    critic_loss     | 0.00193  |
|    ent_coef        | 0.000219 |
|    ent_coef_loss   | -0.406   |
|    learning_rate   | 0.0003   |
|    n_updates       | 250621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 45       |
|    time_elapsed    | 5817     |
|    total_timesteps | 262622   |
| train/             |          |
|    actor_loss      | -0.214   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000252 |
|    ent_coef_loss   | 0.513    |
|    learning_rate   | 0.0003   |
|    n_updates       | 252621   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 536      |
|    fps             | 45       |
|    time_elapsed    | 5843     |
|    total_timesteps | 264194   |
| train/             |          |
|    actor_loss      | -0.318   |
|    critic_loss     | 0.000818 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 254193   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 540      |
|    fps             | 45       |
|    time_elapsed    | 5877     |
|    total_timesteps | 266194   |
| train/             |          |
|    actor_loss      | -0.248   |
|    critic_loss     | 0.0004   |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | 3.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 256193   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 544      |
|    fps             | 45       |
|    time_elapsed    | 5911     |
|    total_timesteps | 268194   |
| train/             |          |
|    actor_loss      | -0.241   |
|    critic_loss     | 0.000449 |
|    ent_coef        | 0.000328 |
|    ent_coef_loss   | -4.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 258193   |
---------------------------------
{'grasped(cube2)': True}
Eval num_timesteps=270000, episode_reward=0.10 +/- 0.30
Episode length: 461.30 +/- 116.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.000809 |
|    ent_coef        | 0.000357 |
|    ent_coef_loss   | -4.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 259999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 548      |
|    fps             | 45       |
|    time_elapsed    | 5996     |
|    total_timesteps | 270194   |
| train/             |          |
|    actor_loss      | -0.243   |
|    critic_loss     | 0.000784 |
|    ent_coef        | 0.000361 |
|    ent_coef_loss   | -2.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 260193   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 552      |
|    fps             | 45       |
|    time_elapsed    | 6026     |
|    total_timesteps | 271963   |
| train/             |          |
|    actor_loss      | -0.373   |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000369 |
|    ent_coef_loss   | -0.998   |
|    learning_rate   | 0.0003   |
|    n_updates       | 261962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 556      |
|    fps             | 45       |
|    time_elapsed    | 6061     |
|    total_timesteps | 273963   |
| train/             |          |
|    actor_loss      | -0.363   |
|    critic_loss     | 0.00129  |
|    ent_coef        | 0.000413 |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 263962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 560      |
|    fps             | 45       |
|    time_elapsed    | 6095     |
|    total_timesteps | 275963   |
| train/             |          |
|    actor_loss      | -0.3     |
|    critic_loss     | 0.0013   |
|    ent_coef        | 0.000437 |
|    ent_coef_loss   | -0.536   |
|    learning_rate   | 0.0003   |
|    n_updates       | 265962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 564      |
|    fps             | 45       |
|    time_elapsed    | 6129     |
|    total_timesteps | 277963   |
| train/             |          |
|    actor_loss      | -0.398   |
|    critic_loss     | 0.000854 |
|    ent_coef        | 0.000451 |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 0.0003   |
|    n_updates       | 267962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 568      |
|    fps             | 45       |
|    time_elapsed    | 6164     |
|    total_timesteps | 279963   |
| train/             |          |
|    actor_loss      | -0.514   |
|    critic_loss     | 0.00276  |
|    ent_coef        | 0.000475 |
|    ent_coef_loss   | 4.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 269962   |
---------------------------------
Eval num_timesteps=280000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -0.305   |
|    critic_loss     | 0.00193  |
|    ent_coef        | 0.000479 |
|    ent_coef_loss   | 0.952    |
|    learning_rate   | 0.0003   |
|    n_updates       | 269999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 572      |
|    fps             | 45       |
|    time_elapsed    | 6257     |
|    total_timesteps | 281963   |
| train/             |          |
|    actor_loss      | -0.275   |
|    critic_loss     | 0.00211  |
|    ent_coef        | 0.000506 |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 271962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 576      |
|    fps             | 45       |
|    time_elapsed    | 6291     |
|    total_timesteps | 283963   |
| train/             |          |
|    actor_loss      | -0.433   |
|    critic_loss     | 0.00103  |
|    ent_coef        | 0.000499 |
|    ent_coef_loss   | 0.516    |
|    learning_rate   | 0.0003   |
|    n_updates       | 273962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 580      |
|    fps             | 45       |
|    time_elapsed    | 6326     |
|    total_timesteps | 285963   |
| train/             |          |
|    actor_loss      | -0.24    |
|    critic_loss     | 0.000719 |
|    ent_coef        | 0.000502 |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 275962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 584      |
|    fps             | 45       |
|    time_elapsed    | 6359     |
|    total_timesteps | 287963   |
| train/             |          |
|    actor_loss      | -0.541   |
|    critic_loss     | 0.00186  |
|    ent_coef        | 0.000549 |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 0.0003   |
|    n_updates       | 277962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 588      |
|    fps             | 45       |
|    time_elapsed    | 6396     |
|    total_timesteps | 289963   |
| train/             |          |
|    actor_loss      | -0.549   |
|    critic_loss     | 0.0081   |
|    ent_coef        | 0.000561 |
|    ent_coef_loss   | 0.378    |
|    learning_rate   | 0.0003   |
|    n_updates       | 279962   |
---------------------------------
Eval num_timesteps=290000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -0.596   |
|    critic_loss     | 0.00214  |
|    ent_coef        | 0.000564 |
|    ent_coef_loss   | 3.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 279999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 592      |
|    fps             | 44       |
|    time_elapsed    | 6489     |
|    total_timesteps | 291963   |
| train/             |          |
|    actor_loss      | -0.566   |
|    critic_loss     | 0.00268  |
|    ent_coef        | 0.000586 |
|    ent_coef_loss   | 0.259    |
|    learning_rate   | 0.0003   |
|    n_updates       | 281962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 596      |
|    fps             | 45       |
|    time_elapsed    | 6523     |
|    total_timesteps | 293963   |
| train/             |          |
|    actor_loss      | -0.581   |
|    critic_loss     | 0.00146  |
|    ent_coef        | 0.000581 |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 283962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 600      |
|    fps             | 45       |
|    time_elapsed    | 6559     |
|    total_timesteps | 295963   |
| train/             |          |
|    actor_loss      | -0.572   |
|    critic_loss     | 0.00323  |
|    ent_coef        | 0.000567 |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 285962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 604      |
|    fps             | 45       |
|    time_elapsed    | 6592     |
|    total_timesteps | 297963   |
| train/             |          |
|    actor_loss      | -0.505   |
|    critic_loss     | 0.00249  |
|    ent_coef        | 0.000603 |
|    ent_coef_loss   | -1.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 287962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 608      |
|    fps             | 45       |
|    time_elapsed    | 6627     |
|    total_timesteps | 299963   |
| train/             |          |
|    actor_loss      | -0.525   |
|    critic_loss     | 0.00222  |
|    ent_coef        | 0.000591 |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 0.0003   |
|    n_updates       | 289962   |
---------------------------------
Eval num_timesteps=300000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -0.679   |
|    critic_loss     | 0.00171  |
|    ent_coef        | 0.000593 |
|    ent_coef_loss   | 0.441    |
|    learning_rate   | 0.0003   |
|    n_updates       | 289999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 612      |
|    fps             | 44       |
|    time_elapsed    | 6715     |
|    total_timesteps | 301963   |
| train/             |          |
|    actor_loss      | -0.906   |
|    critic_loss     | 0.00305  |
|    ent_coef        | 0.000665 |
|    ent_coef_loss   | -4.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 291962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 616      |
|    fps             | 45       |
|    time_elapsed    | 6750     |
|    total_timesteps | 303963   |
| train/             |          |
|    actor_loss      | -0.708   |
|    critic_loss     | 0.00235  |
|    ent_coef        | 0.000634 |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 293962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 620      |
|    fps             | 45       |
|    time_elapsed    | 6784     |
|    total_timesteps | 305963   |
| train/             |          |
|    actor_loss      | -0.722   |
|    critic_loss     | 0.00385  |
|    ent_coef        | 0.000647 |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 295962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 624      |
|    fps             | 45       |
|    time_elapsed    | 6819     |
|    total_timesteps | 307963   |
| train/             |          |
|    actor_loss      | -0.733   |
|    critic_loss     | 0.00426  |
|    ent_coef        | 0.000671 |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 0.0003   |
|    n_updates       | 297962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 628      |
|    fps             | 45       |
|    time_elapsed    | 6852     |
|    total_timesteps | 309963   |
| train/             |          |
|    actor_loss      | -0.608   |
|    critic_loss     | 0.00277  |
|    ent_coef        | 0.000626 |
|    ent_coef_loss   | -0.267   |
|    learning_rate   | 0.0003   |
|    n_updates       | 299962   |
---------------------------------
Eval num_timesteps=310000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -0.865   |
|    critic_loss     | 0.00764  |
|    ent_coef        | 0.00063  |
|    ent_coef_loss   | 2.82     |
|    learning_rate   | 0.0003   |
|    n_updates       | 299999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 493      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 632      |
|    fps             | 44       |
|    time_elapsed    | 6944     |
|    total_timesteps | 311963   |
| train/             |          |
|    actor_loss      | -0.714   |
|    critic_loss     | 0.00273  |
|    ent_coef        | 0.000658 |
|    ent_coef_loss   | 0.273    |
|    learning_rate   | 0.0003   |
|    n_updates       | 301962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 636      |
|    fps             | 44       |
|    time_elapsed    | 6979     |
|    total_timesteps | 313963   |
| train/             |          |
|    actor_loss      | -0.568   |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.000642 |
|    ent_coef_loss   | -2.83    |
|    learning_rate   | 0.0003   |
|    n_updates       | 303962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 640      |
|    fps             | 45       |
|    time_elapsed    | 7017     |
|    total_timesteps | 315963   |
| train/             |          |
|    actor_loss      | -0.752   |
|    critic_loss     | 0.00358  |
|    ent_coef        | 0.000672 |
|    ent_coef_loss   | -1.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 305962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 644      |
|    fps             | 45       |
|    time_elapsed    | 7049     |
|    total_timesteps | 317963   |
| train/             |          |
|    actor_loss      | -0.433   |
|    critic_loss     | 0.00228  |
|    ent_coef        | 0.000681 |
|    ent_coef_loss   | -1.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 307962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 498      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 648      |
|    fps             | 45       |
|    time_elapsed    | 7081     |
|    total_timesteps | 319963   |
| train/             |          |
|    actor_loss      | -0.658   |
|    critic_loss     | 0.00292  |
|    ent_coef        | 0.00068  |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 309962   |
---------------------------------
Eval num_timesteps=320000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -0.865   |
|    critic_loss     | 0.00516  |
|    ent_coef        | 0.000676 |
|    ent_coef_loss   | 2.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 309999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 652      |
|    fps             | 44       |
|    time_elapsed    | 7171     |
|    total_timesteps | 321963   |
| train/             |          |
|    actor_loss      | -0.638   |
|    critic_loss     | 0.0048   |
|    ent_coef        | 0.000685 |
|    ent_coef_loss   | 0.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 311962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 656      |
|    fps             | 44       |
|    time_elapsed    | 7205     |
|    total_timesteps | 323963   |
| train/             |          |
|    actor_loss      | -0.564   |
|    critic_loss     | 0.0024   |
|    ent_coef        | 0.000692 |
|    ent_coef_loss   | -0.988   |
|    learning_rate   | 0.0003   |
|    n_updates       | 313962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 660      |
|    fps             | 45       |
|    time_elapsed    | 7239     |
|    total_timesteps | 325963   |
| train/             |          |
|    actor_loss      | -0.62    |
|    critic_loss     | 0.00615  |
|    ent_coef        | 0.000737 |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 315962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 664      |
|    fps             | 45       |
|    time_elapsed    | 7274     |
|    total_timesteps | 327963   |
| train/             |          |
|    actor_loss      | -0.473   |
|    critic_loss     | 0.00239  |
|    ent_coef        | 0.000676 |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 317962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 668      |
|    fps             | 45       |
|    time_elapsed    | 7306     |
|    total_timesteps | 329963   |
| train/             |          |
|    actor_loss      | -0.72    |
|    critic_loss     | 0.00999  |
|    ent_coef        | 0.000667 |
|    ent_coef_loss   | -0.814   |
|    learning_rate   | 0.0003   |
|    n_updates       | 319962   |
---------------------------------
Eval num_timesteps=330000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -0.676   |
|    critic_loss     | 0.00299  |
|    ent_coef        | 0.000665 |
|    ent_coef_loss   | -0.0258  |
|    learning_rate   | 0.0003   |
|    n_updates       | 319999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 672      |
|    fps             | 44       |
|    time_elapsed    | 7398     |
|    total_timesteps | 331963   |
| train/             |          |
|    actor_loss      | -0.892   |
|    critic_loss     | 0.0151   |
|    ent_coef        | 0.000655 |
|    ent_coef_loss   | 0.546    |
|    learning_rate   | 0.0003   |
|    n_updates       | 321962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 676      |
|    fps             | 44       |
|    time_elapsed    | 7430     |
|    total_timesteps | 333963   |
| train/             |          |
|    actor_loss      | -0.511   |
|    critic_loss     | 0.00585  |
|    ent_coef        | 0.000669 |
|    ent_coef_loss   | -0.0942  |
|    learning_rate   | 0.0003   |
|    n_updates       | 323962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 680      |
|    fps             | 44       |
|    time_elapsed    | 7466     |
|    total_timesteps | 335963   |
| train/             |          |
|    actor_loss      | -0.549   |
|    critic_loss     | 0.00285  |
|    ent_coef        | 0.000693 |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 325962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 684      |
|    fps             | 45       |
|    time_elapsed    | 7499     |
|    total_timesteps | 337963   |
| train/             |          |
|    actor_loss      | -0.824   |
|    critic_loss     | 0.0215   |
|    ent_coef        | 0.000725 |
|    ent_coef_loss   | 3.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 327962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 688      |
|    fps             | 45       |
|    time_elapsed    | 7534     |
|    total_timesteps | 339963   |
| train/             |          |
|    actor_loss      | -0.846   |
|    critic_loss     | 0.0111   |
|    ent_coef        | 0.000734 |
|    ent_coef_loss   | 3.55     |
|    learning_rate   | 0.0003   |
|    n_updates       | 329962   |
---------------------------------
Eval num_timesteps=340000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -0.725   |
|    critic_loss     | 0.00403  |
|    ent_coef        | 0.000735 |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 329999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 692      |
|    fps             | 44       |
|    time_elapsed    | 7623     |
|    total_timesteps | 341963   |
| train/             |          |
|    actor_loss      | -0.501   |
|    critic_loss     | 0.00253  |
|    ent_coef        | 0.000716 |
|    ent_coef_loss   | -0.467   |
|    learning_rate   | 0.0003   |
|    n_updates       | 331962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 696      |
|    fps             | 44       |
|    time_elapsed    | 7656     |
|    total_timesteps | 343963   |
| train/             |          |
|    actor_loss      | -0.439   |
|    critic_loss     | 0.00583  |
|    ent_coef        | 0.000733 |
|    ent_coef_loss   | -0.923   |
|    learning_rate   | 0.0003   |
|    n_updates       | 333962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 700      |
|    fps             | 44       |
|    time_elapsed    | 7691     |
|    total_timesteps | 345963   |
| train/             |          |
|    actor_loss      | -0.648   |
|    critic_loss     | 0.00784  |
|    ent_coef        | 0.000757 |
|    ent_coef_loss   | -0.845   |
|    learning_rate   | 0.0003   |
|    n_updates       | 335962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 704      |
|    fps             | 45       |
|    time_elapsed    | 7724     |
|    total_timesteps | 347963   |
| train/             |          |
|    actor_loss      | -0.654   |
|    critic_loss     | 0.00414  |
|    ent_coef        | 0.000748 |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 337962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 708      |
|    fps             | 45       |
|    time_elapsed    | 7759     |
|    total_timesteps | 349963   |
| train/             |          |
|    actor_loss      | -0.627   |
|    critic_loss     | 0.00362  |
|    ent_coef        | 0.000735 |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 0.0003   |
|    n_updates       | 339962   |
---------------------------------
Eval num_timesteps=350000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -0.569   |
|    critic_loss     | 0.0058   |
|    ent_coef        | 0.000738 |
|    ent_coef_loss   | 2.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 339999   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 44       |
|    time_elapsed    | 7842     |
|    total_timesteps | 351548   |
| train/             |          |
|    actor_loss      | -0.665   |
|    critic_loss     | 0.0032   |
|    ent_coef        | 0.000809 |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 341547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 716      |
|    fps             | 44       |
|    time_elapsed    | 7876     |
|    total_timesteps | 353548   |
| train/             |          |
|    actor_loss      | -0.827   |
|    critic_loss     | 0.00497  |
|    ent_coef        | 0.00077  |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 343547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 720      |
|    fps             | 44       |
|    time_elapsed    | 7911     |
|    total_timesteps | 355548   |
| train/             |          |
|    actor_loss      | -0.5     |
|    critic_loss     | 0.00339  |
|    ent_coef        | 0.000797 |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 345547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 724      |
|    fps             | 45       |
|    time_elapsed    | 7943     |
|    total_timesteps | 357548   |
| train/             |          |
|    actor_loss      | -0.617   |
|    critic_loss     | 0.00362  |
|    ent_coef        | 0.000838 |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 347547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 728      |
|    fps             | 45       |
|    time_elapsed    | 7979     |
|    total_timesteps | 359548   |
| train/             |          |
|    actor_loss      | -0.866   |
|    critic_loss     | 0.493    |
|    ent_coef        | 0.000818 |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 349547   |
---------------------------------
Eval num_timesteps=360000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -0.674   |
|    critic_loss     | 0.00937  |
|    ent_coef        | 0.000838 |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 349999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 44       |
|    time_elapsed    | 8069     |
|    total_timesteps | 361548   |
| train/             |          |
|    actor_loss      | -0.614   |
|    critic_loss     | 0.0201   |
|    ent_coef        | 0.000802 |
|    ent_coef_loss   | 2.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 351547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 736      |
|    fps             | 44       |
|    time_elapsed    | 8104     |
|    total_timesteps | 363548   |
| train/             |          |
|    actor_loss      | -0.691   |
|    critic_loss     | 0.00353  |
|    ent_coef        | 0.000811 |
|    ent_coef_loss   | -0.538   |
|    learning_rate   | 0.0003   |
|    n_updates       | 353547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 44       |
|    time_elapsed    | 8139     |
|    total_timesteps | 365548   |
| train/             |          |
|    actor_loss      | -0.641   |
|    critic_loss     | 0.00386  |
|    ent_coef        | 0.000818 |
|    ent_coef_loss   | -0.128   |
|    learning_rate   | 0.0003   |
|    n_updates       | 355547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 744      |
|    fps             | 44       |
|    time_elapsed    | 8171     |
|    total_timesteps | 367548   |
| train/             |          |
|    actor_loss      | -0.556   |
|    critic_loss     | 0.0164   |
|    ent_coef        | 0.000811 |
|    ent_coef_loss   | -1.65    |
|    learning_rate   | 0.0003   |
|    n_updates       | 357547   |
---------------------------------
{'grasped(cube1)': True}
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 748      |
|    fps             | 44       |
|    time_elapsed    | 8195     |
|    total_timesteps | 368625   |
| train/             |          |
|    actor_loss      | -0.702   |
|    critic_loss     | 0.00546  |
|    ent_coef        | 0.000821 |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 0.0003   |
|    n_updates       | 358624   |
---------------------------------
Eval num_timesteps=370000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -0.631   |
|    critic_loss     | 0.00863  |
|    ent_coef        | 0.000839 |
|    ent_coef_loss   | 0.131    |
|    learning_rate   | 0.0003   |
|    n_updates       | 359999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 752      |
|    fps             | 44       |
|    time_elapsed    | 8284     |
|    total_timesteps | 370625   |
| train/             |          |
|    actor_loss      | -0.554   |
|    critic_loss     | 0.00406  |
|    ent_coef        | 0.000821 |
|    ent_coef_loss   | 4.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 360624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 44       |
|    time_elapsed    | 8317     |
|    total_timesteps | 372625   |
| train/             |          |
|    actor_loss      | -0.739   |
|    critic_loss     | 0.0052   |
|    ent_coef        | 0.000818 |
|    ent_coef_loss   | 0.845    |
|    learning_rate   | 0.0003   |
|    n_updates       | 362624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 760      |
|    fps             | 44       |
|    time_elapsed    | 8351     |
|    total_timesteps | 374625   |
| train/             |          |
|    actor_loss      | -0.661   |
|    critic_loss     | 0.0123   |
|    ent_coef        | 0.000788 |
|    ent_coef_loss   | 2.9      |
|    learning_rate   | 0.0003   |
|    n_updates       | 364624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 764      |
|    fps             | 44       |
|    time_elapsed    | 8385     |
|    total_timesteps | 376625   |
| train/             |          |
|    actor_loss      | -0.63    |
|    critic_loss     | 0.0039   |
|    ent_coef        | 0.000752 |
|    ent_coef_loss   | 0.578    |
|    learning_rate   | 0.0003   |
|    n_updates       | 366624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 768      |
|    fps             | 44       |
|    time_elapsed    | 8418     |
|    total_timesteps | 378625   |
| train/             |          |
|    actor_loss      | -0.592   |
|    critic_loss     | 0.00362  |
|    ent_coef        | 0.000718 |
|    ent_coef_loss   | 0.323    |
|    learning_rate   | 0.0003   |
|    n_updates       | 368624   |
---------------------------------
Eval num_timesteps=380000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -0.538   |
|    critic_loss     | 0.00365  |
|    ent_coef        | 0.000731 |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 369999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 772      |
|    fps             | 44       |
|    time_elapsed    | 8506     |
|    total_timesteps | 380625   |
| train/             |          |
|    actor_loss      | -0.549   |
|    critic_loss     | 0.00275  |
|    ent_coef        | 0.000715 |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 370624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 776      |
|    fps             | 44       |
|    time_elapsed    | 8539     |
|    total_timesteps | 382625   |
| train/             |          |
|    actor_loss      | -0.662   |
|    critic_loss     | 0.00445  |
|    ent_coef        | 0.000682 |
|    ent_coef_loss   | 0.995    |
|    learning_rate   | 0.0003   |
|    n_updates       | 372624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 780      |
|    fps             | 44       |
|    time_elapsed    | 8574     |
|    total_timesteps | 384625   |
| train/             |          |
|    actor_loss      | -0.579   |
|    critic_loss     | 0.00252  |
|    ent_coef        | 0.000642 |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 374624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 784      |
|    fps             | 44       |
|    time_elapsed    | 8607     |
|    total_timesteps | 386625   |
| train/             |          |
|    actor_loss      | -0.457   |
|    critic_loss     | 0.012    |
|    ent_coef        | 0.000631 |
|    ent_coef_loss   | -0.262   |
|    learning_rate   | 0.0003   |
|    n_updates       | 376624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 788      |
|    fps             | 44       |
|    time_elapsed    | 8640     |
|    total_timesteps | 388625   |
| train/             |          |
|    actor_loss      | -0.395   |
|    critic_loss     | 0.00315  |
|    ent_coef        | 0.000604 |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 378624   |
---------------------------------
Eval num_timesteps=390000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -0.575   |
|    critic_loss     | 0.00221  |
|    ent_coef        | 0.000581 |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 379999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 792      |
|    fps             | 44       |
|    time_elapsed    | 8730     |
|    total_timesteps | 390625   |
| train/             |          |
|    actor_loss      | -0.545   |
|    critic_loss     | 0.00284  |
|    ent_coef        | 0.000572 |
|    ent_coef_loss   | 0.172    |
|    learning_rate   | 0.0003   |
|    n_updates       | 380624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 796      |
|    fps             | 44       |
|    time_elapsed    | 8768     |
|    total_timesteps | 392625   |
| train/             |          |
|    actor_loss      | -0.433   |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000584 |
|    ent_coef_loss   | -0.47    |
|    learning_rate   | 0.0003   |
|    n_updates       | 382624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 800      |
|    fps             | 44       |
|    time_elapsed    | 8803     |
|    total_timesteps | 394625   |
| train/             |          |
|    actor_loss      | -0.526   |
|    critic_loss     | 0.0417   |
|    ent_coef        | 0.000575 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 384624   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 804      |
|    fps             | 44       |
|    time_elapsed    | 8837     |
|    total_timesteps | 396625   |
| train/             |          |
|    actor_loss      | -0.466   |
|    critic_loss     | 0.00177  |
|    ent_coef        | 0.000534 |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 386624   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 808      |
|    fps             | 44       |
|    time_elapsed    | 8866     |
|    total_timesteps | 398227   |
| train/             |          |
|    actor_loss      | -0.457   |
|    critic_loss     | 0.00201  |
|    ent_coef        | 0.000532 |
|    ent_coef_loss   | 2.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 388226   |
---------------------------------
Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -0.371   |
|    critic_loss     | 0.00189  |
|    ent_coef        | 0.000522 |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 389999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 812      |
|    fps             | 44       |
|    time_elapsed    | 8962     |
|    total_timesteps | 400227   |
| train/             |          |
|    actor_loss      | -0.339   |
|    critic_loss     | 0.0015   |
|    ent_coef        | 0.000518 |
|    ent_coef_loss   | -0.179   |
|    learning_rate   | 0.0003   |
|    n_updates       | 390226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 816      |
|    fps             | 44       |
|    time_elapsed    | 8997     |
|    total_timesteps | 402227   |
| train/             |          |
|    actor_loss      | -0.309   |
|    critic_loss     | 0.00177  |
|    ent_coef        | 0.000487 |
|    ent_coef_loss   | -0.927   |
|    learning_rate   | 0.0003   |
|    n_updates       | 392226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 820      |
|    fps             | 44       |
|    time_elapsed    | 9032     |
|    total_timesteps | 404227   |
| train/             |          |
|    actor_loss      | -0.265   |
|    critic_loss     | 0.00135  |
|    ent_coef        | 0.000498 |
|    ent_coef_loss   | -0.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 394226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 824      |
|    fps             | 44       |
|    time_elapsed    | 9066     |
|    total_timesteps | 406227   |
| train/             |          |
|    actor_loss      | -0.306   |
|    critic_loss     | 0.00258  |
|    ent_coef        | 0.000468 |
|    ent_coef_loss   | -0.213   |
|    learning_rate   | 0.0003   |
|    n_updates       | 396226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 828      |
|    fps             | 44       |
|    time_elapsed    | 9099     |
|    total_timesteps | 408227   |
| train/             |          |
|    actor_loss      | -0.339   |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000456 |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 398226   |
---------------------------------
Eval num_timesteps=410000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -0.335   |
|    critic_loss     | 0.00191  |
|    ent_coef        | 0.000434 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 399999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 832      |
|    fps             | 44       |
|    time_elapsed    | 9191     |
|    total_timesteps | 410227   |
| train/             |          |
|    actor_loss      | -0.327   |
|    critic_loss     | 0.0012   |
|    ent_coef        | 0.000438 |
|    ent_coef_loss   | 0.345    |
|    learning_rate   | 0.0003   |
|    n_updates       | 400226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 836      |
|    fps             | 44       |
|    time_elapsed    | 9226     |
|    total_timesteps | 412227   |
| train/             |          |
|    actor_loss      | -0.155   |
|    critic_loss     | 0.000802 |
|    ent_coef        | 0.000432 |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 402226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 840      |
|    fps             | 44       |
|    time_elapsed    | 9259     |
|    total_timesteps | 414227   |
| train/             |          |
|    actor_loss      | -0.252   |
|    critic_loss     | 0.00124  |
|    ent_coef        | 0.000417 |
|    ent_coef_loss   | -0.801   |
|    learning_rate   | 0.0003   |
|    n_updates       | 404226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 844      |
|    fps             | 44       |
|    time_elapsed    | 9290     |
|    total_timesteps | 416227   |
| train/             |          |
|    actor_loss      | -0.269   |
|    critic_loss     | 0.00108  |
|    ent_coef        | 0.000428 |
|    ent_coef_loss   | 5.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 406226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 848      |
|    fps             | 44       |
|    time_elapsed    | 9324     |
|    total_timesteps | 418227   |
| train/             |          |
|    actor_loss      | -0.221   |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.000412 |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 408226   |
---------------------------------
Eval num_timesteps=420000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -0.211   |
|    critic_loss     | 0.000854 |
|    ent_coef        | 0.000408 |
|    ent_coef_loss   | 0.547    |
|    learning_rate   | 0.0003   |
|    n_updates       | 409999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 852      |
|    fps             | 44       |
|    time_elapsed    | 9412     |
|    total_timesteps | 420227   |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 0.0459   |
|    ent_coef        | 0.000418 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 410226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 856      |
|    fps             | 44       |
|    time_elapsed    | 9447     |
|    total_timesteps | 422227   |
| train/             |          |
|    actor_loss      | -0.203   |
|    critic_loss     | 0.00261  |
|    ent_coef        | 0.000409 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 412226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 860      |
|    fps             | 44       |
|    time_elapsed    | 9480     |
|    total_timesteps | 424227   |
| train/             |          |
|    actor_loss      | -0.186   |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.000381 |
|    ent_coef_loss   | -3.83    |
|    learning_rate   | 0.0003   |
|    n_updates       | 414226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 864      |
|    fps             | 44       |
|    time_elapsed    | 9516     |
|    total_timesteps | 426227   |
| train/             |          |
|    actor_loss      | -0.173   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.00037  |
|    ent_coef_loss   | 2        |
|    learning_rate   | 0.0003   |
|    n_updates       | 416226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 868      |
|    fps             | 44       |
|    time_elapsed    | 9550     |
|    total_timesteps | 428227   |
| train/             |          |
|    actor_loss      | -0.234   |
|    critic_loss     | 0.000981 |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | -4.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 418226   |
---------------------------------
Eval num_timesteps=430000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 0.00187  |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | 9.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 419999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 872      |
|    fps             | 44       |
|    time_elapsed    | 9640     |
|    total_timesteps | 430227   |
| train/             |          |
|    actor_loss      | -0.115   |
|    critic_loss     | 0.00114  |
|    ent_coef        | 0.000478 |
|    ent_coef_loss   | 0.0502   |
|    learning_rate   | 0.0003   |
|    n_updates       | 420226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 876      |
|    fps             | 44       |
|    time_elapsed    | 9676     |
|    total_timesteps | 432227   |
| train/             |          |
|    actor_loss      | -0.21    |
|    critic_loss     | 0.00149  |
|    ent_coef        | 0.000391 |
|    ent_coef_loss   | -0.0694  |
|    learning_rate   | 0.0003   |
|    n_updates       | 422226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 880      |
|    fps             | 44       |
|    time_elapsed    | 9710     |
|    total_timesteps | 434227   |
| train/             |          |
|    actor_loss      | -0.217   |
|    critic_loss     | 0.00324  |
|    ent_coef        | 0.00037  |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 0.0003   |
|    n_updates       | 424226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 884      |
|    fps             | 44       |
|    time_elapsed    | 9748     |
|    total_timesteps | 436227   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.00183  |
|    ent_coef        | 0.000366 |
|    ent_coef_loss   | -3.83    |
|    learning_rate   | 0.0003   |
|    n_updates       | 426226   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 888      |
|    fps             | 44       |
|    time_elapsed    | 9774     |
|    total_timesteps | 437745   |
| train/             |          |
|    actor_loss      | -0.106   |
|    critic_loss     | 0.000623 |
|    ent_coef        | 0.000339 |
|    ent_coef_loss   | -0.0862  |
|    learning_rate   | 0.0003   |
|    n_updates       | 427744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 892      |
|    fps             | 44       |
|    time_elapsed    | 9807     |
|    total_timesteps | 439745   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.00139  |
|    ent_coef        | 0.000339 |
|    ent_coef_loss   | 2.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 429744   |
---------------------------------
Eval num_timesteps=440000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -0.105   |
|    critic_loss     | 0.000729 |
|    ent_coef        | 0.000338 |
|    ent_coef_loss   | -3.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 429999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 896      |
|    fps             | 44       |
|    time_elapsed    | 9898     |
|    total_timesteps | 441745   |
| train/             |          |
|    actor_loss      | -0.18    |
|    critic_loss     | 0.000719 |
|    ent_coef        | 0.000344 |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 431744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 900      |
|    fps             | 44       |
|    time_elapsed    | 9935     |
|    total_timesteps | 443745   |
| train/             |          |
|    actor_loss      | -0.151   |
|    critic_loss     | 0.000819 |
|    ent_coef        | 0.000337 |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 433744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 904      |
|    fps             | 44       |
|    time_elapsed    | 9968     |
|    total_timesteps | 445745   |
| train/             |          |
|    actor_loss      | -0.127   |
|    critic_loss     | 0.000613 |
|    ent_coef        | 0.000342 |
|    ent_coef_loss   | -3.9     |
|    learning_rate   | 0.0003   |
|    n_updates       | 435744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 908      |
|    fps             | 44       |
|    time_elapsed    | 10001    |
|    total_timesteps | 447745   |
| train/             |          |
|    actor_loss      | -0.106   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000327 |
|    ent_coef_loss   | -0.968   |
|    learning_rate   | 0.0003   |
|    n_updates       | 437744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 912      |
|    fps             | 44       |
|    time_elapsed    | 10036    |
|    total_timesteps | 449745   |
| train/             |          |
|    actor_loss      | -0.223   |
|    critic_loss     | 0.00337  |
|    ent_coef        | 0.000325 |
|    ent_coef_loss   | 5.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 439744   |
---------------------------------
Eval num_timesteps=450000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -0.107   |
|    critic_loss     | 0.000835 |
|    ent_coef        | 0.00033  |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 439999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 916      |
|    fps             | 44       |
|    time_elapsed    | 10124    |
|    total_timesteps | 451745   |
| train/             |          |
|    actor_loss      | -0.184   |
|    critic_loss     | 0.000983 |
|    ent_coef        | 0.000332 |
|    ent_coef_loss   | 1.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 441744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 920      |
|    fps             | 44       |
|    time_elapsed    | 10157    |
|    total_timesteps | 453745   |
| train/             |          |
|    actor_loss      | -0.123   |
|    critic_loss     | 0.000953 |
|    ent_coef        | 0.000314 |
|    ent_coef_loss   | 5.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 443744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 924      |
|    fps             | 44       |
|    time_elapsed    | 10193    |
|    total_timesteps | 455745   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.000728 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 445744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 928      |
|    fps             | 44       |
|    time_elapsed    | 10231    |
|    total_timesteps | 457745   |
| train/             |          |
|    actor_loss      | -0.164   |
|    critic_loss     | 0.00217  |
|    ent_coef        | 0.000303 |
|    ent_coef_loss   | 2.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 447744   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 932      |
|    fps             | 44       |
|    time_elapsed    | 10260    |
|    total_timesteps | 459296   |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 0.000694 |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | -2.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 449295   |
---------------------------------
Eval num_timesteps=460000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -0.0853  |
|    critic_loss     | 0.00147  |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | -2.21    |
|    learning_rate   | 0.0003   |
|    n_updates       | 449999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 936      |
|    fps             | 44       |
|    time_elapsed    | 10346    |
|    total_timesteps | 461296   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.000676 |
|    ent_coef        | 0.000298 |
|    ent_coef_loss   | -0.598   |
|    learning_rate   | 0.0003   |
|    n_updates       | 451295   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 940      |
|    fps             | 44       |
|    time_elapsed    | 10382    |
|    total_timesteps | 463296   |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.00087  |
|    ent_coef        | 0.000308 |
|    ent_coef_loss   | -5.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 453295   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 944      |
|    fps             | 44       |
|    time_elapsed    | 10415    |
|    total_timesteps | 465296   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 0.000608 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 455295   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 948      |
|    fps             | 44       |
|    time_elapsed    | 10451    |
|    total_timesteps | 467296   |
| train/             |          |
|    actor_loss      | -0.0892  |
|    critic_loss     | 0.000654 |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 457295   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 952      |
|    fps             | 44       |
|    time_elapsed    | 10486    |
|    total_timesteps | 469296   |
| train/             |          |
|    actor_loss      | -0.167   |
|    critic_loss     | 0.000704 |
|    ent_coef        | 0.00029  |
|    ent_coef_loss   | -0.988   |
|    learning_rate   | 0.0003   |
|    n_updates       | 459295   |
---------------------------------
Eval num_timesteps=470000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -0.0847  |
|    critic_loss     | 0.00143  |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | -4.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 459999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 956      |
|    fps             | 44       |
|    time_elapsed    | 10577    |
|    total_timesteps | 471296   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 0.00064  |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 461295   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 960      |
|    fps             | 44       |
|    time_elapsed    | 10607    |
|    total_timesteps | 472902   |
| train/             |          |
|    actor_loss      | -0.061   |
|    critic_loss     | 0.00446  |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -3.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 462901   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 964      |
|    fps             | 44       |
|    time_elapsed    | 10642    |
|    total_timesteps | 474902   |
| train/             |          |
|    actor_loss      | -0.125   |
|    critic_loss     | 0.000676 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | -5.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 464901   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 968      |
|    fps             | 44       |
|    time_elapsed    | 10679    |
|    total_timesteps | 476902   |
| train/             |          |
|    actor_loss      | -0.0879  |
|    critic_loss     | 0.000668 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 0.0003   |
|    n_updates       | 466901   |
---------------------------------
{'grasped(cube3)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 972      |
|    fps             | 44       |
|    time_elapsed    | 10708    |
|    total_timesteps | 478481   |
| train/             |          |
|    actor_loss      | -0.0667  |
|    critic_loss     | 0.000841 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | 0.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 468480   |
---------------------------------
Eval num_timesteps=480000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.0005   |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -5.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 469999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 976      |
|    fps             | 44       |
|    time_elapsed    | 10796    |
|    total_timesteps | 480481   |
| train/             |          |
|    actor_loss      | -0.138   |
|    critic_loss     | 0.000719 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 1        |
|    learning_rate   | 0.0003   |
|    n_updates       | 470480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 980      |
|    fps             | 44       |
|    time_elapsed    | 10831    |
|    total_timesteps | 482481   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 0.000447 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -0.722   |
|    learning_rate   | 0.0003   |
|    n_updates       | 472480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 984      |
|    fps             | 44       |
|    time_elapsed    | 10865    |
|    total_timesteps | 484481   |
| train/             |          |
|    actor_loss      | -0.078   |
|    critic_loss     | 0.000827 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | 0.421    |
|    learning_rate   | 0.0003   |
|    n_updates       | 474480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 988      |
|    fps             | 44       |
|    time_elapsed    | 10898    |
|    total_timesteps | 486481   |
| train/             |          |
|    actor_loss      | -0.0571  |
|    critic_loss     | 0.00087  |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | -3.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 476480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 992      |
|    fps             | 44       |
|    time_elapsed    | 10932    |
|    total_timesteps | 488481   |
| train/             |          |
|    actor_loss      | -0.0876  |
|    critic_loss     | 0.000915 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | -0.0587  |
|    learning_rate   | 0.0003   |
|    n_updates       | 478480   |
---------------------------------
Eval num_timesteps=490000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -0.0749  |
|    critic_loss     | 0.000533 |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -0.653   |
|    learning_rate   | 0.0003   |
|    n_updates       | 479999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 996      |
|    fps             | 44       |
|    time_elapsed    | 11025    |
|    total_timesteps | 490481   |
| train/             |          |
|    actor_loss      | -0.0549  |
|    critic_loss     | 0.000873 |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | 2.9      |
|    learning_rate   | 0.0003   |
|    n_updates       | 480480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 44       |
|    time_elapsed    | 11060    |
|    total_timesteps | 492481   |
| train/             |          |
|    actor_loss      | -0.148   |
|    critic_loss     | 0.000703 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 7.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 482480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 44       |
|    time_elapsed    | 11093    |
|    total_timesteps | 494481   |
| train/             |          |
|    actor_loss      | -0.0498  |
|    critic_loss     | 0.00821  |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 484480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 44       |
|    time_elapsed    | 11126    |
|    total_timesteps | 496481   |
| train/             |          |
|    actor_loss      | -0.0685  |
|    critic_loss     | 0.00108  |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 486480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 44       |
|    time_elapsed    | 11160    |
|    total_timesteps | 498481   |
| train/             |          |
|    actor_loss      | -0.0978  |
|    critic_loss     | 0.00112  |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | 0.421    |
|    learning_rate   | 0.0003   |
|    n_updates       | 488480   |
---------------------------------
Eval num_timesteps=500000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -0.0546  |
|    critic_loss     | 0.000824 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 489999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 44       |
|    time_elapsed    | 11248    |
|    total_timesteps | 500481   |
| train/             |          |
|    actor_loss      | -0.0946  |
|    critic_loss     | 0.000716 |
|    ent_coef        | 0.000299 |
|    ent_coef_loss   | 4.97     |
|    learning_rate   | 0.0003   |
|    n_updates       | 490480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 44       |
|    time_elapsed    | 11284    |
|    total_timesteps | 502481   |
| train/             |          |
|    actor_loss      | -0.247   |
|    critic_loss     | 0.00406  |
|    ent_coef        | 0.000324 |
|    ent_coef_loss   | -0.0491  |
|    learning_rate   | 0.0003   |
|    n_updates       | 492480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 44       |
|    time_elapsed    | 11318    |
|    total_timesteps | 504481   |
| train/             |          |
|    actor_loss      | -0.0385  |
|    critic_loss     | 0.000889 |
|    ent_coef        | 0.00036  |
|    ent_coef_loss   | -2.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 494480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 44       |
|    time_elapsed    | 11353    |
|    total_timesteps | 506481   |
| train/             |          |
|    actor_loss      | -0.0751  |
|    critic_loss     | 0.00142  |
|    ent_coef        | 0.00035  |
|    ent_coef_loss   | -0.324   |
|    learning_rate   | 0.0003   |
|    n_updates       | 496480   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 44       |
|    time_elapsed    | 11386    |
|    total_timesteps | 508481   |
| train/             |          |
|    actor_loss      | -0.0672  |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.000372 |
|    ent_coef_loss   | 3.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 498480   |
---------------------------------
Eval num_timesteps=510000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.00185  |
|    ent_coef        | 0.000369 |
|    ent_coef_loss   | 2.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 499999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 44       |
|    time_elapsed    | 11478    |
|    total_timesteps | 510481   |
| train/             |          |
|    actor_loss      | -0.112   |
|    critic_loss     | 0.00171  |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | 1        |
|    learning_rate   | 0.0003   |
|    n_updates       | 500480   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 44       |
|    time_elapsed    | 11504    |
|    total_timesteps | 512089   |
| train/             |          |
|    actor_loss      | -0.0756  |
|    critic_loss     | 0.00289  |
|    ent_coef        | 0.000391 |
|    ent_coef_loss   | 2.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 502088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 44       |
|    time_elapsed    | 11537    |
|    total_timesteps | 514089   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.00129  |
|    ent_coef        | 0.000394 |
|    ent_coef_loss   | 0.132    |
|    learning_rate   | 0.0003   |
|    n_updates       | 504088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 44       |
|    time_elapsed    | 11569    |
|    total_timesteps | 516089   |
| train/             |          |
|    actor_loss      | -0.0729  |
|    critic_loss     | 0.00126  |
|    ent_coef        | 0.000408 |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 506088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 44       |
|    time_elapsed    | 11601    |
|    total_timesteps | 518089   |
| train/             |          |
|    actor_loss      | -0.128   |
|    critic_loss     | 0.002    |
|    ent_coef        | 0.000438 |
|    ent_coef_loss   | 0.291    |
|    learning_rate   | 0.0003   |
|    n_updates       | 508088   |
---------------------------------
Eval num_timesteps=520000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -0.201   |
|    critic_loss     | 0.00229  |
|    ent_coef        | 0.00049  |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 509999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 44       |
|    time_elapsed    | 11689    |
|    total_timesteps | 520089   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.00313  |
|    ent_coef        | 0.000489 |
|    ent_coef_loss   | -0.258   |
|    learning_rate   | 0.0003   |
|    n_updates       | 510088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 44       |
|    time_elapsed    | 11722    |
|    total_timesteps | 522089   |
| train/             |          |
|    actor_loss      | -0.211   |
|    critic_loss     | 0.44     |
|    ent_coef        | 0.000557 |
|    ent_coef_loss   | 0.195    |
|    learning_rate   | 0.0003   |
|    n_updates       | 512088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 44       |
|    time_elapsed    | 11759    |
|    total_timesteps | 524089   |
| train/             |          |
|    actor_loss      | -0.399   |
|    critic_loss     | 0.0052   |
|    ent_coef        | 0.000581 |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 514088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 44       |
|    time_elapsed    | 11790    |
|    total_timesteps | 526089   |
| train/             |          |
|    actor_loss      | -0.186   |
|    critic_loss     | 0.00344  |
|    ent_coef        | 0.000584 |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 516088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 44       |
|    time_elapsed    | 11824    |
|    total_timesteps | 528089   |
| train/             |          |
|    actor_loss      | -0.221   |
|    critic_loss     | 0.00825  |
|    ent_coef        | 0.000628 |
|    ent_coef_loss   | 0.0861   |
|    learning_rate   | 0.0003   |
|    n_updates       | 518088   |
---------------------------------
Eval num_timesteps=530000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -0.295   |
|    critic_loss     | 0.00467  |
|    ent_coef        | 0.000671 |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 519999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 44       |
|    time_elapsed    | 11911    |
|    total_timesteps | 530089   |
| train/             |          |
|    actor_loss      | -0.372   |
|    critic_loss     | 0.00432  |
|    ent_coef        | 0.000663 |
|    ent_coef_loss   | -0.624   |
|    learning_rate   | 0.0003   |
|    n_updates       | 520088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 44       |
|    time_elapsed    | 11946    |
|    total_timesteps | 532089   |
| train/             |          |
|    actor_loss      | -0.395   |
|    critic_loss     | 0.00771  |
|    ent_coef        | 0.000747 |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 522088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 44       |
|    time_elapsed    | 11979    |
|    total_timesteps | 534089   |
| train/             |          |
|    actor_loss      | -0.346   |
|    critic_loss     | 0.00409  |
|    ent_coef        | 0.000788 |
|    ent_coef_loss   | -0.287   |
|    learning_rate   | 0.0003   |
|    n_updates       | 524088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 44       |
|    time_elapsed    | 12012    |
|    total_timesteps | 536089   |
| train/             |          |
|    actor_loss      | -0.431   |
|    critic_loss     | 0.0196   |
|    ent_coef        | 0.000829 |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 526088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 44       |
|    time_elapsed    | 12048    |
|    total_timesteps | 538089   |
| train/             |          |
|    actor_loss      | -0.919   |
|    critic_loss     | 0.00685  |
|    ent_coef        | 0.000884 |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 528088   |
---------------------------------
Eval num_timesteps=540000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -0.635   |
|    critic_loss     | 0.0116   |
|    ent_coef        | 0.000834 |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 529999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 44       |
|    time_elapsed    | 12139    |
|    total_timesteps | 540089   |
| train/             |          |
|    actor_loss      | -0.632   |
|    critic_loss     | 0.00749  |
|    ent_coef        | 0.000844 |
|    ent_coef_loss   | 4.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 530088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 44       |
|    time_elapsed    | 12173    |
|    total_timesteps | 542089   |
| train/             |          |
|    actor_loss      | -0.445   |
|    critic_loss     | 0.00663  |
|    ent_coef        | 0.000857 |
|    ent_coef_loss   | -1.57    |
|    learning_rate   | 0.0003   |
|    n_updates       | 532088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 44       |
|    time_elapsed    | 12209    |
|    total_timesteps | 544089   |
| train/             |          |
|    actor_loss      | -0.502   |
|    critic_loss     | 0.00831  |
|    ent_coef        | 0.000909 |
|    ent_coef_loss   | -0.793   |
|    learning_rate   | 0.0003   |
|    n_updates       | 534088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 44       |
|    time_elapsed    | 12242    |
|    total_timesteps | 546089   |
| train/             |          |
|    actor_loss      | -0.702   |
|    critic_loss     | 0.0076   |
|    ent_coef        | 0.000892 |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 536088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 44       |
|    time_elapsed    | 12275    |
|    total_timesteps | 548089   |
| train/             |          |
|    actor_loss      | -0.657   |
|    critic_loss     | 0.00791  |
|    ent_coef        | 0.000957 |
|    ent_coef_loss   | 3.23     |
|    learning_rate   | 0.0003   |
|    n_updates       | 538088   |
---------------------------------
Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -0.509   |
|    critic_loss     | 0.00837  |
|    ent_coef        | 0.00102  |
|    ent_coef_loss   | -2.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 539999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 44       |
|    time_elapsed    | 12358    |
|    total_timesteps | 550089   |
| train/             |          |
|    actor_loss      | -0.554   |
|    critic_loss     | 0.0073   |
|    ent_coef        | 0.00101  |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 540088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 44       |
|    time_elapsed    | 12391    |
|    total_timesteps | 552089   |
| train/             |          |
|    actor_loss      | -0.559   |
|    critic_loss     | 0.0146   |
|    ent_coef        | 0.00102  |
|    ent_coef_loss   | -1.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 542088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 44       |
|    time_elapsed    | 12425    |
|    total_timesteps | 554089   |
| train/             |          |
|    actor_loss      | -0.604   |
|    critic_loss     | 0.0139   |
|    ent_coef        | 0.00109  |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 544088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 44       |
|    time_elapsed    | 12460    |
|    total_timesteps | 556089   |
| train/             |          |
|    actor_loss      | -1.3     |
|    critic_loss     | 0.0169   |
|    ent_coef        | 0.0011   |
|    ent_coef_loss   | -0.747   |
|    learning_rate   | 0.0003   |
|    n_updates       | 546088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 44       |
|    time_elapsed    | 12492    |
|    total_timesteps | 558089   |
| train/             |          |
|    actor_loss      | -0.705   |
|    critic_loss     | 0.0327   |
|    ent_coef        | 0.00129  |
|    ent_coef_loss   | -0.942   |
|    learning_rate   | 0.0003   |
|    n_updates       | 548088   |
---------------------------------
Eval num_timesteps=560000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -0.636   |
|    critic_loss     | 0.0157   |
|    ent_coef        | 0.00142  |
|    ent_coef_loss   | -0.222   |
|    learning_rate   | 0.0003   |
|    n_updates       | 549999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 44       |
|    time_elapsed    | 12578    |
|    total_timesteps | 560089   |
| train/             |          |
|    actor_loss      | -1.1     |
|    critic_loss     | 0.0281   |
|    ent_coef        | 0.00142  |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 550088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 44       |
|    time_elapsed    | 12614    |
|    total_timesteps | 562089   |
| train/             |          |
|    actor_loss      | -1.33    |
|    critic_loss     | 0.0405   |
|    ent_coef        | 0.00144  |
|    ent_coef_loss   | 3.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 552088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 44       |
|    time_elapsed    | 12647    |
|    total_timesteps | 564089   |
| train/             |          |
|    actor_loss      | -0.856   |
|    critic_loss     | 0.0349   |
|    ent_coef        | 0.00152  |
|    ent_coef_loss   | 5.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 554088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 44       |
|    time_elapsed    | 12681    |
|    total_timesteps | 566089   |
| train/             |          |
|    actor_loss      | -0.981   |
|    critic_loss     | 0.0314   |
|    ent_coef        | 0.00159  |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 556088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 44       |
|    time_elapsed    | 12715    |
|    total_timesteps | 568089   |
| train/             |          |
|    actor_loss      | -1.11    |
|    critic_loss     | 0.0508   |
|    ent_coef        | 0.00168  |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 558088   |
---------------------------------
Eval num_timesteps=570000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -1.19    |
|    critic_loss     | 0.0312   |
|    ent_coef        | 0.00184  |
|    ent_coef_loss   | -0.773   |
|    learning_rate   | 0.0003   |
|    n_updates       | 559999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 44       |
|    time_elapsed    | 12806    |
|    total_timesteps | 570089   |
| train/             |          |
|    actor_loss      | -0.453   |
|    critic_loss     | 0.0226   |
|    ent_coef        | 0.00183  |
|    ent_coef_loss   | -3.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 560088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 44       |
|    time_elapsed    | 12842    |
|    total_timesteps | 572089   |
| train/             |          |
|    actor_loss      | -2.04    |
|    critic_loss     | 0.186    |
|    ent_coef        | 0.00189  |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 562088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 44       |
|    time_elapsed    | 12875    |
|    total_timesteps | 574089   |
| train/             |          |
|    actor_loss      | -1.58    |
|    critic_loss     | 0.0704   |
|    ent_coef        | 0.00224  |
|    ent_coef_loss   | 0.701    |
|    learning_rate   | 0.0003   |
|    n_updates       | 564088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 44       |
|    time_elapsed    | 12909    |
|    total_timesteps | 576089   |
| train/             |          |
|    actor_loss      | -0.694   |
|    critic_loss     | 1.29     |
|    ent_coef        | 0.00234  |
|    ent_coef_loss   | -3.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 566088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 44       |
|    time_elapsed    | 12942    |
|    total_timesteps | 578089   |
| train/             |          |
|    actor_loss      | -1.27    |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.00234  |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 568088   |
---------------------------------
Eval num_timesteps=580000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -2.33    |
|    critic_loss     | 0.0656   |
|    ent_coef        | 0.00231  |
|    ent_coef_loss   | -0.683   |
|    learning_rate   | 0.0003   |
|    n_updates       | 569999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 44       |
|    time_elapsed    | 13030    |
|    total_timesteps | 580089   |
| train/             |          |
|    actor_loss      | -1.4     |
|    critic_loss     | 0.0677   |
|    ent_coef        | 0.00231  |
|    ent_coef_loss   | -0.399   |
|    learning_rate   | 0.0003   |
|    n_updates       | 570088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 44       |
|    time_elapsed    | 13063    |
|    total_timesteps | 582089   |
| train/             |          |
|    actor_loss      | -1.67    |
|    critic_loss     | 0.0643   |
|    ent_coef        | 0.00247  |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 572088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 44       |
|    time_elapsed    | 13097    |
|    total_timesteps | 584089   |
| train/             |          |
|    actor_loss      | -1.31    |
|    critic_loss     | 0.0503   |
|    ent_coef        | 0.00255  |
|    ent_coef_loss   | -3.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 574088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 44       |
|    time_elapsed    | 13134    |
|    total_timesteps | 586089   |
| train/             |          |
|    actor_loss      | -2.34    |
|    critic_loss     | 0.0641   |
|    ent_coef        | 0.00275  |
|    ent_coef_loss   | 0.214    |
|    learning_rate   | 0.0003   |
|    n_updates       | 576088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 44       |
|    time_elapsed    | 13167    |
|    total_timesteps | 588089   |
| train/             |          |
|    actor_loss      | -2.15    |
|    critic_loss     | 0.408    |
|    ent_coef        | 0.00301  |
|    ent_coef_loss   | -0.675   |
|    learning_rate   | 0.0003   |
|    n_updates       | 578088   |
---------------------------------
Eval num_timesteps=590000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -2.28    |
|    critic_loss     | 0.24     |
|    ent_coef        | 0.00311  |
|    ent_coef_loss   | 0.519    |
|    learning_rate   | 0.0003   |
|    n_updates       | 579999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 44       |
|    time_elapsed    | 13253    |
|    total_timesteps | 590089   |
| train/             |          |
|    actor_loss      | -2.41    |
|    critic_loss     | 0.106    |
|    ent_coef        | 0.00322  |
|    ent_coef_loss   | 2.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 580088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 44       |
|    time_elapsed    | 13287    |
|    total_timesteps | 592089   |
| train/             |          |
|    actor_loss      | -2.48    |
|    critic_loss     | 0.128    |
|    ent_coef        | 0.00304  |
|    ent_coef_loss   | -0.705   |
|    learning_rate   | 0.0003   |
|    n_updates       | 582088   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 497      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 44       |
|    time_elapsed    | 13317    |
|    total_timesteps | 593763   |
| train/             |          |
|    actor_loss      | -2.21    |
|    critic_loss     | 0.0875   |
|    ent_coef        | 0.00338  |
|    ent_coef_loss   | -0.749   |
|    learning_rate   | 0.0003   |
|    n_updates       | 583762   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 497      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 44       |
|    time_elapsed    | 13350    |
|    total_timesteps | 595763   |
| train/             |          |
|    actor_loss      | -2.74    |
|    critic_loss     | 0.179    |
|    ent_coef        | 0.00385  |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 585762   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 44       |
|    time_elapsed    | 13378    |
|    total_timesteps | 597280   |
| train/             |          |
|    actor_loss      | -3.3     |
|    critic_loss     | 0.103    |
|    ent_coef        | 0.00368  |
|    ent_coef_loss   | -0.441   |
|    learning_rate   | 0.0003   |
|    n_updates       | 587279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 44       |
|    time_elapsed    | 13411    |
|    total_timesteps | 599280   |
| train/             |          |
|    actor_loss      | -2.8     |
|    critic_loss     | 0.19     |
|    ent_coef        | 0.00376  |
|    ent_coef_loss   | 1.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 589279   |
---------------------------------
Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -4.42    |
|    critic_loss     | 0.309    |
|    ent_coef        | 0.00379  |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 0.0003   |
|    n_updates       | 589999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 44       |
|    time_elapsed    | 13502    |
|    total_timesteps | 601280   |
| train/             |          |
|    actor_loss      | -4.85    |
|    critic_loss     | 0.262    |
|    ent_coef        | 0.00402  |
|    ent_coef_loss   | -0.666   |
|    learning_rate   | 0.0003   |
|    n_updates       | 591279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 44       |
|    time_elapsed    | 13534    |
|    total_timesteps | 603280   |
| train/             |          |
|    actor_loss      | -2.11    |
|    critic_loss     | 0.228    |
|    ent_coef        | 0.00393  |
|    ent_coef_loss   | -2.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 593279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 44       |
|    time_elapsed    | 13571    |
|    total_timesteps | 605280   |
| train/             |          |
|    actor_loss      | -4.04    |
|    critic_loss     | 0.333    |
|    ent_coef        | 0.00437  |
|    ent_coef_loss   | 3.22     |
|    learning_rate   | 0.0003   |
|    n_updates       | 595279   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 44       |
|    time_elapsed    | 13603    |
|    total_timesteps | 607222   |
| train/             |          |
|    actor_loss      | -6.01    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.00496  |
|    ent_coef_loss   | 4.96     |
|    learning_rate   | 0.0003   |
|    n_updates       | 597221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 44       |
|    time_elapsed    | 13636    |
|    total_timesteps | 609222   |
| train/             |          |
|    actor_loss      | -3.66    |
|    critic_loss     | 9.79     |
|    ent_coef        | 0.00499  |
|    ent_coef_loss   | 0.501    |
|    learning_rate   | 0.0003   |
|    n_updates       | 599221   |
---------------------------------
Eval num_timesteps=610000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -3.2     |
|    critic_loss     | 0.214    |
|    ent_coef        | 0.00501  |
|    ent_coef_loss   | 0.928    |
|    learning_rate   | 0.0003   |
|    n_updates       | 599999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 44       |
|    time_elapsed    | 13727    |
|    total_timesteps | 611222   |
| train/             |          |
|    actor_loss      | -3.92    |
|    critic_loss     | 0.287    |
|    ent_coef        | 0.00553  |
|    ent_coef_loss   | 2.54     |
|    learning_rate   | 0.0003   |
|    n_updates       | 601221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 44       |
|    time_elapsed    | 13763    |
|    total_timesteps | 613222   |
| train/             |          |
|    actor_loss      | -5.01    |
|    critic_loss     | 0.989    |
|    ent_coef        | 0.00556  |
|    ent_coef_loss   | 0.763    |
|    learning_rate   | 0.0003   |
|    n_updates       | 603221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 44       |
|    time_elapsed    | 13798    |
|    total_timesteps | 615222   |
| train/             |          |
|    actor_loss      | -2.89    |
|    critic_loss     | 0.248    |
|    ent_coef        | 0.0058   |
|    ent_coef_loss   | 0.506    |
|    learning_rate   | 0.0003   |
|    n_updates       | 605221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 44       |
|    time_elapsed    | 13831    |
|    total_timesteps | 617222   |
| train/             |          |
|    actor_loss      | -4.81    |
|    critic_loss     | 0.344    |
|    ent_coef        | 0.00615  |
|    ent_coef_loss   | -0.0224  |
|    learning_rate   | 0.0003   |
|    n_updates       | 607221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 44       |
|    time_elapsed    | 13866    |
|    total_timesteps | 619222   |
| train/             |          |
|    actor_loss      | -5.21    |
|    critic_loss     | 0.35     |
|    ent_coef        | 0.00661  |
|    ent_coef_loss   | -0.00508 |
|    learning_rate   | 0.0003   |
|    n_updates       | 609221   |
---------------------------------
Eval num_timesteps=620000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -5.82    |
|    critic_loss     | 0.519    |
|    ent_coef        | 0.00673  |
|    ent_coef_loss   | -0.334   |
|    learning_rate   | 0.0003   |
|    n_updates       | 609999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 44       |
|    time_elapsed    | 13965    |
|    total_timesteps | 621222   |
| train/             |          |
|    actor_loss      | -5.59    |
|    critic_loss     | 0.618    |
|    ent_coef        | 0.00703  |
|    ent_coef_loss   | 0.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 611221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 44       |
|    time_elapsed    | 14001    |
|    total_timesteps | 623222   |
| train/             |          |
|    actor_loss      | -4.84    |
|    critic_loss     | 2.12     |
|    ent_coef        | 0.008    |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 613221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 44       |
|    time_elapsed    | 14036    |
|    total_timesteps | 625222   |
| train/             |          |
|    actor_loss      | -5.73    |
|    critic_loss     | 0.527    |
|    ent_coef        | 0.00797  |
|    ent_coef_loss   | 0.00908  |
|    learning_rate   | 0.0003   |
|    n_updates       | 615221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 44       |
|    time_elapsed    | 14069    |
|    total_timesteps | 627222   |
| train/             |          |
|    actor_loss      | -4.26    |
|    critic_loss     | 0.509    |
|    ent_coef        | 0.00865  |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 617221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 44       |
|    time_elapsed    | 14105    |
|    total_timesteps | 629222   |
| train/             |          |
|    actor_loss      | -6.5     |
|    critic_loss     | 0.574    |
|    ent_coef        | 0.00807  |
|    ent_coef_loss   | -0.361   |
|    learning_rate   | 0.0003   |
|    n_updates       | 619221   |
---------------------------------
Eval num_timesteps=630000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -8.66    |
|    critic_loss     | 7.67     |
|    ent_coef        | 0.00786  |
|    ent_coef_loss   | 5.05     |
|    learning_rate   | 0.0003   |
|    n_updates       | 619999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 44       |
|    time_elapsed    | 14193    |
|    total_timesteps | 631222   |
| train/             |          |
|    actor_loss      | -10.8    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.00812  |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 621221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 44       |
|    time_elapsed    | 14226    |
|    total_timesteps | 633222   |
| train/             |          |
|    actor_loss      | -6.85    |
|    critic_loss     | 0.587    |
|    ent_coef        | 0.00801  |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 623221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 44       |
|    time_elapsed    | 14261    |
|    total_timesteps | 635222   |
| train/             |          |
|    actor_loss      | -5.81    |
|    critic_loss     | 0.525    |
|    ent_coef        | 0.00774  |
|    ent_coef_loss   | 2.84     |
|    learning_rate   | 0.0003   |
|    n_updates       | 625221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 44       |
|    time_elapsed    | 14298    |
|    total_timesteps | 637222   |
| train/             |          |
|    actor_loss      | -8.96    |
|    critic_loss     | 0.97     |
|    ent_coef        | 0.00768  |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 627221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 44       |
|    time_elapsed    | 14330    |
|    total_timesteps | 639222   |
| train/             |          |
|    actor_loss      | -6.45    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.00737  |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 0.0003   |
|    n_updates       | 629221   |
---------------------------------
Eval num_timesteps=640000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -6.73    |
|    critic_loss     | 0.469    |
|    ent_coef        | 0.00777  |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 0.0003   |
|    n_updates       | 629999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 44       |
|    time_elapsed    | 14414    |
|    total_timesteps | 641222   |
| train/             |          |
|    actor_loss      | -7.36    |
|    critic_loss     | 0.71     |
|    ent_coef        | 0.007    |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 631221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 44       |
|    time_elapsed    | 14445    |
|    total_timesteps | 643222   |
| train/             |          |
|    actor_loss      | -5.46    |
|    critic_loss     | 0.361    |
|    ent_coef        | 0.00733  |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 633221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 44       |
|    time_elapsed    | 14482    |
|    total_timesteps | 645222   |
| train/             |          |
|    actor_loss      | -5.6     |
|    critic_loss     | 0.498    |
|    ent_coef        | 0.00742  |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 635221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 44       |
|    time_elapsed    | 14513    |
|    total_timesteps | 647222   |
| train/             |          |
|    actor_loss      | -7.87    |
|    critic_loss     | 0.702    |
|    ent_coef        | 0.00716  |
|    ent_coef_loss   | 0.528    |
|    learning_rate   | 0.0003   |
|    n_updates       | 637221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 44       |
|    time_elapsed    | 14544    |
|    total_timesteps | 649222   |
| train/             |          |
|    actor_loss      | -5.52    |
|    critic_loss     | 0.288    |
|    ent_coef        | 0.00708  |
|    ent_coef_loss   | -0.807   |
|    learning_rate   | 0.0003   |
|    n_updates       | 639221   |
---------------------------------
Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -3.97    |
|    critic_loss     | 0.399    |
|    ent_coef        | 0.00691  |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 639999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 44       |
|    time_elapsed    | 14629    |
|    total_timesteps | 651222   |
| train/             |          |
|    actor_loss      | -4.81    |
|    critic_loss     | 0.377    |
|    ent_coef        | 0.00728  |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 641221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 44       |
|    time_elapsed    | 14663    |
|    total_timesteps | 653222   |
| train/             |          |
|    actor_loss      | -4.2     |
|    critic_loss     | 0.347    |
|    ent_coef        | 0.00719  |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 643221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 44       |
|    time_elapsed    | 14697    |
|    total_timesteps | 655222   |
| train/             |          |
|    actor_loss      | -8.92    |
|    critic_loss     | 0.428    |
|    ent_coef        | 0.00731  |
|    ent_coef_loss   | 1.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 645221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 44       |
|    time_elapsed    | 14732    |
|    total_timesteps | 657222   |
| train/             |          |
|    actor_loss      | -4.87    |
|    critic_loss     | 0.386    |
|    ent_coef        | 0.00732  |
|    ent_coef_loss   | -0.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 647221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 44       |
|    time_elapsed    | 14765    |
|    total_timesteps | 659222   |
| train/             |          |
|    actor_loss      | -7.16    |
|    critic_loss     | 0.524    |
|    ent_coef        | 0.00687  |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 649221   |
---------------------------------
Eval num_timesteps=660000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -5.62    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.00703  |
|    ent_coef_loss   | 0.884    |
|    learning_rate   | 0.0003   |
|    n_updates       | 649999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 44       |
|    time_elapsed    | 14852    |
|    total_timesteps | 661222   |
| train/             |          |
|    actor_loss      | -6.47    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.0068   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 651221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 44       |
|    time_elapsed    | 14887    |
|    total_timesteps | 663222   |
| train/             |          |
|    actor_loss      | -6.03    |
|    critic_loss     | 0.419    |
|    ent_coef        | 0.00675  |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 653221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 44       |
|    time_elapsed    | 14920    |
|    total_timesteps | 665222   |
| train/             |          |
|    actor_loss      | -5.03    |
|    critic_loss     | 0.337    |
|    ent_coef        | 0.00705  |
|    ent_coef_loss   | 0.684    |
|    learning_rate   | 0.0003   |
|    n_updates       | 655221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 44       |
|    time_elapsed    | 14955    |
|    total_timesteps | 667222   |
| train/             |          |
|    actor_loss      | -5.32    |
|    critic_loss     | 0.462    |
|    ent_coef        | 0.00679  |
|    ent_coef_loss   | -0.0601  |
|    learning_rate   | 0.0003   |
|    n_updates       | 657221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 44       |
|    time_elapsed    | 14987    |
|    total_timesteps | 669222   |
| train/             |          |
|    actor_loss      | -3.93    |
|    critic_loss     | 0.373    |
|    ent_coef        | 0.00647  |
|    ent_coef_loss   | 0.605    |
|    learning_rate   | 0.0003   |
|    n_updates       | 659221   |
---------------------------------
{'grasped(cube2)': True}
Eval num_timesteps=670000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -4.03    |
|    critic_loss     | 0.497    |
|    ent_coef        | 0.00628  |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 659999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 44       |
|    time_elapsed    | 15074    |
|    total_timesteps | 670770   |
| train/             |          |
|    actor_loss      | -3.1     |
|    critic_loss     | 0.334    |
|    ent_coef        | 0.00622  |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 660769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 44       |
|    time_elapsed    | 15107    |
|    total_timesteps | 672770   |
| train/             |          |
|    actor_loss      | -4.6     |
|    critic_loss     | 0.536    |
|    ent_coef        | 0.0069   |
|    ent_coef_loss   | -0.524   |
|    learning_rate   | 0.0003   |
|    n_updates       | 662769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 44       |
|    time_elapsed    | 15140    |
|    total_timesteps | 674770   |
| train/             |          |
|    actor_loss      | -5.54    |
|    critic_loss     | 0.477    |
|    ent_coef        | 0.00657  |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 664769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 44       |
|    time_elapsed    | 15171    |
|    total_timesteps | 676770   |
| train/             |          |
|    actor_loss      | -4.32    |
|    critic_loss     | 0.643    |
|    ent_coef        | 0.00622  |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 0.0003   |
|    n_updates       | 666769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 44       |
|    time_elapsed    | 15203    |
|    total_timesteps | 678770   |
| train/             |          |
|    actor_loss      | -5.22    |
|    critic_loss     | 1.87     |
|    ent_coef        | 0.00665  |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 668769   |
---------------------------------
{'grasped(cube1)': True}
Eval num_timesteps=680000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -2.64    |
|    critic_loss     | 0.316    |
|    ent_coef        | 0.00648  |
|    ent_coef_loss   | 2.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 669999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 44       |
|    time_elapsed    | 15290    |
|    total_timesteps | 680328   |
| train/             |          |
|    actor_loss      | -4.14    |
|    critic_loss     | 0.407    |
|    ent_coef        | 0.00639  |
|    ent_coef_loss   | -0.144   |
|    learning_rate   | 0.0003   |
|    n_updates       | 670327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 44       |
|    time_elapsed    | 15323    |
|    total_timesteps | 682328   |
| train/             |          |
|    actor_loss      | -3.22    |
|    critic_loss     | 1.22     |
|    ent_coef        | 0.00641  |
|    ent_coef_loss   | -2.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 672327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 44       |
|    time_elapsed    | 15356    |
|    total_timesteps | 684328   |
| train/             |          |
|    actor_loss      | -4.06    |
|    critic_loss     | 0.386    |
|    ent_coef        | 0.00633  |
|    ent_coef_loss   | -1.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 674327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 44       |
|    time_elapsed    | 15389    |
|    total_timesteps | 686328   |
| train/             |          |
|    actor_loss      | -4.88    |
|    critic_loss     | 1.09     |
|    ent_coef        | 0.00579  |
|    ent_coef_loss   | -0.118   |
|    learning_rate   | 0.0003   |
|    n_updates       | 676327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 44       |
|    time_elapsed    | 15423    |
|    total_timesteps | 688328   |
| train/             |          |
|    actor_loss      | -4.23    |
|    critic_loss     | 0.37     |
|    ent_coef        | 0.00597  |
|    ent_coef_loss   | 0.244    |
|    learning_rate   | 0.0003   |
|    n_updates       | 678327   |
---------------------------------
Eval num_timesteps=690000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -2.65    |
|    critic_loss     | 0.284    |
|    ent_coef        | 0.00624  |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 679999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 44       |
|    time_elapsed    | 15515    |
|    total_timesteps | 690328   |
| train/             |          |
|    actor_loss      | -2.11    |
|    critic_loss     | 0.378    |
|    ent_coef        | 0.00622  |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 680327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 44       |
|    time_elapsed    | 15551    |
|    total_timesteps | 692328   |
| train/             |          |
|    actor_loss      | -1.24    |
|    critic_loss     | 0.628    |
|    ent_coef        | 0.00613  |
|    ent_coef_loss   | 0.0124   |
|    learning_rate   | 0.0003   |
|    n_updates       | 682327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 44       |
|    time_elapsed    | 15583    |
|    total_timesteps | 694328   |
| train/             |          |
|    actor_loss      | -5.38    |
|    critic_loss     | 0.588    |
|    ent_coef        | 0.00583  |
|    ent_coef_loss   | -0.527   |
|    learning_rate   | 0.0003   |
|    n_updates       | 684327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 44       |
|    time_elapsed    | 15618    |
|    total_timesteps | 696328   |
| train/             |          |
|    actor_loss      | -3.78    |
|    critic_loss     | 0.587    |
|    ent_coef        | 0.00618  |
|    ent_coef_loss   | -1.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 686327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 44       |
|    time_elapsed    | 15652    |
|    total_timesteps | 698328   |
| train/             |          |
|    actor_loss      | -2.56    |
|    critic_loss     | 0.28     |
|    ent_coef        | 0.0065   |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 688327   |
---------------------------------
Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -5.77    |
|    critic_loss     | 0.886    |
|    ent_coef        | 0.00646  |
|    ent_coef_loss   | -0.363   |
|    learning_rate   | 0.0003   |
|    n_updates       | 689999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 44       |
|    time_elapsed    | 15737    |
|    total_timesteps | 700328   |
| train/             |          |
|    actor_loss      | -4.16    |
|    critic_loss     | 0.493    |
|    ent_coef        | 0.00657  |
|    ent_coef_loss   | 2.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 690327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 44       |
|    time_elapsed    | 15771    |
|    total_timesteps | 702328   |
| train/             |          |
|    actor_loss      | -1.85    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.00668  |
|    ent_coef_loss   | 0.505    |
|    learning_rate   | 0.0003   |
|    n_updates       | 692327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 44       |
|    time_elapsed    | 15807    |
|    total_timesteps | 704328   |
| train/             |          |
|    actor_loss      | -1.62    |
|    critic_loss     | 0.573    |
|    ent_coef        | 0.00634  |
|    ent_coef_loss   | -0.275   |
|    learning_rate   | 0.0003   |
|    n_updates       | 694327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 44       |
|    time_elapsed    | 15843    |
|    total_timesteps | 706328   |
| train/             |          |
|    actor_loss      | -1.57    |
|    critic_loss     | 0.295    |
|    ent_coef        | 0.00682  |
|    ent_coef_loss   | -1.88    |
|    learning_rate   | 0.0003   |
|    n_updates       | 696327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 44       |
|    time_elapsed    | 15877    |
|    total_timesteps | 708328   |
| train/             |          |
|    actor_loss      | -2.95    |
|    critic_loss     | 0.93     |
|    ent_coef        | 0.00713  |
|    ent_coef_loss   | 2.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 698327   |
---------------------------------
Eval num_timesteps=710000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -3.08    |
|    critic_loss     | 9.5      |
|    ent_coef        | 0.00739  |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 699999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 44       |
|    time_elapsed    | 15971    |
|    total_timesteps | 710328   |
| train/             |          |
|    actor_loss      | -4.33    |
|    critic_loss     | 2.03     |
|    ent_coef        | 0.00744  |
|    ent_coef_loss   | -0.179   |
|    learning_rate   | 0.0003   |
|    n_updates       | 700327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 44       |
|    time_elapsed    | 16002    |
|    total_timesteps | 712328   |
| train/             |          |
|    actor_loss      | -4.04    |
|    critic_loss     | 0.64     |
|    ent_coef        | 0.00771  |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 702327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 44       |
|    time_elapsed    | 16037    |
|    total_timesteps | 714328   |
| train/             |          |
|    actor_loss      | -1.41    |
|    critic_loss     | 0.461    |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 704327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 44       |
|    time_elapsed    | 16071    |
|    total_timesteps | 716328   |
| train/             |          |
|    actor_loss      | -3.37    |
|    critic_loss     | 1.04     |
|    ent_coef        | 0.00785  |
|    ent_coef_loss   | 0.301    |
|    learning_rate   | 0.0003   |
|    n_updates       | 706327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 44       |
|    time_elapsed    | 16105    |
|    total_timesteps | 718328   |
| train/             |          |
|    actor_loss      | -4.52    |
|    critic_loss     | 0.466    |
|    ent_coef        | 0.00832  |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 708327   |
---------------------------------
Eval num_timesteps=720000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -5.8     |
|    critic_loss     | 0.781    |
|    ent_coef        | 0.00822  |
|    ent_coef_loss   | 1.82     |
|    learning_rate   | 0.0003   |
|    n_updates       | 709999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 44       |
|    time_elapsed    | 16196    |
|    total_timesteps | 720328   |
| train/             |          |
|    actor_loss      | -3.2     |
|    critic_loss     | 0.465    |
|    ent_coef        | 0.00809  |
|    ent_coef_loss   | -1.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 710327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 44       |
|    time_elapsed    | 16230    |
|    total_timesteps | 722328   |
| train/             |          |
|    actor_loss      | -6.04    |
|    critic_loss     | 1.28     |
|    ent_coef        | 0.0081   |
|    ent_coef_loss   | 0.899    |
|    learning_rate   | 0.0003   |
|    n_updates       | 712327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 44       |
|    time_elapsed    | 16263    |
|    total_timesteps | 724328   |
| train/             |          |
|    actor_loss      | -4.19    |
|    critic_loss     | 0.456    |
|    ent_coef        | 0.00789  |
|    ent_coef_loss   | 0.859    |
|    learning_rate   | 0.0003   |
|    n_updates       | 714327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 44       |
|    time_elapsed    | 16298    |
|    total_timesteps | 726328   |
| train/             |          |
|    actor_loss      | -4.14    |
|    critic_loss     | 0.965    |
|    ent_coef        | 0.00807  |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 716327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 44       |
|    time_elapsed    | 16332    |
|    total_timesteps | 728328   |
| train/             |          |
|    actor_loss      | -3.52    |
|    critic_loss     | 0.675    |
|    ent_coef        | 0.00837  |
|    ent_coef_loss   | -2.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 718327   |
---------------------------------
{'grasped(cube2)': True}
Eval num_timesteps=730000, episode_reward=0.10 +/- 0.30
Episode length: 459.80 +/- 120.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -5.77    |
|    critic_loss     | 1.94     |
|    ent_coef        | 0.00906  |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 719999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 44       |
|    time_elapsed    | 16417    |
|    total_timesteps | 730328   |
| train/             |          |
|    actor_loss      | -7.48    |
|    critic_loss     | 1.22     |
|    ent_coef        | 0.00868  |
|    ent_coef_loss   | 0.154    |
|    learning_rate   | 0.0003   |
|    n_updates       | 720327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 44       |
|    time_elapsed    | 16451    |
|    total_timesteps | 732328   |
| train/             |          |
|    actor_loss      | -5.62    |
|    critic_loss     | 1.26     |
|    ent_coef        | 0.00817  |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 0.0003   |
|    n_updates       | 722327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 44       |
|    time_elapsed    | 16486    |
|    total_timesteps | 734328   |
| train/             |          |
|    actor_loss      | -7.23    |
|    critic_loss     | 0.671    |
|    ent_coef        | 0.00804  |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 724327   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 44       |
|    time_elapsed    | 16515    |
|    total_timesteps | 735967   |
| train/             |          |
|    actor_loss      | -9.52    |
|    critic_loss     | 1.48     |
|    ent_coef        | 0.00819  |
|    ent_coef_loss   | 0.834    |
|    learning_rate   | 0.0003   |
|    n_updates       | 725966   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 44       |
|    time_elapsed    | 16550    |
|    total_timesteps | 737967   |
| train/             |          |
|    actor_loss      | -2.72    |
|    critic_loss     | 0.492    |
|    ent_coef        | 0.00822  |
|    ent_coef_loss   | -0.945   |
|    learning_rate   | 0.0003   |
|    n_updates       | 727966   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 44       |
|    time_elapsed    | 16581    |
|    total_timesteps | 739841   |
| train/             |          |
|    actor_loss      | -5.85    |
|    critic_loss     | 2.02     |
|    ent_coef        | 0.0086   |
|    ent_coef_loss   | -0.883   |
|    learning_rate   | 0.0003   |
|    n_updates       | 729840   |
---------------------------------
Eval num_timesteps=740000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -2.9     |
|    critic_loss     | 0.522    |
|    ent_coef        | 0.00851  |
|    ent_coef_loss   | -0.871   |
|    learning_rate   | 0.0003   |
|    n_updates       | 729999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 44       |
|    time_elapsed    | 16672    |
|    total_timesteps | 741841   |
| train/             |          |
|    actor_loss      | -7.18    |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 0.256    |
|    learning_rate   | 0.0003   |
|    n_updates       | 731840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 44       |
|    time_elapsed    | 16705    |
|    total_timesteps | 743841   |
| train/             |          |
|    actor_loss      | -3.71    |
|    critic_loss     | 0.827    |
|    ent_coef        | 0.00877  |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 733840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 44       |
|    time_elapsed    | 16740    |
|    total_timesteps | 745841   |
| train/             |          |
|    actor_loss      | -6.11    |
|    critic_loss     | 1.32     |
|    ent_coef        | 0.00867  |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 735840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 44       |
|    time_elapsed    | 16776    |
|    total_timesteps | 747841   |
| train/             |          |
|    actor_loss      | -5.19    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.00876  |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 737840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 44       |
|    time_elapsed    | 16809    |
|    total_timesteps | 749841   |
| train/             |          |
|    actor_loss      | -7.31    |
|    critic_loss     | 2.15     |
|    ent_coef        | 0.00897  |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 739840   |
---------------------------------
Eval num_timesteps=750000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -5.44    |
|    critic_loss     | 0.554    |
|    ent_coef        | 0.009    |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 739999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 44       |
|    time_elapsed    | 16898    |
|    total_timesteps | 751841   |
| train/             |          |
|    actor_loss      | -7.54    |
|    critic_loss     | 0.686    |
|    ent_coef        | 0.00905  |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 741840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 44       |
|    time_elapsed    | 16932    |
|    total_timesteps | 753841   |
| train/             |          |
|    actor_loss      | -4.53    |
|    critic_loss     | 0.82     |
|    ent_coef        | 0.00937  |
|    ent_coef_loss   | -0.294   |
|    learning_rate   | 0.0003   |
|    n_updates       | 743840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 44       |
|    time_elapsed    | 16965    |
|    total_timesteps | 755841   |
| train/             |          |
|    actor_loss      | -4.64    |
|    critic_loss     | 1.16     |
|    ent_coef        | 0.00949  |
|    ent_coef_loss   | -0.901   |
|    learning_rate   | 0.0003   |
|    n_updates       | 745840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 44       |
|    time_elapsed    | 17002    |
|    total_timesteps | 757841   |
| train/             |          |
|    actor_loss      | -8.89    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.00947  |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 747840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 44       |
|    time_elapsed    | 17036    |
|    total_timesteps | 759841   |
| train/             |          |
|    actor_loss      | -2.38    |
|    critic_loss     | 0.692    |
|    ent_coef        | 0.00946  |
|    ent_coef_loss   | -0.657   |
|    learning_rate   | 0.0003   |
|    n_updates       | 749840   |
---------------------------------
Eval num_timesteps=760000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -5.19    |
|    critic_loss     | 0.808    |
|    ent_coef        | 0.00944  |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 749999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 44       |
|    time_elapsed    | 17127    |
|    total_timesteps | 761841   |
| train/             |          |
|    actor_loss      | -4.14    |
|    critic_loss     | 1.36     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | 0.949    |
|    learning_rate   | 0.0003   |
|    n_updates       | 751840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 44       |
|    time_elapsed    | 17162    |
|    total_timesteps | 763841   |
| train/             |          |
|    actor_loss      | -3.92    |
|    critic_loss     | 0.753    |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 753840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 44       |
|    time_elapsed    | 17195    |
|    total_timesteps | 765841   |
| train/             |          |
|    actor_loss      | -3.59    |
|    critic_loss     | 1.09     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 755840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 44       |
|    time_elapsed    | 17232    |
|    total_timesteps | 767841   |
| train/             |          |
|    actor_loss      | -3.15    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -0.205   |
|    learning_rate   | 0.0003   |
|    n_updates       | 757840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 44       |
|    time_elapsed    | 17265    |
|    total_timesteps | 769841   |
| train/             |          |
|    actor_loss      | -3.5     |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 759840   |
---------------------------------
Eval num_timesteps=770000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -3       |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.763   |
|    learning_rate   | 0.0003   |
|    n_updates       | 759999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 44       |
|    time_elapsed    | 17355    |
|    total_timesteps | 771841   |
| train/             |          |
|    actor_loss      | -7.38    |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 1.72     |
|    learning_rate   | 0.0003   |
|    n_updates       | 761840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 44       |
|    time_elapsed    | 17392    |
|    total_timesteps | 773841   |
| train/             |          |
|    actor_loss      | -4.55    |
|    critic_loss     | 1.71     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -0.396   |
|    learning_rate   | 0.0003   |
|    n_updates       | 763840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 44       |
|    time_elapsed    | 17426    |
|    total_timesteps | 775841   |
| train/             |          |
|    actor_loss      | -11.6    |
|    critic_loss     | 5.97     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 1.91     |
|    learning_rate   | 0.0003   |
|    n_updates       | 765840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 44       |
|    time_elapsed    | 17460    |
|    total_timesteps | 777841   |
| train/             |          |
|    actor_loss      | -5.92    |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 0.0003   |
|    n_updates       | 767840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 44       |
|    time_elapsed    | 17493    |
|    total_timesteps | 779841   |
| train/             |          |
|    actor_loss      | -5.13    |
|    critic_loss     | 1.2      |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 1.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 769840   |
---------------------------------
Eval num_timesteps=780000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -3.01    |
|    critic_loss     | 1.32     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 769999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 44       |
|    time_elapsed    | 17584    |
|    total_timesteps | 781841   |
| train/             |          |
|    actor_loss      | -7.15    |
|    critic_loss     | 2.3      |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 771840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 44       |
|    time_elapsed    | 17619    |
|    total_timesteps | 783841   |
| train/             |          |
|    actor_loss      | -8.77    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.268    |
|    learning_rate   | 0.0003   |
|    n_updates       | 773840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 44       |
|    time_elapsed    | 17656    |
|    total_timesteps | 785841   |
| train/             |          |
|    actor_loss      | -7.72    |
|    critic_loss     | 2.01     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 0.609    |
|    learning_rate   | 0.0003   |
|    n_updates       | 775840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 44       |
|    time_elapsed    | 17689    |
|    total_timesteps | 787841   |
| train/             |          |
|    actor_loss      | -6.16    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -0.513   |
|    learning_rate   | 0.0003   |
|    n_updates       | 777840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 44       |
|    time_elapsed    | 17724    |
|    total_timesteps | 789841   |
| train/             |          |
|    actor_loss      | -5.67    |
|    critic_loss     | 1.15     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 0.0003   |
|    n_updates       | 779840   |
---------------------------------
Eval num_timesteps=790000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -6.5     |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 0.789    |
|    learning_rate   | 0.0003   |
|    n_updates       | 779999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 44       |
|    time_elapsed    | 17820    |
|    total_timesteps | 791841   |
| train/             |          |
|    actor_loss      | -6.72    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -0.581   |
|    learning_rate   | 0.0003   |
|    n_updates       | 781840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 44       |
|    time_elapsed    | 17854    |
|    total_timesteps | 793841   |
| train/             |          |
|    actor_loss      | -6.52    |
|    critic_loss     | 2.88     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 0.336    |
|    learning_rate   | 0.0003   |
|    n_updates       | 783840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 44       |
|    time_elapsed    | 17886    |
|    total_timesteps | 795841   |
| train/             |          |
|    actor_loss      | -6.97    |
|    critic_loss     | 1.66     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 785840   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 44       |
|    time_elapsed    | 17921    |
|    total_timesteps | 797841   |
| train/             |          |
|    actor_loss      | -8.94    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 787840   |
---------------------------------
{'grasped(cube3)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 44       |
|    time_elapsed    | 17947    |
|    total_timesteps | 799403   |
| train/             |          |
|    actor_loss      | -9.77    |
|    critic_loss     | 1.93     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.101    |
|    learning_rate   | 0.0003   |
|    n_updates       | 789402   |
---------------------------------
{'grasped(cube1)': True}
Eval num_timesteps=800000, episode_reward=0.10 +/- 0.30
Episode length: 487.50 +/- 37.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -7.69    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 789999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 44       |
|    time_elapsed    | 18036    |
|    total_timesteps | 801403   |
| train/             |          |
|    actor_loss      | -12.2    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.863    |
|    learning_rate   | 0.0003   |
|    n_updates       | 791402   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 44       |
|    time_elapsed    | 18065    |
|    total_timesteps | 803038   |
| train/             |          |
|    actor_loss      | -12.6    |
|    critic_loss     | 8.03     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.651    |
|    learning_rate   | 0.0003   |
|    n_updates       | 793037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 44       |
|    time_elapsed    | 18097    |
|    total_timesteps | 805038   |
| train/             |          |
|    actor_loss      | -4.97    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 0.115    |
|    learning_rate   | 0.0003   |
|    n_updates       | 795037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 44       |
|    time_elapsed    | 18130    |
|    total_timesteps | 807038   |
| train/             |          |
|    actor_loss      | -11.9    |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 797037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 44       |
|    time_elapsed    | 18164    |
|    total_timesteps | 809038   |
| train/             |          |
|    actor_loss      | -8.78    |
|    critic_loss     | 6.43     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 3.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 799037   |
---------------------------------
Eval num_timesteps=810000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -19.7    |
|    critic_loss     | 8.47     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 799999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 44       |
|    time_elapsed    | 18253    |
|    total_timesteps | 811038   |
| train/             |          |
|    actor_loss      | -8.81    |
|    critic_loss     | 2.59     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.526    |
|    learning_rate   | 0.0003   |
|    n_updates       | 801037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 44       |
|    time_elapsed    | 18287    |
|    total_timesteps | 813038   |
| train/             |          |
|    actor_loss      | -11.8    |
|    critic_loss     | 21.5     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -0.568   |
|    learning_rate   | 0.0003   |
|    n_updates       | 803037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 44       |
|    time_elapsed    | 18321    |
|    total_timesteps | 815038   |
| train/             |          |
|    actor_loss      | -7.18    |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 805037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 44       |
|    time_elapsed    | 18352    |
|    total_timesteps | 817038   |
| train/             |          |
|    actor_loss      | -16.6    |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -0.389   |
|    learning_rate   | 0.0003   |
|    n_updates       | 807037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 44       |
|    time_elapsed    | 18385    |
|    total_timesteps | 819038   |
| train/             |          |
|    actor_loss      | -11.2    |
|    critic_loss     | 8.69     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.594    |
|    learning_rate   | 0.0003   |
|    n_updates       | 809037   |
---------------------------------
Eval num_timesteps=820000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -13.9    |
|    critic_loss     | 5.08     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 2.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 809999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 44       |
|    time_elapsed    | 18477    |
|    total_timesteps | 821038   |
| train/             |          |
|    actor_loss      | -6.6     |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 0.0003   |
|    n_updates       | 811037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 44       |
|    time_elapsed    | 18512    |
|    total_timesteps | 823038   |
| train/             |          |
|    actor_loss      | -7.52    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | -3.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 813037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 44       |
|    time_elapsed    | 18547    |
|    total_timesteps | 825038   |
| train/             |          |
|    actor_loss      | -19.4    |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 815037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 44       |
|    time_elapsed    | 18582    |
|    total_timesteps | 827038   |
| train/             |          |
|    actor_loss      | -18.9    |
|    critic_loss     | 9.39     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 817037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 44       |
|    time_elapsed    | 18618    |
|    total_timesteps | 829038   |
| train/             |          |
|    actor_loss      | -10.6    |
|    critic_loss     | 39.1     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | -2.61    |
|    learning_rate   | 0.0003   |
|    n_updates       | 819037   |
---------------------------------
Eval num_timesteps=830000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -18.4    |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -1.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 819999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 44       |
|    time_elapsed    | 18710    |
|    total_timesteps | 831038   |
| train/             |          |
|    actor_loss      | -11.2    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.0204   |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 821037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 44       |
|    time_elapsed    | 18743    |
|    total_timesteps | 833038   |
| train/             |          |
|    actor_loss      | -20      |
|    critic_loss     | 17.1     |
|    ent_coef        | 0.0214   |
|    ent_coef_loss   | -0.899   |
|    learning_rate   | 0.0003   |
|    n_updates       | 823037   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 44       |
|    time_elapsed    | 18772    |
|    total_timesteps | 834594   |
| train/             |          |
|    actor_loss      | -9.57    |
|    critic_loss     | 8.16     |
|    ent_coef        | 0.0218   |
|    ent_coef_loss   | 0.604    |
|    learning_rate   | 0.0003   |
|    n_updates       | 824593   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 44       |
|    time_elapsed    | 18807    |
|    total_timesteps | 836594   |
| train/             |          |
|    actor_loss      | -21      |
|    critic_loss     | 164      |
|    ent_coef        | 0.0218   |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 826593   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 44       |
|    time_elapsed    | 18844    |
|    total_timesteps | 838594   |
| train/             |          |
|    actor_loss      | -15.2    |
|    critic_loss     | 7.3      |
|    ent_coef        | 0.0225   |
|    ent_coef_loss   | 0.641    |
|    learning_rate   | 0.0003   |
|    n_updates       | 828593   |
---------------------------------
Eval num_timesteps=840000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -16.9    |
|    critic_loss     | 4.97     |
|    ent_coef        | 0.0219   |
|    ent_coef_loss   | 0.696    |
|    learning_rate   | 0.0003   |
|    n_updates       | 829999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 44       |
|    time_elapsed    | 18936    |
|    total_timesteps | 840594   |
| train/             |          |
|    actor_loss      | -25.6    |
|    critic_loss     | 9.5      |
|    ent_coef        | 0.0222   |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 0.0003   |
|    n_updates       | 830593   |
---------------------------------
{'grasped(cube2)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 44       |
|    time_elapsed    | 18965    |
|    total_timesteps | 842207   |
| train/             |          |
|    actor_loss      | -34.2    |
|    critic_loss     | 8.46     |
|    ent_coef        | 0.0239   |
|    ent_coef_loss   | 0.449    |
|    learning_rate   | 0.0003   |
|    n_updates       | 832206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 44       |
|    time_elapsed    | 18998    |
|    total_timesteps | 844207   |
| train/             |          |
|    actor_loss      | -33.6    |
|    critic_loss     | 8.09     |
|    ent_coef        | 0.0238   |
|    ent_coef_loss   | 0.895    |
|    learning_rate   | 0.0003   |
|    n_updates       | 834206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 44       |
|    time_elapsed    | 19031    |
|    total_timesteps | 846207   |
| train/             |          |
|    actor_loss      | -19.4    |
|    critic_loss     | 9.03     |
|    ent_coef        | 0.0246   |
|    ent_coef_loss   | 0.986    |
|    learning_rate   | 0.0003   |
|    n_updates       | 836206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 44       |
|    time_elapsed    | 19067    |
|    total_timesteps | 848207   |
| train/             |          |
|    actor_loss      | -31.9    |
|    critic_loss     | 6.9      |
|    ent_coef        | 0.0251   |
|    ent_coef_loss   | 0.993    |
|    learning_rate   | 0.0003   |
|    n_updates       | 838206   |
---------------------------------
Eval num_timesteps=850000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -18      |
|    critic_loss     | 5.79     |
|    ent_coef        | 0.0255   |
|    ent_coef_loss   | -0.847   |
|    learning_rate   | 0.0003   |
|    n_updates       | 839999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 44       |
|    time_elapsed    | 19155    |
|    total_timesteps | 850207   |
| train/             |          |
|    actor_loss      | -17.2    |
|    critic_loss     | 7.96     |
|    ent_coef        | 0.0256   |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 0.0003   |
|    n_updates       | 840206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 44       |
|    time_elapsed    | 19189    |
|    total_timesteps | 852207   |
| train/             |          |
|    actor_loss      | -26.5    |
|    critic_loss     | 11.7     |
|    ent_coef        | 0.0254   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 842206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 44       |
|    time_elapsed    | 19222    |
|    total_timesteps | 854207   |
| train/             |          |
|    actor_loss      | -22.4    |
|    critic_loss     | 22.8     |
|    ent_coef        | 0.0267   |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 844206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 44       |
|    time_elapsed    | 19258    |
|    total_timesteps | 856207   |
| train/             |          |
|    actor_loss      | -18.3    |
|    critic_loss     | 5.09     |
|    ent_coef        | 0.0265   |
|    ent_coef_loss   | 0.226    |
|    learning_rate   | 0.0003   |
|    n_updates       | 846206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 44       |
|    time_elapsed    | 19291    |
|    total_timesteps | 858207   |
| train/             |          |
|    actor_loss      | -20.9    |
|    critic_loss     | 7        |
|    ent_coef        | 0.0265   |
|    ent_coef_loss   | -0.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 848206   |
---------------------------------
Eval num_timesteps=860000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -17.4    |
|    critic_loss     | 19.6     |
|    ent_coef        | 0.0267   |
|    ent_coef_loss   | -0.646   |
|    learning_rate   | 0.0003   |
|    n_updates       | 849999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 44       |
|    time_elapsed    | 19375    |
|    total_timesteps | 860207   |
| train/             |          |
|    actor_loss      | -27      |
|    critic_loss     | 31.4     |
|    ent_coef        | 0.0263   |
|    ent_coef_loss   | 1.22     |
|    learning_rate   | 0.0003   |
|    n_updates       | 850206   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 44       |
|    time_elapsed    | 19405    |
|    total_timesteps | 861812   |
| train/             |          |
|    actor_loss      | -16.3    |
|    critic_loss     | 6.74     |
|    ent_coef        | 0.0256   |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 851811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 44       |
|    time_elapsed    | 19436    |
|    total_timesteps | 863812   |
| train/             |          |
|    actor_loss      | -30.3    |
|    critic_loss     | 8.25     |
|    ent_coef        | 0.0281   |
|    ent_coef_loss   | -0.993   |
|    learning_rate   | 0.0003   |
|    n_updates       | 853811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 44       |
|    time_elapsed    | 19470    |
|    total_timesteps | 865812   |
| train/             |          |
|    actor_loss      | -16.6    |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0274   |
|    ent_coef_loss   | -2.44    |
|    learning_rate   | 0.0003   |
|    n_updates       | 855811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 44       |
|    time_elapsed    | 19503    |
|    total_timesteps | 867812   |
| train/             |          |
|    actor_loss      | -30.1    |
|    critic_loss     | 32.5     |
|    ent_coef        | 0.0274   |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 857811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 44       |
|    time_elapsed    | 19538    |
|    total_timesteps | 869812   |
| train/             |          |
|    actor_loss      | -24.4    |
|    critic_loss     | 17.2     |
|    ent_coef        | 0.0283   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 859811   |
---------------------------------
Eval num_timesteps=870000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -50.6    |
|    critic_loss     | 30       |
|    ent_coef        | 0.028    |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 859999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 44       |
|    time_elapsed    | 19625    |
|    total_timesteps | 871812   |
| train/             |          |
|    actor_loss      | -22.3    |
|    critic_loss     | 63.4     |
|    ent_coef        | 0.0292   |
|    ent_coef_loss   | -0.921   |
|    learning_rate   | 0.0003   |
|    n_updates       | 861811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 44       |
|    time_elapsed    | 19661    |
|    total_timesteps | 873812   |
| train/             |          |
|    actor_loss      | -23.3    |
|    critic_loss     | 14.9     |
|    ent_coef        | 0.0294   |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 863811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 44       |
|    time_elapsed    | 19696    |
|    total_timesteps | 875812   |
| train/             |          |
|    actor_loss      | -39.8    |
|    critic_loss     | 74       |
|    ent_coef        | 0.0293   |
|    ent_coef_loss   | -0.591   |
|    learning_rate   | 0.0003   |
|    n_updates       | 865811   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 44       |
|    time_elapsed    | 19728    |
|    total_timesteps | 877812   |
| train/             |          |
|    actor_loss      | -19.6    |
|    critic_loss     | 13.7     |
|    ent_coef        | 0.0321   |
|    ent_coef_loss   | -0.722   |
|    learning_rate   | 0.0003   |
|    n_updates       | 867811   |
---------------------------------
{'grasped(cube1)': True}
{'grasped(cube3)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 44       |
|    time_elapsed    | 19754    |
|    total_timesteps | 879333   |
| train/             |          |
|    actor_loss      | -38.5    |
|    critic_loss     | 29.6     |
|    ent_coef        | 0.0318   |
|    ent_coef_loss   | 0.791    |
|    learning_rate   | 0.0003   |
|    n_updates       | 869332   |
---------------------------------
{'grasped(cube2)': True}
Eval num_timesteps=880000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | -20      |
|    critic_loss     | 19.5     |
|    ent_coef        | 0.0323   |
|    ent_coef_loss   | -0.808   |
|    learning_rate   | 0.0003   |
|    n_updates       | 869999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 44       |
|    time_elapsed    | 19841    |
|    total_timesteps | 881176   |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 38.2     |
|    ent_coef        | 0.031    |
|    ent_coef_loss   | 0.853    |
|    learning_rate   | 0.0003   |
|    n_updates       | 871175   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 44       |
|    time_elapsed    | 19868    |
|    total_timesteps | 882767   |
| train/             |          |
|    actor_loss      | -19.6    |
|    critic_loss     | 17.8     |
|    ent_coef        | 0.0327   |
|    ent_coef_loss   | 0.972    |
|    learning_rate   | 0.0003   |
|    n_updates       | 872766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 44       |
|    time_elapsed    | 19901    |
|    total_timesteps | 884767   |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 16.7     |
|    ent_coef        | 0.0336   |
|    ent_coef_loss   | -0.712   |
|    learning_rate   | 0.0003   |
|    n_updates       | 874766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 44       |
|    time_elapsed    | 19936    |
|    total_timesteps | 886767   |
| train/             |          |
|    actor_loss      | -22.5    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.0341   |
|    ent_coef_loss   | -0.254   |
|    learning_rate   | 0.0003   |
|    n_updates       | 876766   |
---------------------------------
{'grasped(cube1)': True}
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 44       |
|    time_elapsed    | 19957    |
|    total_timesteps | 887883   |
| train/             |          |
|    actor_loss      | -25.6    |
|    critic_loss     | 14       |
|    ent_coef        | 0.0344   |
|    ent_coef_loss   | -0.179   |
|    learning_rate   | 0.0003   |
|    n_updates       | 877882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 44       |
|    time_elapsed    | 19990    |
|    total_timesteps | 889883   |
| train/             |          |
|    actor_loss      | -23.6    |
|    critic_loss     | 11.6     |
|    ent_coef        | 0.0345   |
|    ent_coef_loss   | -0.428   |
|    learning_rate   | 0.0003   |
|    n_updates       | 879882   |
---------------------------------
Eval num_timesteps=890000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | -31.4    |
|    critic_loss     | 24.4     |
|    ent_coef        | 0.0342   |
|    ent_coef_loss   | -0.398   |
|    learning_rate   | 0.0003   |
|    n_updates       | 879999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 44       |
|    time_elapsed    | 20079    |
|    total_timesteps | 891883   |
| train/             |          |
|    actor_loss      | -34.9    |
|    critic_loss     | 22.2     |
|    ent_coef        | 0.0347   |
|    ent_coef_loss   | 0.645    |
|    learning_rate   | 0.0003   |
|    n_updates       | 881882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 44       |
|    time_elapsed    | 20112    |
|    total_timesteps | 893883   |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 4.12e+04 |
|    ent_coef        | 0.0359   |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 883882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 44       |
|    time_elapsed    | 20148    |
|    total_timesteps | 895883   |
| train/             |          |
|    actor_loss      | -40.1    |
|    critic_loss     | 22.3     |
|    ent_coef        | 0.0371   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 885882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 44       |
|    time_elapsed    | 20180    |
|    total_timesteps | 897883   |
| train/             |          |
|    actor_loss      | -25.3    |
|    critic_loss     | 32.6     |
|    ent_coef        | 0.0349   |
|    ent_coef_loss   | 0.844    |
|    learning_rate   | 0.0003   |
|    n_updates       | 887882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 44       |
|    time_elapsed    | 20212    |
|    total_timesteps | 899883   |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 42.5     |
|    ent_coef        | 0.0373   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 889882   |
---------------------------------
Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -31.5    |
|    critic_loss     | 155      |
|    ent_coef        | 0.037    |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 889999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 44       |
|    time_elapsed    | 20300    |
|    total_timesteps | 901883   |
| train/             |          |
|    actor_loss      | -33.1    |
|    critic_loss     | 140      |
|    ent_coef        | 0.0382   |
|    ent_coef_loss   | -0.373   |
|    learning_rate   | 0.0003   |
|    n_updates       | 891882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 44       |
|    time_elapsed    | 20332    |
|    total_timesteps | 903883   |
| train/             |          |
|    actor_loss      | -24.8    |
|    critic_loss     | 28.1     |
|    ent_coef        | 0.0372   |
|    ent_coef_loss   | 0.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 893882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 44       |
|    time_elapsed    | 20365    |
|    total_timesteps | 905883   |
| train/             |          |
|    actor_loss      | -25.2    |
|    critic_loss     | 18.3     |
|    ent_coef        | 0.0395   |
|    ent_coef_loss   | 0.326    |
|    learning_rate   | 0.0003   |
|    n_updates       | 895882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 44       |
|    time_elapsed    | 20399    |
|    total_timesteps | 907883   |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 19.9     |
|    ent_coef        | 0.0388   |
|    ent_coef_loss   | 0.954    |
|    learning_rate   | 0.0003   |
|    n_updates       | 897882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 44       |
|    time_elapsed    | 20435    |
|    total_timesteps | 909883   |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 30.5     |
|    ent_coef        | 0.039    |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 899882   |
---------------------------------
Eval num_timesteps=910000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | -27.1    |
|    critic_loss     | 38       |
|    ent_coef        | 0.0398   |
|    ent_coef_loss   | 0.481    |
|    learning_rate   | 0.0003   |
|    n_updates       | 899999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 44       |
|    time_elapsed    | 20527    |
|    total_timesteps | 911883   |
| train/             |          |
|    actor_loss      | -38.6    |
|    critic_loss     | 24.4     |
|    ent_coef        | 0.0407   |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 901882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 44       |
|    time_elapsed    | 20561    |
|    total_timesteps | 913883   |
| train/             |          |
|    actor_loss      | -46.4    |
|    critic_loss     | 31.2     |
|    ent_coef        | 0.0417   |
|    ent_coef_loss   | 0.674    |
|    learning_rate   | 0.0003   |
|    n_updates       | 903882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 44       |
|    time_elapsed    | 20595    |
|    total_timesteps | 915883   |
| train/             |          |
|    actor_loss      | -40.9    |
|    critic_loss     | 19       |
|    ent_coef        | 0.043    |
|    ent_coef_loss   | 0.181    |
|    learning_rate   | 0.0003   |
|    n_updates       | 905882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 44       |
|    time_elapsed    | 20628    |
|    total_timesteps | 917883   |
| train/             |          |
|    actor_loss      | -51.1    |
|    critic_loss     | 23.6     |
|    ent_coef        | 0.0433   |
|    ent_coef_loss   | 0.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 907882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 44       |
|    time_elapsed    | 20660    |
|    total_timesteps | 919883   |
| train/             |          |
|    actor_loss      | -39      |
|    critic_loss     | 22.1     |
|    ent_coef        | 0.0456   |
|    ent_coef_loss   | -0.613   |
|    learning_rate   | 0.0003   |
|    n_updates       | 909882   |
---------------------------------
Eval num_timesteps=920000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | -22.7    |
|    critic_loss     | 706      |
|    ent_coef        | 0.0453   |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 909999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 44       |
|    time_elapsed    | 20753    |
|    total_timesteps | 921883   |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 55.7     |
|    ent_coef        | 0.0455   |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 0.0003   |
|    n_updates       | 911882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 44       |
|    time_elapsed    | 20788    |
|    total_timesteps | 923883   |
| train/             |          |
|    actor_loss      | -38.3    |
|    critic_loss     | 301      |
|    ent_coef        | 0.0438   |
|    ent_coef_loss   | -0.649   |
|    learning_rate   | 0.0003   |
|    n_updates       | 913882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 44       |
|    time_elapsed    | 20820    |
|    total_timesteps | 925883   |
| train/             |          |
|    actor_loss      | -21.3    |
|    critic_loss     | 14.9     |
|    ent_coef        | 0.0453   |
|    ent_coef_loss   | -1.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 915882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 486      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 44       |
|    time_elapsed    | 20856    |
|    total_timesteps | 927883   |
| train/             |          |
|    actor_loss      | -28      |
|    critic_loss     | 46.9     |
|    ent_coef        | 0.0443   |
|    ent_coef_loss   | -0.671   |
|    learning_rate   | 0.0003   |
|    n_updates       | 917882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 44       |
|    time_elapsed    | 20890    |
|    total_timesteps | 929883   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 56.2     |
|    ent_coef        | 0.0446   |
|    ent_coef_loss   | 0.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 919882   |
---------------------------------
Eval num_timesteps=930000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | -19.2    |
|    critic_loss     | 25.7     |
|    ent_coef        | 0.0459   |
|    ent_coef_loss   | -0.502   |
|    learning_rate   | 0.0003   |
|    n_updates       | 919999   |
---------------------------------
{'grasped(cube3)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 44       |
|    time_elapsed    | 20975    |
|    total_timesteps | 931477   |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 28.4     |
|    ent_coef        | 0.0457   |
|    ent_coef_loss   | -0.285   |
|    learning_rate   | 0.0003   |
|    n_updates       | 921476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 44       |
|    time_elapsed    | 21009    |
|    total_timesteps | 933477   |
| train/             |          |
|    actor_loss      | -34.5    |
|    critic_loss     | 38.2     |
|    ent_coef        | 0.0467   |
|    ent_coef_loss   | -0.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 923476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 44       |
|    time_elapsed    | 21040    |
|    total_timesteps | 935477   |
| train/             |          |
|    actor_loss      | -32.8    |
|    critic_loss     | 22.5     |
|    ent_coef        | 0.0441   |
|    ent_coef_loss   | -0.0515  |
|    learning_rate   | 0.0003   |
|    n_updates       | 925476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 44       |
|    time_elapsed    | 21075    |
|    total_timesteps | 937477   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 83       |
|    ent_coef        | 0.0452   |
|    ent_coef_loss   | 1.59     |
|    learning_rate   | 0.0003   |
|    n_updates       | 927476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 44       |
|    time_elapsed    | 21108    |
|    total_timesteps | 939477   |
| train/             |          |
|    actor_loss      | -45.5    |
|    critic_loss     | 59.1     |
|    ent_coef        | 0.045    |
|    ent_coef_loss   | 0.951    |
|    learning_rate   | 0.0003   |
|    n_updates       | 929476   |
---------------------------------
Eval num_timesteps=940000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 25.9     |
|    ent_coef        | 0.0463   |
|    ent_coef_loss   | 0.249    |
|    learning_rate   | 0.0003   |
|    n_updates       | 929999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 44       |
|    time_elapsed    | 21203    |
|    total_timesteps | 941477   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 39.6     |
|    ent_coef        | 0.0489   |
|    ent_coef_loss   | 0.228    |
|    learning_rate   | 0.0003   |
|    n_updates       | 931476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 44       |
|    time_elapsed    | 21235    |
|    total_timesteps | 943477   |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 34.1     |
|    ent_coef        | 0.0493   |
|    ent_coef_loss   | 0.714    |
|    learning_rate   | 0.0003   |
|    n_updates       | 933476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 44       |
|    time_elapsed    | 21269    |
|    total_timesteps | 945477   |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 64.9     |
|    ent_coef        | 0.0477   |
|    ent_coef_loss   | -0.804   |
|    learning_rate   | 0.0003   |
|    n_updates       | 935476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 44       |
|    time_elapsed    | 21302    |
|    total_timesteps | 947477   |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 45.6     |
|    ent_coef        | 0.0477   |
|    ent_coef_loss   | 0.532    |
|    learning_rate   | 0.0003   |
|    n_updates       | 937476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 44       |
|    time_elapsed    | 21337    |
|    total_timesteps | 949477   |
| train/             |          |
|    actor_loss      | -89.2    |
|    critic_loss     | 77.2     |
|    ent_coef        | 0.0485   |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 939476   |
---------------------------------
Eval num_timesteps=950000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 43.2     |
|    ent_coef        | 0.0481   |
|    ent_coef_loss   | -0.402   |
|    learning_rate   | 0.0003   |
|    n_updates       | 939999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 44       |
|    time_elapsed    | 21425    |
|    total_timesteps | 951477   |
| train/             |          |
|    actor_loss      | -50.8    |
|    critic_loss     | 45.3     |
|    ent_coef        | 0.0516   |
|    ent_coef_loss   | -0.967   |
|    learning_rate   | 0.0003   |
|    n_updates       | 941476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 44       |
|    time_elapsed    | 21459    |
|    total_timesteps | 953477   |
| train/             |          |
|    actor_loss      | -22.5    |
|    critic_loss     | 41.1     |
|    ent_coef        | 0.0508   |
|    ent_coef_loss   | -0.747   |
|    learning_rate   | 0.0003   |
|    n_updates       | 943476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 44       |
|    time_elapsed    | 21492    |
|    total_timesteps | 955477   |
| train/             |          |
|    actor_loss      | -36.1    |
|    critic_loss     | 51.3     |
|    ent_coef        | 0.0515   |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 945476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 44       |
|    time_elapsed    | 21525    |
|    total_timesteps | 957477   |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 47.6     |
|    ent_coef        | 0.0512   |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 0.0003   |
|    n_updates       | 947476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 44       |
|    time_elapsed    | 21557    |
|    total_timesteps | 959477   |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 96.4     |
|    ent_coef        | 0.0511   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 949476   |
---------------------------------
Eval num_timesteps=960000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 44.4     |
|    ent_coef        | 0.0518   |
|    ent_coef_loss   | -0.296   |
|    learning_rate   | 0.0003   |
|    n_updates       | 949999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 44       |
|    time_elapsed    | 21644    |
|    total_timesteps | 961477   |
| train/             |          |
|    actor_loss      | -71      |
|    critic_loss     | 85.8     |
|    ent_coef        | 0.0492   |
|    ent_coef_loss   | 0.582    |
|    learning_rate   | 0.0003   |
|    n_updates       | 951476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 44       |
|    time_elapsed    | 21679    |
|    total_timesteps | 963477   |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 51.8     |
|    ent_coef        | 0.0521   |
|    ent_coef_loss   | -0.399   |
|    learning_rate   | 0.0003   |
|    n_updates       | 953476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1960     |
|    fps             | 44       |
|    time_elapsed    | 21712    |
|    total_timesteps | 965477   |
| train/             |          |
|    actor_loss      | -26.3    |
|    critic_loss     | 35.5     |
|    ent_coef        | 0.0504   |
|    ent_coef_loss   | -0.0657  |
|    learning_rate   | 0.0003   |
|    n_updates       | 955476   |
---------------------------------
WARNING: Nan, Inf or huge value in QACC at DOF 2. The simulation is unstable. Time = 22.8900.

---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 44       |
|    time_elapsed    | 21748    |
|    total_timesteps | 967477   |
| train/             |          |
|    actor_loss      | -49.6    |
|    critic_loss     | 49.7     |
|    ent_coef        | 0.0507   |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 957476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 44       |
|    time_elapsed    | 21784    |
|    total_timesteps | 969477   |
| train/             |          |
|    actor_loss      | -25.1    |
|    critic_loss     | 154      |
|    ent_coef        | 0.0501   |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 959476   |
---------------------------------
Eval num_timesteps=970000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | -40.5    |
|    critic_loss     | 31       |
|    ent_coef        | 0.05     |
|    ent_coef_loss   | -0.524   |
|    learning_rate   | 0.0003   |
|    n_updates       | 959999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 44       |
|    time_elapsed    | 21874    |
|    total_timesteps | 971477   |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 29.9     |
|    ent_coef        | 0.0519   |
|    ent_coef_loss   | -0.071   |
|    learning_rate   | 0.0003   |
|    n_updates       | 961476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 44       |
|    time_elapsed    | 21906    |
|    total_timesteps | 973477   |
| train/             |          |
|    actor_loss      | -48      |
|    critic_loss     | 35.6     |
|    ent_coef        | 0.0488   |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 963476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 44       |
|    time_elapsed    | 21939    |
|    total_timesteps | 975477   |
| train/             |          |
|    actor_loss      | -22.8    |
|    critic_loss     | 54.3     |
|    ent_coef        | 0.0516   |
|    ent_coef_loss   | 0.375    |
|    learning_rate   | 0.0003   |
|    n_updates       | 965476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 44       |
|    time_elapsed    | 21974    |
|    total_timesteps | 977477   |
| train/             |          |
|    actor_loss      | -32.6    |
|    critic_loss     | 43.8     |
|    ent_coef        | 0.0503   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 967476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 44       |
|    time_elapsed    | 22010    |
|    total_timesteps | 979477   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 49.6     |
|    ent_coef        | 0.0495   |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 969476   |
---------------------------------
Eval num_timesteps=980000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -12.9    |
|    critic_loss     | 18.4     |
|    ent_coef        | 0.049    |
|    ent_coef_loss   | -0.764   |
|    learning_rate   | 0.0003   |
|    n_updates       | 969999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 44       |
|    time_elapsed    | 22096    |
|    total_timesteps | 981477   |
| train/             |          |
|    actor_loss      | -30.1    |
|    critic_loss     | 26.5     |
|    ent_coef        | 0.0467   |
|    ent_coef_loss   | 0.534    |
|    learning_rate   | 0.0003   |
|    n_updates       | 971476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 1996     |
|    fps             | 44       |
|    time_elapsed    | 22130    |
|    total_timesteps | 983477   |
| train/             |          |
|    actor_loss      | -29.7    |
|    critic_loss     | 104      |
|    ent_coef        | 0.0482   |
|    ent_coef_loss   | 0.262    |
|    learning_rate   | 0.0003   |
|    n_updates       | 973476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 44       |
|    time_elapsed    | 22164    |
|    total_timesteps | 985477   |
| train/             |          |
|    actor_loss      | -34.2    |
|    critic_loss     | 48.3     |
|    ent_coef        | 0.0482   |
|    ent_coef_loss   | 0.0298   |
|    learning_rate   | 0.0003   |
|    n_updates       | 975476   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 44       |
|    time_elapsed    | 22197    |
|    total_timesteps | 987477   |
| train/             |          |
|    actor_loss      | -26.6    |
|    critic_loss     | 41.7     |
|    ent_coef        | 0.0478   |
|    ent_coef_loss   | -0.638   |
|    learning_rate   | 0.0003   |
|    n_updates       | 977476   |
---------------------------------
{'grasped(cube1)': True}
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 44       |
|    time_elapsed    | 22223    |
|    total_timesteps | 989013   |
| train/             |          |
|    actor_loss      | -33.9    |
|    critic_loss     | 57.8     |
|    ent_coef        | 0.0536   |
|    ent_coef_loss   | 0.191    |
|    learning_rate   | 0.0003   |
|    n_updates       | 979012   |
---------------------------------
Eval num_timesteps=990000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | -12.2    |
|    critic_loss     | 72.3     |
|    ent_coef        | 0.0595   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 979999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 44       |
|    time_elapsed    | 22310    |
|    total_timesteps | 991013   |
| train/             |          |
|    actor_loss      | -35.2    |
|    critic_loss     | 79.8     |
|    ent_coef        | 0.0546   |
|    ent_coef_loss   | -0.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 981012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 44       |
|    time_elapsed    | 22344    |
|    total_timesteps | 993013   |
| train/             |          |
|    actor_loss      | -21.3    |
|    critic_loss     | 4.52e+05 |
|    ent_coef        | 0.0494   |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 983012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 44       |
|    time_elapsed    | 22377    |
|    total_timesteps | 995013   |
| train/             |          |
|    actor_loss      | -27.1    |
|    critic_loss     | 38       |
|    ent_coef        | 0.0493   |
|    ent_coef_loss   | -0.363   |
|    learning_rate   | 0.0003   |
|    n_updates       | 985012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 44       |
|    time_elapsed    | 22413    |
|    total_timesteps | 997013   |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 89       |
|    ent_coef        | 0.0507   |
|    ent_coef_loss   | -0.248   |
|    learning_rate   | 0.0003   |
|    n_updates       | 987012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 44       |
|    time_elapsed    | 22447    |
|    total_timesteps | 999013   |
| train/             |          |
|    actor_loss      | -19.9    |
|    critic_loss     | 45.7     |
|    ent_coef        | 0.0508   |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 989012   |
---------------------------------
Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000000  |
| train/             |          |
|    actor_loss      | -9.15    |
|    critic_loss     | 28.5     |
|    ent_coef        | 0.0477   |
|    ent_coef_loss   | -0.233   |
|    learning_rate   | 0.0003   |
|    n_updates       | 989999   |
---------------------------------
 100%  1,000,000/1,000,000  [ 6:15:18 < 0:00:00 , ? it/s ]
Training Drop
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Using cuda device
Wrapping the env in a DummyVecEnv.
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Logging to ./logs/SAC_31
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 46       |
|    time_elapsed    | 32       |
|    total_timesteps | 1507     |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 49       |
|    time_elapsed    | 61       |
|    total_timesteps | 3014     |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 0.333    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 47       |
|    time_elapsed    | 85       |
|    total_timesteps | 4036     |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 0.312    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 51       |
|    time_elapsed    | 108      |
|    total_timesteps | 5550     |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 53       |
|    time_elapsed    | 140      |
|    total_timesteps | 7550     |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | 0.292    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 52       |
|    time_elapsed    | 161      |
|    total_timesteps | 8572     |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 0.286    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 37       |
|    time_elapsed    | 266      |
|    total_timesteps | 10103    |
| train/             |          |
|    actor_loss      | -5.98    |
|    critic_loss     | 0.202    |
|    ent_coef        | 0.97     |
|    ent_coef_loss   | -0.204   |
|    learning_rate   | 0.0003   |
|    n_updates       | 102      |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 39       |
|    time_elapsed    | 308      |
|    total_timesteps | 12103    |
| train/             |          |
|    actor_loss      | -19.7    |
|    critic_loss     | 0.796    |
|    ent_coef        | 0.532    |
|    ent_coef_loss   | -4.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 2102     |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 39       |
|    time_elapsed    | 343      |
|    total_timesteps | 13609    |
| train/             |          |
|    actor_loss      | -25.2    |
|    critic_loss     | 0.162    |
|    ent_coef        | 0.339    |
|    ent_coef_loss   | -7.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 3608     |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.225    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 40       |
|    time_elapsed    | 386      |
|    total_timesteps | 15609    |
| train/             |          |
|    actor_loss      | -27.7    |
|    critic_loss     | 0.997    |
|    ent_coef        | 0.188    |
|    ent_coef_loss   | -10.5    |
|    learning_rate   | 0.0003   |
|    n_updates       | 5608     |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 400      |
|    ep_rew_mean     | 0.205    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 40       |
|    time_elapsed    | 437      |
|    total_timesteps | 17609    |
| train/             |          |
|    actor_loss      | -27.7    |
|    critic_loss     | 0.258    |
|    ent_coef        | 0.106    |
|    ent_coef_loss   | -12.9    |
|    learning_rate   | 0.0003   |
|    n_updates       | 7608     |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.188    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 41       |
|    time_elapsed    | 474      |
|    total_timesteps | 19609    |
| train/             |          |
|    actor_loss      | -26.6    |
|    critic_loss     | 0.216    |
|    ent_coef        | 0.0607   |
|    ent_coef_loss   | -13.4    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9608     |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -25.9    |
|    critic_loss     | 1.34     |
|    ent_coef        | 0.0546   |
|    ent_coef_loss   | -12.5    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9999     |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 416      |
|    ep_rew_mean     | 0.173    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 36       |
|    time_elapsed    | 594      |
|    total_timesteps | 21609    |
| train/             |          |
|    actor_loss      | -25      |
|    critic_loss     | 1.24     |
|    ent_coef        | 0.0355   |
|    ent_coef_loss   | -11.7    |
|    learning_rate   | 0.0003   |
|    n_updates       | 11608    |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 0.179    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 36       |
|    time_elapsed    | 633      |
|    total_timesteps | 23121    |
| train/             |          |
|    actor_loss      | -23.6    |
|    critic_loss     | 0.994    |
|    ent_coef        | 0.0241   |
|    ent_coef_loss   | -11.8    |
|    learning_rate   | 0.0003   |
|    n_updates       | 13120    |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.167    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 36       |
|    time_elapsed    | 682      |
|    total_timesteps | 25121    |
| train/             |          |
|    actor_loss      | -22.4    |
|    critic_loss     | 1.33     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -9.67    |
|    learning_rate   | 0.0003   |
|    n_updates       | 15120    |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.156    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 37       |
|    time_elapsed    | 730      |
|    total_timesteps | 27121    |
| train/             |          |
|    actor_loss      | -20.8    |
|    critic_loss     | 0.173    |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -4.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 17120    |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 428      |
|    ep_rew_mean     | 0.147    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 37       |
|    time_elapsed    | 770      |
|    total_timesteps | 29121    |
| train/             |          |
|    actor_loss      | -19.7    |
|    critic_loss     | 0.0634   |
|    ent_coef        | 0.00806  |
|    ent_coef_loss   | -0.736   |
|    learning_rate   | 0.0003   |
|    n_updates       | 19120    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=30000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -19.1    |
|    critic_loss     | 1.15     |
|    ent_coef        | 0.00763  |
|    ent_coef_loss   | -2.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 19999    |
---------------------------------
New best mean reward!
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.139    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 35       |
|    time_elapsed    | 880      |
|    total_timesteps | 31121    |
| train/             |          |
|    actor_loss      | -18.7    |
|    critic_loss     | 0.0595   |
|    ent_coef        | 0.00748  |
|    ent_coef_loss   | 7.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 21120    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.132    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 35       |
|    time_elapsed    | 923      |
|    total_timesteps | 33121    |
| train/             |          |
|    actor_loss      | -17.5    |
|    critic_loss     | 0.0623   |
|    ent_coef        | 0.00662  |
|    ent_coef_loss   | -4.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 23120    |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 0.138    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 35       |
|    time_elapsed    | 965      |
|    total_timesteps | 34649    |
| train/             |          |
|    actor_loss      | -16.6    |
|    critic_loss     | 0.0437   |
|    ent_coef        | 0.00576  |
|    ent_coef_loss   | 1.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 24648    |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.131    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 36       |
|    time_elapsed    | 1010     |
|    total_timesteps | 36649    |
| train/             |          |
|    actor_loss      | -15.6    |
|    critic_loss     | 0.0362   |
|    ent_coef        | 0.00579  |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 26648    |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 0.125    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 36       |
|    time_elapsed    | 1053     |
|    total_timesteps | 38649    |
| train/             |          |
|    actor_loss      | -14.5    |
|    critic_loss     | 0.674    |
|    ent_coef        | 0.00569  |
|    ent_coef_loss   | -0.476   |
|    learning_rate   | 0.0003   |
|    n_updates       | 28648    |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -13.8    |
|    critic_loss     | 0.0224   |
|    ent_coef        | 0.005    |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 29999    |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 34       |
|    time_elapsed    | 1166     |
|    total_timesteps | 40649    |
| train/             |          |
|    actor_loss      | -13.7    |
|    critic_loss     | 0.0316   |
|    ent_coef        | 0.00514  |
|    ent_coef_loss   | 0.193    |
|    learning_rate   | 0.0003   |
|    n_updates       | 30648    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 0.115    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 35       |
|    time_elapsed    | 1217     |
|    total_timesteps | 42649    |
| train/             |          |
|    actor_loss      | -12.6    |
|    critic_loss     | 0.0233   |
|    ent_coef        | 0.0044   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 32648    |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 35       |
|    time_elapsed    | 1258     |
|    total_timesteps | 44649    |
| train/             |          |
|    actor_loss      | -11.7    |
|    critic_loss     | 0.024    |
|    ent_coef        | 0.00405  |
|    ent_coef_loss   | -0.452   |
|    learning_rate   | 0.0003   |
|    n_updates       | 34648    |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 35       |
|    time_elapsed    | 1301     |
|    total_timesteps | 46649    |
| train/             |          |
|    actor_loss      | -10.8    |
|    critic_loss     | 0.0141   |
|    ent_coef        | 0.00333  |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 36648    |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 35       |
|    time_elapsed    | 1343     |
|    total_timesteps | 47984    |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.0239   |
|    ent_coef        | 0.00304  |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 37983    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 35       |
|    time_elapsed    | 1395     |
|    total_timesteps | 49984    |
| train/             |          |
|    actor_loss      | -9.43    |
|    critic_loss     | 0.0193   |
|    ent_coef        | 0.00266  |
|    ent_coef_loss   | 0.341    |
|    learning_rate   | 0.0003   |
|    n_updates       | 39983    |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -9.28    |
|    critic_loss     | 0.0563   |
|    ent_coef        | 0.00266  |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 39999    |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 33       |
|    time_elapsed    | 1538     |
|    total_timesteps | 51984    |
| train/             |          |
|    actor_loss      | -8.58    |
|    critic_loss     | 0.201    |
|    ent_coef        | 0.00236  |
|    ent_coef_loss   | 0.716    |
|    learning_rate   | 0.0003   |
|    n_updates       | 41983    |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 33       |
|    time_elapsed    | 1594     |
|    total_timesteps | 53984    |
| train/             |          |
|    actor_loss      | -8.03    |
|    critic_loss     | 0.0142   |
|    ent_coef        | 0.00215  |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 43983    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 33       |
|    time_elapsed    | 1651     |
|    total_timesteps | 55984    |
| train/             |          |
|    actor_loss      | -7.32    |
|    critic_loss     | 0.00967  |
|    ent_coef        | 0.00197  |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 45983    |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 34       |
|    time_elapsed    | 1689     |
|    total_timesteps | 57984    |
| train/             |          |
|    actor_loss      | -6.65    |
|    critic_loss     | 0.00601  |
|    ent_coef        | 0.00189  |
|    ent_coef_loss   | 0.0111   |
|    learning_rate   | 0.0003   |
|    n_updates       | 47983    |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 34       |
|    time_elapsed    | 1731     |
|    total_timesteps | 59984    |
| train/             |          |
|    actor_loss      | -6       |
|    critic_loss     | 0.102    |
|    ent_coef        | 0.00175  |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 49983    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -6.18    |
|    critic_loss     | 0.00805  |
|    ent_coef        | 0.00175  |
|    ent_coef_loss   | -4.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 49999    |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 33       |
|    time_elapsed    | 1874     |
|    total_timesteps | 61984    |
| train/             |          |
|    actor_loss      | -5.58    |
|    critic_loss     | 0.152    |
|    ent_coef        | 0.00166  |
|    ent_coef_loss   | -0.641   |
|    learning_rate   | 0.0003   |
|    n_updates       | 51983    |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 33       |
|    time_elapsed    | 1910     |
|    total_timesteps | 63984    |
| train/             |          |
|    actor_loss      | -4.89    |
|    critic_loss     | 0.0106   |
|    ent_coef        | 0.00181  |
|    ent_coef_loss   | 7.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 53983    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 33       |
|    time_elapsed    | 1953     |
|    total_timesteps | 65984    |
| train/             |          |
|    actor_loss      | -4.48    |
|    critic_loss     | 0.00485  |
|    ent_coef        | 0.00152  |
|    ent_coef_loss   | -5.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 55983    |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 34       |
|    time_elapsed    | 1994     |
|    total_timesteps | 67984    |
| train/             |          |
|    actor_loss      | -4.18    |
|    critic_loss     | 0.0145   |
|    ent_coef        | 0.00131  |
|    ent_coef_loss   | 2.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 57983    |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 34       |
|    time_elapsed    | 2034     |
|    total_timesteps | 69984    |
| train/             |          |
|    actor_loss      | -3.62    |
|    critic_loss     | 0.00962  |
|    ent_coef        | 0.0013   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 59983    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -3.58    |
|    critic_loss     | 0.0173   |
|    ent_coef        | 0.00131  |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 59999    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 33       |
|    time_elapsed    | 2152     |
|    total_timesteps | 71984    |
| train/             |          |
|    actor_loss      | -3.3     |
|    critic_loss     | 0.00716  |
|    ent_coef        | 0.00121  |
|    ent_coef_loss   | 1.23     |
|    learning_rate   | 0.0003   |
|    n_updates       | 61983    |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 33       |
|    time_elapsed    | 2193     |
|    total_timesteps | 73984    |
| train/             |          |
|    actor_loss      | -2.94    |
|    critic_loss     | 0.00282  |
|    ent_coef        | 0.00115  |
|    ent_coef_loss   | 0.559    |
|    learning_rate   | 0.0003   |
|    n_updates       | 63983    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 34       |
|    time_elapsed    | 2234     |
|    total_timesteps | 75984    |
| train/             |          |
|    actor_loss      | -2.71    |
|    critic_loss     | 0.0232   |
|    ent_coef        | 0.00082  |
|    ent_coef_loss   | 3.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 65983    |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 34       |
|    time_elapsed    | 2284     |
|    total_timesteps | 77984    |
| train/             |          |
|    actor_loss      | -2.46    |
|    critic_loss     | 0.00196  |
|    ent_coef        | 0.000838 |
|    ent_coef_loss   | 0.484    |
|    learning_rate   | 0.0003   |
|    n_updates       | 67983    |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 34       |
|    time_elapsed    | 2323     |
|    total_timesteps | 79984    |
| train/             |          |
|    actor_loss      | -2.23    |
|    critic_loss     | 0.00178  |
|    ent_coef        | 0.0007   |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 69983    |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -2.21    |
|    critic_loss     | 0.00199  |
|    ent_coef        | 0.000697 |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 0.0003   |
|    n_updates       | 69999    |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 489      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 33       |
|    time_elapsed    | 2457     |
|    total_timesteps | 81984    |
| train/             |          |
|    actor_loss      | -2.02    |
|    critic_loss     | 0.00212  |
|    ent_coef        | 0.000586 |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 71983    |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 33       |
|    time_elapsed    | 2499     |
|    total_timesteps | 83491    |
| train/             |          |
|    actor_loss      | -1.86    |
|    critic_loss     | 0.000947 |
|    ent_coef        | 0.000584 |
|    ent_coef_loss   | -0.505   |
|    learning_rate   | 0.0003   |
|    n_updates       | 73490    |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 33       |
|    time_elapsed    | 2545     |
|    total_timesteps | 85491    |
| train/             |          |
|    actor_loss      | -1.57    |
|    critic_loss     | 0.0192   |
|    ent_coef        | 0.000529 |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 75490    |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 33       |
|    time_elapsed    | 2590     |
|    total_timesteps | 87491    |
| train/             |          |
|    actor_loss      | -1.53    |
|    critic_loss     | 0.00108  |
|    ent_coef        | 0.000528 |
|    ent_coef_loss   | -5.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 77490    |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 33       |
|    time_elapsed    | 2632     |
|    total_timesteps | 88996    |
| train/             |          |
|    actor_loss      | -1.4     |
|    critic_loss     | 0.00591  |
|    ent_coef        | 0.00047  |
|    ent_coef_loss   | -7.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 78995    |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -1.33    |
|    critic_loss     | 0.000794 |
|    ent_coef        | 0.000472 |
|    ent_coef_loss   | 0.591    |
|    learning_rate   | 0.0003   |
|    n_updates       | 79999    |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 32       |
|    time_elapsed    | 2779     |
|    total_timesteps | 90996    |
| train/             |          |
|    actor_loss      | -1.3     |
|    critic_loss     | 0.0134   |
|    ent_coef        | 0.000495 |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 80995    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 32       |
|    time_elapsed    | 2822     |
|    total_timesteps | 92996    |
| train/             |          |
|    actor_loss      | -1.14    |
|    critic_loss     | 0.001    |
|    ent_coef        | 0.000488 |
|    ent_coef_loss   | 0.823    |
|    learning_rate   | 0.0003   |
|    n_updates       | 82995    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 33       |
|    time_elapsed    | 2863     |
|    total_timesteps | 94996    |
| train/             |          |
|    actor_loss      | -1.04    |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.00043  |
|    ent_coef_loss   | -0.509   |
|    learning_rate   | 0.0003   |
|    n_updates       | 84995    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 33       |
|    time_elapsed    | 2905     |
|    total_timesteps | 96996    |
| train/             |          |
|    actor_loss      | -0.929   |
|    critic_loss     | 0.00679  |
|    ent_coef        | 0.000322 |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 86995    |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 33       |
|    time_elapsed    | 2950     |
|    total_timesteps | 98996    |
| train/             |          |
|    actor_loss      | -0.847   |
|    critic_loss     | 0.00235  |
|    ent_coef        | 0.000315 |
|    ent_coef_loss   | 3.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 88995    |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -0.798   |
|    critic_loss     | 0.000765 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -4.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 89999    |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 32       |
|    time_elapsed    | 3077     |
|    total_timesteps | 100996   |
| train/             |          |
|    actor_loss      | -0.701   |
|    critic_loss     | 0.0031   |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | 6.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 90995    |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 32       |
|    time_elapsed    | 3109     |
|    total_timesteps | 102508   |
| train/             |          |
|    actor_loss      | -0.653   |
|    critic_loss     | 0.00173  |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 92507    |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 32       |
|    time_elapsed    | 3153     |
|    total_timesteps | 103520   |
| train/             |          |
|    actor_loss      | -0.62    |
|    critic_loss     | 0.002    |
|    ent_coef        | 0.000204 |
|    ent_coef_loss   | -3.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 93519    |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 32       |
|    time_elapsed    | 3186     |
|    total_timesteps | 105028   |
| train/             |          |
|    actor_loss      | -0.569   |
|    critic_loss     | 0.000323 |
|    ent_coef        | 0.000168 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 95027    |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 33       |
|    time_elapsed    | 3223     |
|    total_timesteps | 106533   |
| train/             |          |
|    actor_loss      | -0.511   |
|    critic_loss     | 0.000874 |
|    ent_coef        | 0.000228 |
|    ent_coef_loss   | -2.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 96532    |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 33       |
|    time_elapsed    | 3263     |
|    total_timesteps | 108533   |
| train/             |          |
|    actor_loss      | -0.463   |
|    critic_loss     | 0.00206  |
|    ent_coef        | 0.000168 |
|    ent_coef_loss   | -4.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 98532    |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Eval num_timesteps=110000, episode_reward=0.60 +/- 0.49
Episode length: 204.20 +/- 241.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 204      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -0.438   |
|    critic_loss     | 0.00606  |
|    ent_coef        | 0.000171 |
|    ent_coef_loss   | 5.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 99999    |
---------------------------------
New best mean reward!
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 32       |
|    time_elapsed    | 3369     |
|    total_timesteps | 110533   |
| train/             |          |
|    actor_loss      | -0.422   |
|    critic_loss     | 0.000437 |
|    ent_coef        | 0.000181 |
|    ent_coef_loss   | 0.308    |
|    learning_rate   | 0.0003   |
|    n_updates       | 100532   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 32       |
|    time_elapsed    | 3415     |
|    total_timesteps | 112039   |
| train/             |          |
|    actor_loss      | -0.362   |
|    critic_loss     | 0.0083   |
|    ent_coef        | 0.000232 |
|    ent_coef_loss   | 0.602    |
|    learning_rate   | 0.0003   |
|    n_updates       | 102038   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 32       |
|    time_elapsed    | 3457     |
|    total_timesteps | 114039   |
| train/             |          |
|    actor_loss      | -0.336   |
|    critic_loss     | 0.000721 |
|    ent_coef        | 0.000191 |
|    ent_coef_loss   | -1.54    |
|    learning_rate   | 0.0003   |
|    n_updates       | 104038   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 252      |
|    fps             | 33       |
|    time_elapsed    | 3488     |
|    total_timesteps | 115545   |
| train/             |          |
|    actor_loss      | -0.329   |
|    critic_loss     | 0.000429 |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | -0.311   |
|    learning_rate   | 0.0003   |
|    n_updates       | 105544   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 33       |
|    time_elapsed    | 3522     |
|    total_timesteps | 117051   |
| train/             |          |
|    actor_loss      | -0.325   |
|    critic_loss     | 0.000652 |
|    ent_coef        | 0.000181 |
|    ent_coef_loss   | 0.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 107050   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 33       |
|    time_elapsed    | 3568     |
|    total_timesteps | 119051   |
| train/             |          |
|    actor_loss      | -0.296   |
|    critic_loss     | 0.000373 |
|    ent_coef        | 0.000158 |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 109050   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=120000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -0.275   |
|    critic_loss     | 0.000401 |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | 6.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 109999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 264      |
|    fps             | 32       |
|    time_elapsed    | 3695     |
|    total_timesteps | 120557   |
| train/             |          |
|    actor_loss      | -0.282   |
|    critic_loss     | 0.000263 |
|    ent_coef        | 0.000175 |
|    ent_coef_loss   | 0.943    |
|    learning_rate   | 0.0003   |
|    n_updates       | 110556   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 268      |
|    fps             | 32       |
|    time_elapsed    | 3745     |
|    total_timesteps | 122557   |
| train/             |          |
|    actor_loss      | -0.255   |
|    critic_loss     | 0.000301 |
|    ent_coef        | 0.000165 |
|    ent_coef_loss   | 6.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 112556   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 272      |
|    fps             | 32       |
|    time_elapsed    | 3788     |
|    total_timesteps | 124557   |
| train/             |          |
|    actor_loss      | -0.237   |
|    critic_loss     | 0.000119 |
|    ent_coef        | 0.000194 |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 114556   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 276      |
|    fps             | 33       |
|    time_elapsed    | 3818     |
|    total_timesteps | 126063   |
| train/             |          |
|    actor_loss      | -0.225   |
|    critic_loss     | 0.000185 |
|    ent_coef        | 0.000178 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 116062   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 33       |
|    time_elapsed    | 3856     |
|    total_timesteps | 128063   |
| train/             |          |
|    actor_loss      | -0.192   |
|    critic_loss     | 0.000159 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 118062   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 33       |
|    time_elapsed    | 3890     |
|    total_timesteps | 129570   |
| train/             |          |
|    actor_loss      | -0.169   |
|    critic_loss     | 0.00102  |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | -7.51    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119569   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Eval num_timesteps=130000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -0.164   |
|    critic_loss     | 0.000105 |
|    ent_coef        | 0.000129 |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 32       |
|    time_elapsed    | 4008     |
|    total_timesteps | 131570   |
| train/             |          |
|    actor_loss      | -0.163   |
|    critic_loss     | 0.000377 |
|    ent_coef        | 0.000128 |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 0.0003   |
|    n_updates       | 121569   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 32       |
|    time_elapsed    | 4066     |
|    total_timesteps | 133570   |
| train/             |          |
|    actor_loss      | -0.179   |
|    critic_loss     | 0.000405 |
|    ent_coef        | 0.000124 |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 123569   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 32       |
|    time_elapsed    | 4101     |
|    total_timesteps | 135076   |
| train/             |          |
|    actor_loss      | -0.148   |
|    critic_loss     | 0.000401 |
|    ent_coef        | 0.000123 |
|    ent_coef_loss   | 7.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 125075   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 33       |
|    time_elapsed    | 4133     |
|    total_timesteps | 136582   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 0.000225 |
|    ent_coef        | 0.000133 |
|    ent_coef_loss   | -0.127   |
|    learning_rate   | 0.0003   |
|    n_updates       | 126581   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 33       |
|    time_elapsed    | 4178     |
|    total_timesteps | 138582   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.000126 |
|    ent_coef        | 0.000143 |
|    ent_coef_loss   | 0.948    |
|    learning_rate   | 0.0003   |
|    n_updates       | 128581   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=140000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -0.121   |
|    critic_loss     | 0.000348 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | 0.719    |
|    learning_rate   | 0.0003   |
|    n_updates       | 129999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 32       |
|    time_elapsed    | 4300     |
|    total_timesteps | 140582   |
| train/             |          |
|    actor_loss      | -0.112   |
|    critic_loss     | 0.00018  |
|    ent_coef        | 0.000147 |
|    ent_coef_loss   | -2.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 130581   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 32       |
|    time_elapsed    | 4341     |
|    total_timesteps | 142088   |
| train/             |          |
|    actor_loss      | -0.11    |
|    critic_loss     | 0.000211 |
|    ent_coef        | 0.000131 |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 132087   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 32       |
|    time_elapsed    | 4393     |
|    total_timesteps | 144088   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.000202 |
|    ent_coef        | 0.000123 |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 0.0003   |
|    n_updates       | 134087   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 320      |
|    fps             | 32       |
|    time_elapsed    | 4446     |
|    total_timesteps | 145594   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.000114 |
|    ent_coef        | 0.000116 |
|    ent_coef_loss   | -0.834   |
|    learning_rate   | 0.0003   |
|    n_updates       | 135593   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 32       |
|    time_elapsed    | 4487     |
|    total_timesteps | 147594   |
| train/             |          |
|    actor_loss      | -0.0968  |
|    critic_loss     | 0.000164 |
|    ent_coef        | 0.000114 |
|    ent_coef_loss   | -4.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 137593   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 32       |
|    time_elapsed    | 4525     |
|    total_timesteps | 149100   |
| train/             |          |
|    actor_loss      | -0.0911  |
|    critic_loss     | 0.000504 |
|    ent_coef        | 0.000135 |
|    ent_coef_loss   | -0.899   |
|    learning_rate   | 0.0003   |
|    n_updates       | 139099   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -0.0831  |
|    critic_loss     | 0.00027  |
|    ent_coef        | 0.000137 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 139999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 32       |
|    time_elapsed    | 4641     |
|    total_timesteps | 150605   |
| train/             |          |
|    actor_loss      | -0.11    |
|    critic_loss     | 0.00176  |
|    ent_coef        | 0.000133 |
|    ent_coef_loss   | 5.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 140604   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 32       |
|    time_elapsed    | 4681     |
|    total_timesteps | 152605   |
| train/             |          |
|    actor_loss      | -0.0871  |
|    critic_loss     | 0.000295 |
|    ent_coef        | 0.000151 |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 142604   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 32       |
|    time_elapsed    | 4723     |
|    total_timesteps | 154605   |
| train/             |          |
|    actor_loss      | -0.0502  |
|    critic_loss     | 0.000499 |
|    ent_coef        | 0.000151 |
|    ent_coef_loss   | -4.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 144604   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 344      |
|    fps             | 32       |
|    time_elapsed    | 4787     |
|    total_timesteps | 156605   |
| train/             |          |
|    actor_loss      | -0.0527  |
|    critic_loss     | 0.00079  |
|    ent_coef        | 0.000159 |
|    ent_coef_loss   | -0.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 146604   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 348      |
|    fps             | 32       |
|    time_elapsed    | 4827     |
|    total_timesteps | 158605   |
| train/             |          |
|    actor_loss      | -0.0553  |
|    critic_loss     | 0.000332 |
|    ent_coef        | 0.000196 |
|    ent_coef_loss   | 3.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 148604   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=160000, episode_reward=0.30 +/- 0.46
Episode length: 351.80 +/- 226.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -0.0871  |
|    critic_loss     | 0.00146  |
|    ent_coef        | 0.000186 |
|    ent_coef_loss   | -0.269   |
|    learning_rate   | 0.0003   |
|    n_updates       | 149999   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 32       |
|    time_elapsed    | 4944     |
|    total_timesteps | 160605   |
| train/             |          |
|    actor_loss      | -0.0474  |
|    critic_loss     | 0.00206  |
|    ent_coef        | 0.000185 |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 150604   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 356      |
|    fps             | 32       |
|    time_elapsed    | 4985     |
|    total_timesteps | 162605   |
| train/             |          |
|    actor_loss      | -0.0809  |
|    critic_loss     | 0.000181 |
|    ent_coef        | 0.000206 |
|    ent_coef_loss   | -0.243   |
|    learning_rate   | 0.0003   |
|    n_updates       | 152604   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 360      |
|    fps             | 32       |
|    time_elapsed    | 5030     |
|    total_timesteps | 164605   |
| train/             |          |
|    actor_loss      | -0.0699  |
|    critic_loss     | 0.000493 |
|    ent_coef        | 0.000195 |
|    ent_coef_loss   | -6.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 154604   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 364      |
|    fps             | 32       |
|    time_elapsed    | 5076     |
|    total_timesteps | 166605   |
| train/             |          |
|    actor_loss      | -0.043   |
|    critic_loss     | 0.00497  |
|    ent_coef        | 0.000232 |
|    ent_coef_loss   | 0.318    |
|    learning_rate   | 0.0003   |
|    n_updates       | 156604   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 368      |
|    fps             | 32       |
|    time_elapsed    | 5115     |
|    total_timesteps | 168605   |
| train/             |          |
|    actor_loss      | -0.101   |
|    critic_loss     | 0.000747 |
|    ent_coef        | 0.00023  |
|    ent_coef_loss   | 4.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 158604   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=170000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -0.0834  |
|    critic_loss     | 0.00251  |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | -4.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 159999   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 372      |
|    fps             | 32       |
|    time_elapsed    | 5242     |
|    total_timesteps | 170605   |
| train/             |          |
|    actor_loss      | -0.0842  |
|    critic_loss     | 0.000446 |
|    ent_coef        | 0.000233 |
|    ent_coef_loss   | -5.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 160604   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 376      |
|    fps             | 32       |
|    time_elapsed    | 5272     |
|    total_timesteps | 172110   |
| train/             |          |
|    actor_loss      | -0.0573  |
|    critic_loss     | 0.000441 |
|    ent_coef        | 0.000248 |
|    ent_coef_loss   | -5.52    |
|    learning_rate   | 0.0003   |
|    n_updates       | 162109   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 380      |
|    fps             | 32       |
|    time_elapsed    | 5319     |
|    total_timesteps | 174110   |
| train/             |          |
|    actor_loss      | -0.131   |
|    critic_loss     | 0.000282 |
|    ent_coef        | 0.000235 |
|    ent_coef_loss   | -0.0164  |
|    learning_rate   | 0.0003   |
|    n_updates       | 164109   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 384      |
|    fps             | 32       |
|    time_elapsed    | 5359     |
|    total_timesteps | 176110   |
| train/             |          |
|    actor_loss      | -0.106   |
|    critic_loss     | 0.000615 |
|    ent_coef        | 0.000238 |
|    ent_coef_loss   | -3.94    |
|    learning_rate   | 0.0003   |
|    n_updates       | 166109   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 388      |
|    fps             | 32       |
|    time_elapsed    | 5411     |
|    total_timesteps | 178110   |
| train/             |          |
|    actor_loss      | -0.125   |
|    critic_loss     | 0.000525 |
|    ent_coef        | 0.000233 |
|    ent_coef_loss   | 6.93     |
|    learning_rate   | 0.0003   |
|    n_updates       | 168109   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Eval num_timesteps=180000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000294 |
|    ent_coef        | 0.000248 |
|    ent_coef_loss   | 3        |
|    learning_rate   | 0.0003   |
|    n_updates       | 169999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 32       |
|    time_elapsed    | 5565     |
|    total_timesteps | 180110   |
| train/             |          |
|    actor_loss      | -0.167   |
|    critic_loss     | 0.000371 |
|    ent_coef        | 0.000251 |
|    ent_coef_loss   | 2.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 170109   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 396      |
|    fps             | 32       |
|    time_elapsed    | 5607     |
|    total_timesteps | 182110   |
| train/             |          |
|    actor_loss      | -0.136   |
|    critic_loss     | 0.000304 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 3.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 172109   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 400      |
|    fps             | 32       |
|    time_elapsed    | 5647     |
|    total_timesteps | 184110   |
| train/             |          |
|    actor_loss      | -0.202   |
|    critic_loss     | 0.00883  |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -4.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 174109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 404      |
|    fps             | 32       |
|    time_elapsed    | 5686     |
|    total_timesteps | 186110   |
| train/             |          |
|    actor_loss      | -0.182   |
|    critic_loss     | 0.000404 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | -3.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 176109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 32       |
|    time_elapsed    | 5736     |
|    total_timesteps | 188110   |
| train/             |          |
|    actor_loss      | -0.269   |
|    critic_loss     | 0.00265  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 0.0003   |
|    n_updates       | 178109   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=190000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -0.199   |
|    critic_loss     | 0.000272 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | -0.371   |
|    learning_rate   | 0.0003   |
|    n_updates       | 179999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 32       |
|    time_elapsed    | 5855     |
|    total_timesteps | 190110   |
| train/             |          |
|    actor_loss      | -0.178   |
|    critic_loss     | 0.000427 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 180109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 416      |
|    fps             | 32       |
|    time_elapsed    | 5916     |
|    total_timesteps | 192110   |
| train/             |          |
|    actor_loss      | -0.225   |
|    critic_loss     | 0.000283 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 182109   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 420      |
|    fps             | 32       |
|    time_elapsed    | 5965     |
|    total_timesteps | 194110   |
| train/             |          |
|    actor_loss      | -0.253   |
|    critic_loss     | 0.000364 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | 1.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 184109   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 424      |
|    fps             | 32       |
|    time_elapsed    | 6010     |
|    total_timesteps | 196110   |
| train/             |          |
|    actor_loss      | -0.217   |
|    critic_loss     | 0.000341 |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | -3.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 186109   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 428      |
|    fps             | 32       |
|    time_elapsed    | 6063     |
|    total_timesteps | 197616   |
| train/             |          |
|    actor_loss      | -0.212   |
|    critic_loss     | 0.000566 |
|    ent_coef        | 0.00024  |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 187615   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 32       |
|    time_elapsed    | 6099     |
|    total_timesteps | 199616   |
| train/             |          |
|    actor_loss      | -0.178   |
|    critic_loss     | 0.000185 |
|    ent_coef        | 0.000237 |
|    ent_coef_loss   | -3.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 189615   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -0.193   |
|    critic_loss     | 0.000508 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 189999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 436      |
|    fps             | 32       |
|    time_elapsed    | 6235     |
|    total_timesteps | 201616   |
| train/             |          |
|    actor_loss      | -0.208   |
|    critic_loss     | 0.000479 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | -0.348   |
|    learning_rate   | 0.0003   |
|    n_updates       | 191615   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 440      |
|    fps             | 32       |
|    time_elapsed    | 6277     |
|    total_timesteps | 203616   |
| train/             |          |
|    actor_loss      | -0.273   |
|    critic_loss     | 0.000768 |
|    ent_coef        | 0.000242 |
|    ent_coef_loss   | 5.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 193615   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 444      |
|    fps             | 32       |
|    time_elapsed    | 6320     |
|    total_timesteps | 205616   |
| train/             |          |
|    actor_loss      | -0.181   |
|    critic_loss     | 0.000412 |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 195615   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 448      |
|    fps             | 32       |
|    time_elapsed    | 6359     |
|    total_timesteps | 207616   |
| train/             |          |
|    actor_loss      | -0.274   |
|    critic_loss     | 0.000336 |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | -0.981   |
|    learning_rate   | 0.0003   |
|    n_updates       | 197615   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 452      |
|    fps             | 32       |
|    time_elapsed    | 6404     |
|    total_timesteps | 209121   |
| train/             |          |
|    actor_loss      | -0.302   |
|    critic_loss     | 0.000618 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 2.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 199120   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=210000, episode_reward=0.30 +/- 0.46
Episode length: 351.60 +/- 226.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -0.272   |
|    critic_loss     | 0.000549 |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | 4.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 199999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 456      |
|    fps             | 32       |
|    time_elapsed    | 6529     |
|    total_timesteps | 211121   |
| train/             |          |
|    actor_loss      | -0.271   |
|    critic_loss     | 0.000869 |
|    ent_coef        | 0.000305 |
|    ent_coef_loss   | 4.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 201120   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 460      |
|    fps             | 32       |
|    time_elapsed    | 6561     |
|    total_timesteps | 212626   |
| train/             |          |
|    actor_loss      | -0.259   |
|    critic_loss     | 0.000531 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -0.323   |
|    learning_rate   | 0.0003   |
|    n_updates       | 202625   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 464      |
|    fps             | 32       |
|    time_elapsed    | 6596     |
|    total_timesteps | 214132   |
| train/             |          |
|    actor_loss      | -0.256   |
|    critic_loss     | 0.000492 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 204131   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 468      |
|    fps             | 32       |
|    time_elapsed    | 6649     |
|    total_timesteps | 216132   |
| train/             |          |
|    actor_loss      | -0.283   |
|    critic_loss     | 0.000647 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | -3.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 206131   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 472      |
|    fps             | 32       |
|    time_elapsed    | 6687     |
|    total_timesteps | 218132   |
| train/             |          |
|    actor_loss      | -0.273   |
|    critic_loss     | 0.000884 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 0.561    |
|    learning_rate   | 0.0003   |
|    n_updates       | 208131   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=220000, episode_reward=0.30 +/- 0.46
Episode length: 351.40 +/- 226.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 351      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -0.278   |
|    critic_loss     | 0.00118  |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | 2.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 209999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 476      |
|    fps             | 32       |
|    time_elapsed    | 6784     |
|    total_timesteps | 220132   |
| train/             |          |
|    actor_loss      | -0.283   |
|    critic_loss     | 0.000442 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 210131   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 480      |
|    fps             | 32       |
|    time_elapsed    | 6824     |
|    total_timesteps | 222132   |
| train/             |          |
|    actor_loss      | -0.325   |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | -3.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 212131   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 484      |
|    fps             | 32       |
|    time_elapsed    | 6869     |
|    total_timesteps | 224132   |
| train/             |          |
|    actor_loss      | -0.275   |
|    critic_loss     | 0.0294   |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | -2.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 214131   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 488      |
|    fps             | 32       |
|    time_elapsed    | 6901     |
|    total_timesteps | 225700   |
| train/             |          |
|    actor_loss      | -0.307   |
|    critic_loss     | 0.000504 |
|    ent_coef        | 0.000286 |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 0.0003   |
|    n_updates       | 215699   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 492      |
|    fps             | 32       |
|    time_elapsed    | 6959     |
|    total_timesteps | 227700   |
| train/             |          |
|    actor_loss      | -0.302   |
|    critic_loss     | 0.000588 |
|    ent_coef        | 0.000309 |
|    ent_coef_loss   | -0.728   |
|    learning_rate   | 0.0003   |
|    n_updates       | 217699   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 496      |
|    fps             | 32       |
|    time_elapsed    | 6999     |
|    total_timesteps | 229700   |
| train/             |          |
|    actor_loss      | -0.3     |
|    critic_loss     | 0.00593  |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 219699   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=230000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -0.307   |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.000307 |
|    ent_coef_loss   | -0.458   |
|    learning_rate   | 0.0003   |
|    n_updates       | 219999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 500      |
|    fps             | 32       |
|    time_elapsed    | 7143     |
|    total_timesteps | 231700   |
| train/             |          |
|    actor_loss      | -0.34    |
|    critic_loss     | 0.000381 |
|    ent_coef        | 0.000309 |
|    ent_coef_loss   | 0.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 221699   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 504      |
|    fps             | 32       |
|    time_elapsed    | 7188     |
|    total_timesteps | 233700   |
| train/             |          |
|    actor_loss      | -0.255   |
|    critic_loss     | 0.000548 |
|    ent_coef        | 0.000304 |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 223699   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 508      |
|    fps             | 32       |
|    time_elapsed    | 7228     |
|    total_timesteps | 235700   |
| train/             |          |
|    actor_loss      | -0.33    |
|    critic_loss     | 0.000605 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 0.0003   |
|    n_updates       | 225699   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 512      |
|    fps             | 32       |
|    time_elapsed    | 7261     |
|    total_timesteps | 237206   |
| train/             |          |
|    actor_loss      | -0.311   |
|    critic_loss     | 0.000706 |
|    ent_coef        | 0.000312 |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 227205   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 516      |
|    fps             | 32       |
|    time_elapsed    | 7293     |
|    total_timesteps | 238711   |
| train/             |          |
|    actor_loss      | -0.213   |
|    critic_loss     | 0.000294 |
|    ent_coef        | 0.000289 |
|    ent_coef_loss   | -0.575   |
|    learning_rate   | 0.0003   |
|    n_updates       | 228710   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Eval num_timesteps=240000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -0.236   |
|    critic_loss     | 0.000451 |
|    ent_coef        | 0.000303 |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 229999   |
---------------------------------
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 520      |
|    fps             | 32       |
|    time_elapsed    | 7420     |
|    total_timesteps | 240216   |
| train/             |          |
|    actor_loss      | -0.283   |
|    critic_loss     | 0.000955 |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 0.744    |
|    learning_rate   | 0.0003   |
|    n_updates       | 230215   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 524      |
|    fps             | 32       |
|    time_elapsed    | 7460     |
|    total_timesteps | 242216   |
| train/             |          |
|    actor_loss      | -0.255   |
|    critic_loss     | 0.00037  |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | -0.878   |
|    learning_rate   | 0.0003   |
|    n_updates       | 232215   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 528      |
|    fps             | 32       |
|    time_elapsed    | 7498     |
|    total_timesteps | 244216   |
| train/             |          |
|    actor_loss      | -0.215   |
|    critic_loss     | 0.000945 |
|    ent_coef        | 0.000311 |
|    ent_coef_loss   | 4.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 234215   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 32       |
|    time_elapsed    | 7544     |
|    total_timesteps | 245722   |
| train/             |          |
|    actor_loss      | -0.296   |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 235721   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 536      |
|    fps             | 32       |
|    time_elapsed    | 7593     |
|    total_timesteps | 247722   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.000372 |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | -4.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 237721   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 540      |
|    fps             | 32       |
|    time_elapsed    | 7640     |
|    total_timesteps | 249722   |
| train/             |          |
|    actor_loss      | -0.177   |
|    critic_loss     | 0.000547 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | -3.47    |
|    learning_rate   | 0.0003   |
|    n_updates       | 239721   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=250000, episode_reward=0.20 +/- 0.40
Episode length: 401.10 +/- 197.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -0.218   |
|    critic_loss     | 0.00314  |
|    ent_coef        | 0.000299 |
|    ent_coef_loss   | 0.889    |
|    learning_rate   | 0.0003   |
|    n_updates       | 239999   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 544      |
|    fps             | 32       |
|    time_elapsed    | 7757     |
|    total_timesteps | 251722   |
| train/             |          |
|    actor_loss      | -0.188   |
|    critic_loss     | 0.000814 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 241721   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 548      |
|    fps             | 32       |
|    time_elapsed    | 7805     |
|    total_timesteps | 253722   |
| train/             |          |
|    actor_loss      | -0.264   |
|    critic_loss     | 0.000676 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | 0.0446   |
|    learning_rate   | 0.0003   |
|    n_updates       | 243721   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 552      |
|    fps             | 32       |
|    time_elapsed    | 7844     |
|    total_timesteps | 255722   |
| train/             |          |
|    actor_loss      | -0.256   |
|    critic_loss     | 0.000374 |
|    ent_coef        | 0.000299 |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 245721   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 556      |
|    fps             | 32       |
|    time_elapsed    | 7885     |
|    total_timesteps | 257722   |
| train/             |          |
|    actor_loss      | -0.221   |
|    critic_loss     | 0.000375 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | -0.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 247721   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 560      |
|    fps             | 32       |
|    time_elapsed    | 7928     |
|    total_timesteps | 259722   |
| train/             |          |
|    actor_loss      | -0.242   |
|    critic_loss     | 0.000365 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | 0.975    |
|    learning_rate   | 0.0003   |
|    n_updates       | 249721   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=260000, episode_reward=0.20 +/- 0.40
Episode length: 401.20 +/- 197.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -0.315   |
|    critic_loss     | 0.000571 |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | 2.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 249999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 564      |
|    fps             | 32       |
|    time_elapsed    | 8040     |
|    total_timesteps | 261722   |
| train/             |          |
|    actor_loss      | -0.227   |
|    critic_loss     | 0.000621 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 251721   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 568      |
|    fps             | 32       |
|    time_elapsed    | 8085     |
|    total_timesteps | 263722   |
| train/             |          |
|    actor_loss      | -0.232   |
|    critic_loss     | 0.00038  |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | -3.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 253721   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 572      |
|    fps             | 32       |
|    time_elapsed    | 8134     |
|    total_timesteps | 265722   |
| train/             |          |
|    actor_loss      | -0.211   |
|    critic_loss     | 0.0037   |
|    ent_coef        | 0.000239 |
|    ent_coef_loss   | 1.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 255721   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 576      |
|    fps             | 32       |
|    time_elapsed    | 8180     |
|    total_timesteps | 267722   |
| train/             |          |
|    actor_loss      | -0.194   |
|    critic_loss     | 0.000293 |
|    ent_coef        | 0.000242 |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 257721   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 580      |
|    fps             | 32       |
|    time_elapsed    | 8219     |
|    total_timesteps | 269722   |
| train/             |          |
|    actor_loss      | -0.239   |
|    critic_loss     | 0.000424 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | 0.607    |
|    learning_rate   | 0.0003   |
|    n_updates       | 259721   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=270000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -0.211   |
|    critic_loss     | 0.000436 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 0.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 259999   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 584      |
|    fps             | 32       |
|    time_elapsed    | 8337     |
|    total_timesteps | 271722   |
| train/             |          |
|    actor_loss      | -0.209   |
|    critic_loss     | 0.000461 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 261721   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 588      |
|    fps             | 32       |
|    time_elapsed    | 8368     |
|    total_timesteps | 273227   |
| train/             |          |
|    actor_loss      | -0.163   |
|    critic_loss     | 0.000478 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -4.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 263226   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 592      |
|    fps             | 32       |
|    time_elapsed    | 8422     |
|    total_timesteps | 275227   |
| train/             |          |
|    actor_loss      | -0.201   |
|    critic_loss     | 0.00185  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -2.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 265226   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 596      |
|    fps             | 32       |
|    time_elapsed    | 8462     |
|    total_timesteps | 277227   |
| train/             |          |
|    actor_loss      | -0.193   |
|    critic_loss     | 0.000238 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 267226   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 600      |
|    fps             | 32       |
|    time_elapsed    | 8507     |
|    total_timesteps | 279227   |
| train/             |          |
|    actor_loss      | -0.192   |
|    critic_loss     | 0.000315 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 269226   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=280000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 0.00028  |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -0.995   |
|    learning_rate   | 0.0003   |
|    n_updates       | 269999   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 604      |
|    fps             | 32       |
|    time_elapsed    | 8624     |
|    total_timesteps | 281227   |
| train/             |          |
|    actor_loss      | -0.191   |
|    critic_loss     | 0.000488 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 271226   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 608      |
|    fps             | 32       |
|    time_elapsed    | 8664     |
|    total_timesteps | 283227   |
| train/             |          |
|    actor_loss      | -0.171   |
|    critic_loss     | 0.000355 |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -0.0755  |
|    learning_rate   | 0.0003   |
|    n_updates       | 273226   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 612      |
|    fps             | 32       |
|    time_elapsed    | 8706     |
|    total_timesteps | 285227   |
| train/             |          |
|    actor_loss      | -0.186   |
|    critic_loss     | 0.000255 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 275226   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 616      |
|    fps             | 32       |
|    time_elapsed    | 8748     |
|    total_timesteps | 287227   |
| train/             |          |
|    actor_loss      | -0.164   |
|    critic_loss     | 0.000321 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 277226   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 620      |
|    fps             | 32       |
|    time_elapsed    | 8796     |
|    total_timesteps | 289227   |
| train/             |          |
|    actor_loss      | -0.152   |
|    critic_loss     | 0.000262 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 279226   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Eval num_timesteps=290000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -0.161   |
|    critic_loss     | 0.000249 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | 3.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 279999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 624      |
|    fps             | 32       |
|    time_elapsed    | 8939     |
|    total_timesteps | 291227   |
| train/             |          |
|    actor_loss      | -0.174   |
|    critic_loss     | 0.00186  |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | 5.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 281226   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 628      |
|    fps             | 32       |
|    time_elapsed    | 8981     |
|    total_timesteps | 293227   |
| train/             |          |
|    actor_loss      | -0.112   |
|    critic_loss     | 0.000283 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 0.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 283226   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 632      |
|    fps             | 32       |
|    time_elapsed    | 9045     |
|    total_timesteps | 295227   |
| train/             |          |
|    actor_loss      | -0.13    |
|    critic_loss     | 0.00033  |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -0.0455  |
|    learning_rate   | 0.0003   |
|    n_updates       | 285226   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 636      |
|    fps             | 32       |
|    time_elapsed    | 9087     |
|    total_timesteps | 297227   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 0.00041  |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | -0.552   |
|    learning_rate   | 0.0003   |
|    n_updates       | 287226   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 640      |
|    fps             | 32       |
|    time_elapsed    | 9128     |
|    total_timesteps | 299227   |
| train/             |          |
|    actor_loss      | -0.146   |
|    critic_loss     | 0.000222 |
|    ent_coef        | 0.000254 |
|    ent_coef_loss   | 1.93     |
|    learning_rate   | 0.0003   |
|    n_updates       | 289226   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=300000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -0.115   |
|    critic_loss     | 0.000411 |
|    ent_coef        | 0.000246 |
|    ent_coef_loss   | 0.0224   |
|    learning_rate   | 0.0003   |
|    n_updates       | 289999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 644      |
|    fps             | 32       |
|    time_elapsed    | 9264     |
|    total_timesteps | 301227   |
| train/             |          |
|    actor_loss      | -0.164   |
|    critic_loss     | 0.000544 |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 291226   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 648      |
|    fps             | 32       |
|    time_elapsed    | 9305     |
|    total_timesteps | 303227   |
| train/             |          |
|    actor_loss      | -0.099   |
|    critic_loss     | 0.000369 |
|    ent_coef        | 0.000231 |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 293226   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 652      |
|    fps             | 32       |
|    time_elapsed    | 9369     |
|    total_timesteps | 305227   |
| train/             |          |
|    actor_loss      | -0.0959  |
|    critic_loss     | 0.00492  |
|    ent_coef        | 0.000227 |
|    ent_coef_loss   | -0.156   |
|    learning_rate   | 0.0003   |
|    n_updates       | 295226   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 656      |
|    fps             | 32       |
|    time_elapsed    | 9412     |
|    total_timesteps | 307227   |
| train/             |          |
|    actor_loss      | -0.147   |
|    critic_loss     | 0.000367 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 0.942    |
|    learning_rate   | 0.0003   |
|    n_updates       | 297226   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 660      |
|    fps             | 32       |
|    time_elapsed    | 9452     |
|    total_timesteps | 309227   |
| train/             |          |
|    actor_loss      | -0.0989  |
|    critic_loss     | 0.000229 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | 4.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 299226   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=310000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 0.00019  |
|    ent_coef        | 0.000226 |
|    ent_coef_loss   | -3.57    |
|    learning_rate   | 0.0003   |
|    n_updates       | 299999   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 664      |
|    fps             | 32       |
|    time_elapsed    | 9624     |
|    total_timesteps | 311227   |
| train/             |          |
|    actor_loss      | -0.0902  |
|    critic_loss     | 0.000524 |
|    ent_coef        | 0.000217 |
|    ent_coef_loss   | 0.845    |
|    learning_rate   | 0.0003   |
|    n_updates       | 301226   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 668      |
|    fps             | 32       |
|    time_elapsed    | 9668     |
|    total_timesteps | 312733   |
| train/             |          |
|    actor_loss      | -0.129   |
|    critic_loss     | 0.000462 |
|    ent_coef        | 0.000215 |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 302732   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 672      |
|    fps             | 32       |
|    time_elapsed    | 9707     |
|    total_timesteps | 314733   |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.000202 |
|    ent_coef        | 0.000221 |
|    ent_coef_loss   | 0.756    |
|    learning_rate   | 0.0003   |
|    n_updates       | 304732   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 676      |
|    fps             | 32       |
|    time_elapsed    | 9747     |
|    total_timesteps | 316733   |
| train/             |          |
|    actor_loss      | -0.0884  |
|    critic_loss     | 0.000221 |
|    ent_coef        | 0.000205 |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 306732   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 680      |
|    fps             | 32       |
|    time_elapsed    | 9790     |
|    total_timesteps | 318733   |
| train/             |          |
|    actor_loss      | -0.127   |
|    critic_loss     | 0.000319 |
|    ent_coef        | 0.000216 |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 308732   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=320000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 0.000264 |
|    ent_coef        | 0.000215 |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 309999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 684      |
|    fps             | 32       |
|    time_elapsed    | 9902     |
|    total_timesteps | 320733   |
| train/             |          |
|    actor_loss      | -0.119   |
|    critic_loss     | 0.000271 |
|    ent_coef        | 0.00022  |
|    ent_coef_loss   | -0.467   |
|    learning_rate   | 0.0003   |
|    n_updates       | 310732   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 688      |
|    fps             | 32       |
|    time_elapsed    | 9950     |
|    total_timesteps | 322733   |
| train/             |          |
|    actor_loss      | -0.0498  |
|    critic_loss     | 0.000236 |
|    ent_coef        | 0.000216 |
|    ent_coef_loss   | -5.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 312732   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 692      |
|    fps             | 32       |
|    time_elapsed    | 9993     |
|    total_timesteps | 324733   |
| train/             |          |
|    actor_loss      | -0.105   |
|    critic_loss     | 0.000437 |
|    ent_coef        | 0.000223 |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 314732   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 696      |
|    fps             | 32       |
|    time_elapsed    | 10032    |
|    total_timesteps | 326240   |
| train/             |          |
|    actor_loss      | -0.122   |
|    critic_loss     | 0.000336 |
|    ent_coef        | 0.00022  |
|    ent_coef_loss   | -1.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 316239   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 700      |
|    fps             | 32       |
|    time_elapsed    | 10082    |
|    total_timesteps | 328240   |
| train/             |          |
|    actor_loss      | -0.0971  |
|    critic_loss     | 0.000285 |
|    ent_coef        | 0.000214 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 318239   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=330000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.000305 |
|    ent_coef        | 0.000211 |
|    ent_coef_loss   | -0.776   |
|    learning_rate   | 0.0003   |
|    n_updates       | 319999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 704      |
|    fps             | 32       |
|    time_elapsed    | 10206    |
|    total_timesteps | 330240   |
| train/             |          |
|    actor_loss      | -0.0795  |
|    critic_loss     | 0.000706 |
|    ent_coef        | 0.000208 |
|    ent_coef_loss   | 0.257    |
|    learning_rate   | 0.0003   |
|    n_updates       | 320239   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 708      |
|    fps             | 32       |
|    time_elapsed    | 10255    |
|    total_timesteps | 332240   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.00171  |
|    ent_coef        | 0.000215 |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 322239   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 32       |
|    time_elapsed    | 10310    |
|    total_timesteps | 334240   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.000321 |
|    ent_coef        | 0.000207 |
|    ent_coef_loss   | 3.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 324239   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 716      |
|    fps             | 32       |
|    time_elapsed    | 10349    |
|    total_timesteps | 336240   |
| train/             |          |
|    actor_loss      | -0.0858  |
|    critic_loss     | 0.000334 |
|    ent_coef        | 0.000218 |
|    ent_coef_loss   | -0.679   |
|    learning_rate   | 0.0003   |
|    n_updates       | 326239   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 720      |
|    fps             | 32       |
|    time_elapsed    | 10388    |
|    total_timesteps | 338240   |
| train/             |          |
|    actor_loss      | -0.077   |
|    critic_loss     | 0.000249 |
|    ent_coef        | 0.000227 |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 328239   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=340000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -0.0794  |
|    critic_loss     | 0.000338 |
|    ent_coef        | 0.000215 |
|    ent_coef_loss   | 0.927    |
|    learning_rate   | 0.0003   |
|    n_updates       | 329999   |
---------------------------------
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 724      |
|    fps             | 32       |
|    time_elapsed    | 10521    |
|    total_timesteps | 340240   |
| train/             |          |
|    actor_loss      | -0.0859  |
|    critic_loss     | 0.00022  |
|    ent_coef        | 0.000217 |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 0.0003   |
|    n_updates       | 330239   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 728      |
|    fps             | 32       |
|    time_elapsed    | 10565    |
|    total_timesteps | 342240   |
| train/             |          |
|    actor_loss      | -0.1     |
|    critic_loss     | 0.00049  |
|    ent_coef        | 0.000222 |
|    ent_coef_loss   | -1.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 332239   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 32       |
|    time_elapsed    | 10609    |
|    total_timesteps | 344240   |
| train/             |          |
|    actor_loss      | -0.0647  |
|    critic_loss     | 0.000451 |
|    ent_coef        | 0.000223 |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 334239   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 736      |
|    fps             | 32       |
|    time_elapsed    | 10641    |
|    total_timesteps | 345748   |
| train/             |          |
|    actor_loss      | -0.0979  |
|    critic_loss     | 0.00302  |
|    ent_coef        | 0.000212 |
|    ent_coef_loss   | 0.844    |
|    learning_rate   | 0.0003   |
|    n_updates       | 335747   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 32       |
|    time_elapsed    | 10672    |
|    total_timesteps | 347256   |
| train/             |          |
|    actor_loss      | -0.087   |
|    critic_loss     | 0.00049  |
|    ent_coef        | 0.000215 |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 337255   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 744      |
|    fps             | 32       |
|    time_elapsed    | 10733    |
|    total_timesteps | 349256   |
| train/             |          |
|    actor_loss      | -0.0733  |
|    critic_loss     | 0.000299 |
|    ent_coef        | 0.000203 |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 339255   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Eval num_timesteps=350000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -0.0364  |
|    critic_loss     | 0.000253 |
|    ent_coef        | 0.00021  |
|    ent_coef_loss   | 0.444    |
|    learning_rate   | 0.0003   |
|    n_updates       | 339999   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 748      |
|    fps             | 32       |
|    time_elapsed    | 10867    |
|    total_timesteps | 351256   |
| train/             |          |
|    actor_loss      | -0.0457  |
|    critic_loss     | 0.000215 |
|    ent_coef        | 0.00021  |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 341255   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 752      |
|    fps             | 32       |
|    time_elapsed    | 10905    |
|    total_timesteps | 353256   |
| train/             |          |
|    actor_loss      | -0.0917  |
|    critic_loss     | 0.0047   |
|    ent_coef        | 0.0002   |
|    ent_coef_loss   | 0.485    |
|    learning_rate   | 0.0003   |
|    n_updates       | 343255   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 32       |
|    time_elapsed    | 10947    |
|    total_timesteps | 355256   |
| train/             |          |
|    actor_loss      | -0.0536  |
|    critic_loss     | 0.000506 |
|    ent_coef        | 0.000196 |
|    ent_coef_loss   | -0.115   |
|    learning_rate   | 0.0003   |
|    n_updates       | 345255   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 760      |
|    fps             | 32       |
|    time_elapsed    | 10998    |
|    total_timesteps | 357256   |
| train/             |          |
|    actor_loss      | -0.0474  |
|    critic_loss     | 0.000267 |
|    ent_coef        | 0.000201 |
|    ent_coef_loss   | -0.926   |
|    learning_rate   | 0.0003   |
|    n_updates       | 347255   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 764      |
|    fps             | 32       |
|    time_elapsed    | 11036    |
|    total_timesteps | 359256   |
| train/             |          |
|    actor_loss      | -0.0389  |
|    critic_loss     | 0.000205 |
|    ent_coef        | 0.000194 |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 349255   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=360000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -0.0374  |
|    critic_loss     | 0.000244 |
|    ent_coef        | 0.000197 |
|    ent_coef_loss   | -4.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 349999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 768      |
|    fps             | 32       |
|    time_elapsed    | 11150    |
|    total_timesteps | 361256   |
| train/             |          |
|    actor_loss      | -0.0181  |
|    critic_loss     | 0.000213 |
|    ent_coef        | 0.000185 |
|    ent_coef_loss   | -3.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 351255   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 772      |
|    fps             | 32       |
|    time_elapsed    | 11191    |
|    total_timesteps | 362762   |
| train/             |          |
|    actor_loss      | -0.0951  |
|    critic_loss     | 0.000387 |
|    ent_coef        | 0.00019  |
|    ent_coef_loss   | -3.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 352761   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 776      |
|    fps             | 32       |
|    time_elapsed    | 11243    |
|    total_timesteps | 364762   |
| train/             |          |
|    actor_loss      | -0.0524  |
|    critic_loss     | 0.000335 |
|    ent_coef        | 0.00018  |
|    ent_coef_loss   | 7.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 354761   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 780      |
|    fps             | 32       |
|    time_elapsed    | 11277    |
|    total_timesteps | 365774   |
| train/             |          |
|    actor_loss      | -0.0748  |
|    critic_loss     | 0.000232 |
|    ent_coef        | 0.00019  |
|    ent_coef_loss   | 0.928    |
|    learning_rate   | 0.0003   |
|    n_updates       | 355773   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 784      |
|    fps             | 32       |
|    time_elapsed    | 11315    |
|    total_timesteps | 367774   |
| train/             |          |
|    actor_loss      | -0.0491  |
|    critic_loss     | 0.000295 |
|    ent_coef        | 0.000181 |
|    ent_coef_loss   | 3.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 357773   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 788      |
|    fps             | 32       |
|    time_elapsed    | 11351    |
|    total_timesteps | 369281   |
| train/             |          |
|    actor_loss      | -0.056   |
|    critic_loss     | 0.000254 |
|    ent_coef        | 0.000176 |
|    ent_coef_loss   | 4.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 359280   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=370000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -0.0679  |
|    critic_loss     | 0.000247 |
|    ent_coef        | 0.000173 |
|    ent_coef_loss   | 1.89     |
|    learning_rate   | 0.0003   |
|    n_updates       | 359999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 792      |
|    fps             | 32       |
|    time_elapsed    | 11466    |
|    total_timesteps | 370338   |
| train/             |          |
|    actor_loss      | -0.0285  |
|    critic_loss     | 0.000411 |
|    ent_coef        | 0.000173 |
|    ent_coef_loss   | -0.549   |
|    learning_rate   | 0.0003   |
|    n_updates       | 360337   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 796      |
|    fps             | 32       |
|    time_elapsed    | 11521    |
|    total_timesteps | 372338   |
| train/             |          |
|    actor_loss      | -0.0304  |
|    critic_loss     | 0.000351 |
|    ent_coef        | 0.000172 |
|    ent_coef_loss   | -3.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 362337   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 800      |
|    fps             | 32       |
|    time_elapsed    | 11564    |
|    total_timesteps | 374338   |
| train/             |          |
|    actor_loss      | -0.0773  |
|    critic_loss     | 0.00255  |
|    ent_coef        | 0.000176 |
|    ent_coef_loss   | 0.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 364337   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 804      |
|    fps             | 32       |
|    time_elapsed    | 11595    |
|    total_timesteps | 375844   |
| train/             |          |
|    actor_loss      | -0.0321  |
|    critic_loss     | 0.000196 |
|    ent_coef        | 0.000173 |
|    ent_coef_loss   | 0.81     |
|    learning_rate   | 0.0003   |
|    n_updates       | 365843   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 808      |
|    fps             | 32       |
|    time_elapsed    | 11652    |
|    total_timesteps | 377844   |
| train/             |          |
|    actor_loss      | -0.0948  |
|    critic_loss     | 0.000637 |
|    ent_coef        | 0.000184 |
|    ent_coef_loss   | 4.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 367843   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 812      |
|    fps             | 32       |
|    time_elapsed    | 11699    |
|    total_timesteps | 379844   |
| train/             |          |
|    actor_loss      | -0.0374  |
|    critic_loss     | 0.00024  |
|    ent_coef        | 0.000193 |
|    ent_coef_loss   | 0.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 369843   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=380000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -0.0735  |
|    critic_loss     | 0.000524 |
|    ent_coef        | 0.000196 |
|    ent_coef_loss   | 0.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 369999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 816      |
|    fps             | 32       |
|    time_elapsed    | 11829    |
|    total_timesteps | 381844   |
| train/             |          |
|    actor_loss      | -0.122   |
|    critic_loss     | 0.000283 |
|    ent_coef        | 0.000191 |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 371843   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 820      |
|    fps             | 32       |
|    time_elapsed    | 11883    |
|    total_timesteps | 383844   |
| train/             |          |
|    actor_loss      | -0.0484  |
|    critic_loss     | 0.000134 |
|    ent_coef        | 0.000186 |
|    ent_coef_loss   | -0.967   |
|    learning_rate   | 0.0003   |
|    n_updates       | 373843   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 824      |
|    fps             | 32       |
|    time_elapsed    | 11923    |
|    total_timesteps | 385350   |
| train/             |          |
|    actor_loss      | -0.0504  |
|    critic_loss     | 0.00022  |
|    ent_coef        | 0.000178 |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 375349   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 828      |
|    fps             | 32       |
|    time_elapsed    | 11978    |
|    total_timesteps | 387350   |
| train/             |          |
|    actor_loss      | -0.00882 |
|    critic_loss     | 0.000221 |
|    ent_coef        | 0.000174 |
|    ent_coef_loss   | -7.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 377349   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 832      |
|    fps             | 32       |
|    time_elapsed    | 12027    |
|    total_timesteps | 389350   |
| train/             |          |
|    actor_loss      | -0.0738  |
|    critic_loss     | 0.000515 |
|    ent_coef        | 0.000173 |
|    ent_coef_loss   | 3.04     |
|    learning_rate   | 0.0003   |
|    n_updates       | 379349   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=390000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -0.0405  |
|    critic_loss     | 0.00026  |
|    ent_coef        | 0.000176 |
|    ent_coef_loss   | -5.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 379999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 836      |
|    fps             | 32       |
|    time_elapsed    | 12141    |
|    total_timesteps | 391350   |
| train/             |          |
|    actor_loss      | -0.0823  |
|    critic_loss     | 0.000328 |
|    ent_coef        | 0.000178 |
|    ent_coef_loss   | 6.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 381349   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 840      |
|    fps             | 32       |
|    time_elapsed    | 12164    |
|    total_timesteps | 391868   |
| train/             |          |
|    actor_loss      | -0.0249  |
|    critic_loss     | 0.000194 |
|    ent_coef        | 0.000175 |
|    ent_coef_loss   | 0.0357   |
|    learning_rate   | 0.0003   |
|    n_updates       | 381867   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 844      |
|    fps             | 32       |
|    time_elapsed    | 12215    |
|    total_timesteps | 393868   |
| train/             |          |
|    actor_loss      | -0.0465  |
|    critic_loss     | 0.000287 |
|    ent_coef        | 0.000181 |
|    ent_coef_loss   | -2.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 383867   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 848      |
|    fps             | 32       |
|    time_elapsed    | 12259    |
|    total_timesteps | 395868   |
| train/             |          |
|    actor_loss      | -0.0467  |
|    critic_loss     | 0.000155 |
|    ent_coef        | 0.000172 |
|    ent_coef_loss   | 4.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 385867   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 852      |
|    fps             | 32       |
|    time_elapsed    | 12300    |
|    total_timesteps | 397868   |
| train/             |          |
|    actor_loss      | -0.0307  |
|    critic_loss     | 0.000197 |
|    ent_coef        | 0.000167 |
|    ent_coef_loss   | 0.73     |
|    learning_rate   | 0.0003   |
|    n_updates       | 387867   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 856      |
|    fps             | 32       |
|    time_elapsed    | 12352    |
|    total_timesteps | 399868   |
| train/             |          |
|    actor_loss      | -0.0665  |
|    critic_loss     | 0.000227 |
|    ent_coef        | 0.00016  |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 389867   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -0.0577  |
|    critic_loss     | 0.000152 |
|    ent_coef        | 0.00016  |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 389999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 860      |
|    fps             | 32       |
|    time_elapsed    | 12493    |
|    total_timesteps | 401868   |
| train/             |          |
|    actor_loss      | -0.0263  |
|    critic_loss     | 0.00016  |
|    ent_coef        | 0.000156 |
|    ent_coef_loss   | -0.764   |
|    learning_rate   | 0.0003   |
|    n_updates       | 391867   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 864      |
|    fps             | 32       |
|    time_elapsed    | 12520    |
|    total_timesteps | 402882   |
| train/             |          |
|    actor_loss      | -0.0426  |
|    critic_loss     | 0.000165 |
|    ent_coef        | 0.000158 |
|    ent_coef_loss   | -2.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 392881   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 868      |
|    fps             | 32       |
|    time_elapsed    | 12559    |
|    total_timesteps | 404882   |
| train/             |          |
|    actor_loss      | -0.0297  |
|    critic_loss     | 0.000176 |
|    ent_coef        | 0.000153 |
|    ent_coef_loss   | -5.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 394881   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 872      |
|    fps             | 32       |
|    time_elapsed    | 12595    |
|    total_timesteps | 406882   |
| train/             |          |
|    actor_loss      | -0.0234  |
|    critic_loss     | 0.000134 |
|    ent_coef        | 0.000148 |
|    ent_coef_loss   | 0.169    |
|    learning_rate   | 0.0003   |
|    n_updates       | 396881   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 876      |
|    fps             | 32       |
|    time_elapsed    | 12642    |
|    total_timesteps | 408882   |
| train/             |          |
|    actor_loss      | -0.00783 |
|    critic_loss     | 9.43e-05 |
|    ent_coef        | 0.000148 |
|    ent_coef_loss   | -4.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 398881   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Eval num_timesteps=410000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -0.0261  |
|    critic_loss     | 0.000155 |
|    ent_coef        | 0.000143 |
|    ent_coef_loss   | -0.137   |
|    learning_rate   | 0.0003   |
|    n_updates       | 399999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 880      |
|    fps             | 32       |
|    time_elapsed    | 12768    |
|    total_timesteps | 410882   |
| train/             |          |
|    actor_loss      | -0.0465  |
|    critic_loss     | 0.000156 |
|    ent_coef        | 0.000138 |
|    ent_coef_loss   | 0.716    |
|    learning_rate   | 0.0003   |
|    n_updates       | 400881   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 884      |
|    fps             | 32       |
|    time_elapsed    | 12802    |
|    total_timesteps | 412390   |
| train/             |          |
|    actor_loss      | -0.00165 |
|    critic_loss     | 0.000172 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 402389   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 888      |
|    fps             | 32       |
|    time_elapsed    | 12844    |
|    total_timesteps | 414390   |
| train/             |          |
|    actor_loss      | -0.0406  |
|    critic_loss     | 0.000255 |
|    ent_coef        | 0.00014  |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 404389   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 892      |
|    fps             | 32       |
|    time_elapsed    | 12883    |
|    total_timesteps | 416390   |
| train/             |          |
|    actor_loss      | -0.0144  |
|    critic_loss     | 0.000138 |
|    ent_coef        | 0.000133 |
|    ent_coef_loss   | 0.493    |
|    learning_rate   | 0.0003   |
|    n_updates       | 406389   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 896      |
|    fps             | 32       |
|    time_elapsed    | 12913    |
|    total_timesteps | 417895   |
| train/             |          |
|    actor_loss      | -0.0242  |
|    critic_loss     | 0.000195 |
|    ent_coef        | 0.000134 |
|    ent_coef_loss   | 0.679    |
|    learning_rate   | 0.0003   |
|    n_updates       | 407894   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 900      |
|    fps             | 32       |
|    time_elapsed    | 12955    |
|    total_timesteps | 419895   |
| train/             |          |
|    actor_loss      | -0.0125  |
|    critic_loss     | 0.000211 |
|    ent_coef        | 0.000148 |
|    ent_coef_loss   | -0.521   |
|    learning_rate   | 0.0003   |
|    n_updates       | 409894   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Eval num_timesteps=420000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -0.0192  |
|    critic_loss     | 0.000145 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 0.795    |
|    learning_rate   | 0.0003   |
|    n_updates       | 409999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 904      |
|    fps             | 32       |
|    time_elapsed    | 13073    |
|    total_timesteps | 421895   |
| train/             |          |
|    actor_loss      | -0.0142  |
|    critic_loss     | 0.000175 |
|    ent_coef        | 0.000146 |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 411894   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 908      |
|    fps             | 32       |
|    time_elapsed    | 13110    |
|    total_timesteps | 423895   |
| train/             |          |
|    actor_loss      | -0.0261  |
|    critic_loss     | 0.000161 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 0.022    |
|    learning_rate   | 0.0003   |
|    n_updates       | 413894   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 912      |
|    fps             | 32       |
|    time_elapsed    | 13163    |
|    total_timesteps | 425895   |
| train/             |          |
|    actor_loss      | -0.00422 |
|    critic_loss     | 0.000132 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 3.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 415894   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 916      |
|    fps             | 32       |
|    time_elapsed    | 13213    |
|    total_timesteps | 427895   |
| train/             |          |
|    actor_loss      | -0.0106  |
|    critic_loss     | 0.000206 |
|    ent_coef        | 0.00015  |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 417894   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 920      |
|    fps             | 32       |
|    time_elapsed    | 13268    |
|    total_timesteps | 429401   |
| train/             |          |
|    actor_loss      | -0.0211  |
|    critic_loss     | 0.000222 |
|    ent_coef        | 0.000158 |
|    ent_coef_loss   | 2.72     |
|    learning_rate   | 0.0003   |
|    n_updates       | 419400   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=430000, episode_reward=0.10 +/- 0.30
Episode length: 450.80 +/- 147.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -0.0217  |
|    critic_loss     | 0.000141 |
|    ent_coef        | 0.000156 |
|    ent_coef_loss   | -2.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 419999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 924      |
|    fps             | 32       |
|    time_elapsed    | 13381    |
|    total_timesteps | 431401   |
| train/             |          |
|    actor_loss      | -0.0317  |
|    critic_loss     | 0.000299 |
|    ent_coef        | 0.000153 |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 421400   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 928      |
|    fps             | 32       |
|    time_elapsed    | 13418    |
|    total_timesteps | 433401   |
| train/             |          |
|    actor_loss      | -0.0147  |
|    critic_loss     | 0.000227 |
|    ent_coef        | 0.00017  |
|    ent_coef_loss   | -7.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 423400   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 932      |
|    fps             | 32       |
|    time_elapsed    | 13472    |
|    total_timesteps | 435401   |
| train/             |          |
|    actor_loss      | -0.0234  |
|    critic_loss     | 0.000291 |
|    ent_coef        | 0.000159 |
|    ent_coef_loss   | 5.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 425400   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 936      |
|    fps             | 32       |
|    time_elapsed    | 13507    |
|    total_timesteps | 436907   |
| train/             |          |
|    actor_loss      | -0.0222  |
|    critic_loss     | 0.000173 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 426906   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 470       |
|    ep_rew_mean     | 0.06      |
| time/              |           |
|    episodes        | 940       |
|    fps             | 32        |
|    time_elapsed    | 13547     |
|    total_timesteps | 438907    |
| train/             |           |
|    actor_loss      | -0.000281 |
|    critic_loss     | 0.00017   |
|    ent_coef        | 0.000166  |
|    ent_coef_loss   | -2.83     |
|    learning_rate   | 0.0003    |
|    n_updates       | 428906    |
----------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=440000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -0.00652 |
|    critic_loss     | 0.00093  |
|    ent_coef        | 0.000157 |
|    ent_coef_loss   | -3.1     |
|    learning_rate   | 0.0003   |
|    n_updates       | 429999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 944      |
|    fps             | 32       |
|    time_elapsed    | 13696    |
|    total_timesteps | 440413   |
| train/             |          |
|    actor_loss      | -0.0484  |
|    critic_loss     | 0.000183 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 3        |
|    learning_rate   | 0.0003   |
|    n_updates       | 430412   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 948      |
|    fps             | 32       |
|    time_elapsed    | 13746    |
|    total_timesteps | 442413   |
| train/             |          |
|    actor_loss      | -0.0226  |
|    critic_loss     | 0.000184 |
|    ent_coef        | 0.000159 |
|    ent_coef_loss   | 0.214    |
|    learning_rate   | 0.0003   |
|    n_updates       | 432412   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 952      |
|    fps             | 32       |
|    time_elapsed    | 13799    |
|    total_timesteps | 444413   |
| train/             |          |
|    actor_loss      | -0.0123  |
|    critic_loss     | 0.000149 |
|    ent_coef        | 0.000158 |
|    ent_coef_loss   | -0.781   |
|    learning_rate   | 0.0003   |
|    n_updates       | 434412   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 956      |
|    fps             | 32       |
|    time_elapsed    | 13839    |
|    total_timesteps | 446413   |
| train/             |          |
|    actor_loss      | -0.0211  |
|    critic_loss     | 0.00183  |
|    ent_coef        | 0.000156 |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 436412   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 960      |
|    fps             | 32       |
|    time_elapsed    | 13880    |
|    total_timesteps | 448413   |
| train/             |          |
|    actor_loss      | 0.00799  |
|    critic_loss     | 0.000256 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 0.359    |
|    learning_rate   | 0.0003   |
|    n_updates       | 438412   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 964      |
|    fps             | 32       |
|    time_elapsed    | 13906    |
|    total_timesteps | 449423   |
| train/             |          |
|    actor_loss      | -0.0369  |
|    critic_loss     | 0.000245 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 439422   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=450000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -0.00922 |
|    critic_loss     | 0.000132 |
|    ent_coef        | 0.000154 |
|    ent_coef_loss   | -4.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 439999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 968      |
|    fps             | 32       |
|    time_elapsed    | 14018    |
|    total_timesteps | 451423   |
| train/             |          |
|    actor_loss      | -0.0144  |
|    critic_loss     | 0.0113   |
|    ent_coef        | 0.000161 |
|    ent_coef_loss   | -5.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 441422   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 972      |
|    fps             | 32       |
|    time_elapsed    | 14056    |
|    total_timesteps | 453423   |
| train/             |          |
|    actor_loss      | 0.00323  |
|    critic_loss     | 0.000289 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 443422   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 976      |
|    fps             | 32       |
|    time_elapsed    | 14096    |
|    total_timesteps | 455423   |
| train/             |          |
|    actor_loss      | -0.0354  |
|    critic_loss     | 0.002    |
|    ent_coef        | 0.000148 |
|    ent_coef_loss   | -0.204   |
|    learning_rate   | 0.0003   |
|    n_updates       | 445422   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 980      |
|    fps             | 32       |
|    time_elapsed    | 14138    |
|    total_timesteps | 457423   |
| train/             |          |
|    actor_loss      | -0.00664 |
|    critic_loss     | 0.000363 |
|    ent_coef        | 0.000162 |
|    ent_coef_loss   | 0.568    |
|    learning_rate   | 0.0003   |
|    n_updates       | 447422   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 984      |
|    fps             | 32       |
|    time_elapsed    | 14183    |
|    total_timesteps | 459423   |
| train/             |          |
|    actor_loss      | 0.00381  |
|    critic_loss     | 0.000208 |
|    ent_coef        | 0.000153 |
|    ent_coef_loss   | -0.471   |
|    learning_rate   | 0.0003   |
|    n_updates       | 449422   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=460000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -0.0115  |
|    critic_loss     | 0.000248 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 0.824    |
|    learning_rate   | 0.0003   |
|    n_updates       | 449999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 988      |
|    fps             | 32       |
|    time_elapsed    | 14328    |
|    total_timesteps | 461423   |
| train/             |          |
|    actor_loss      | -0.00259 |
|    critic_loss     | 0.000836 |
|    ent_coef        | 0.000154 |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 451422   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 992      |
|    fps             | 32       |
|    time_elapsed    | 14366    |
|    total_timesteps | 463423   |
| train/             |          |
|    actor_loss      | 0.0158   |
|    critic_loss     | 0.000164 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | -0.0768  |
|    learning_rate   | 0.0003   |
|    n_updates       | 453422   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 996      |
|    fps             | 32       |
|    time_elapsed    | 14411    |
|    total_timesteps | 464436   |
| train/             |          |
|    actor_loss      | -0.00725 |
|    critic_loss     | 0.000191 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 3.49     |
|    learning_rate   | 0.0003   |
|    n_updates       | 454435   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 32       |
|    time_elapsed    | 14458    |
|    total_timesteps | 466436   |
| train/             |          |
|    actor_loss      | -0.0398  |
|    critic_loss     | 0.000255 |
|    ent_coef        | 0.000152 |
|    ent_coef_loss   | -0.933   |
|    learning_rate   | 0.0003   |
|    n_updates       | 456435   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 32       |
|    time_elapsed    | 14504    |
|    total_timesteps | 468436   |
| train/             |          |
|    actor_loss      | -0.0352  |
|    critic_loss     | 0.000165 |
|    ent_coef        | 0.000151 |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 458435   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=470000, episode_reward=0.30 +/- 0.46
Episode length: 351.80 +/- 226.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -0.0112  |
|    critic_loss     | 0.000148 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 459999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 32       |
|    time_elapsed    | 14623    |
|    total_timesteps | 470436   |
| train/             |          |
|    actor_loss      | -0.0144  |
|    critic_loss     | 0.000195 |
|    ent_coef        | 0.000147 |
|    ent_coef_loss   | -0.996   |
|    learning_rate   | 0.0003   |
|    n_updates       | 460435   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 32       |
|    time_elapsed    | 14669    |
|    total_timesteps | 472436   |
| train/             |          |
|    actor_loss      | 0.0172   |
|    critic_loss     | 0.000159 |
|    ent_coef        | 0.00015  |
|    ent_coef_loss   | -3.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 462435   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 32       |
|    time_elapsed    | 14707    |
|    total_timesteps | 474436   |
| train/             |          |
|    actor_loss      | 0.00162  |
|    critic_loss     | 0.000151 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 464435   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 32       |
|    time_elapsed    | 14759    |
|    total_timesteps | 476025   |
| train/             |          |
|    actor_loss      | -0.0113  |
|    critic_loss     | 0.000297 |
|    ent_coef        | 0.00015  |
|    ent_coef_loss   | -0.309   |
|    learning_rate   | 0.0003   |
|    n_updates       | 466024   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 32       |
|    time_elapsed    | 14794    |
|    total_timesteps | 477531   |
| train/             |          |
|    actor_loss      | -0.0429  |
|    critic_loss     | 0.00034  |
|    ent_coef        | 0.000147 |
|    ent_coef_loss   | -0.902   |
|    learning_rate   | 0.0003   |
|    n_updates       | 467530   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 32       |
|    time_elapsed    | 14827    |
|    total_timesteps | 479072   |
| train/             |          |
|    actor_loss      | -0.0438  |
|    critic_loss     | 0.000268 |
|    ent_coef        | 0.000146 |
|    ent_coef_loss   | 4.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 469071   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=480000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 500       |
|    mean_reward     | 0         |
| time/              |           |
|    total_timesteps | 480000    |
| train/             |           |
|    actor_loss      | -0.000867 |
|    critic_loss     | 0.000196  |
|    ent_coef        | 0.000152  |
|    ent_coef_loss   | -1.99     |
|    learning_rate   | 0.0003    |
|    n_updates       | 469999    |
----------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 32       |
|    time_elapsed    | 14940    |
|    total_timesteps | 480578   |
| train/             |          |
|    actor_loss      | -0.00921 |
|    critic_loss     | 0.000203 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 470577   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 32       |
|    time_elapsed    | 14987    |
|    total_timesteps | 482578   |
| train/             |          |
|    actor_loss      | 0.0133   |
|    critic_loss     | 0.000224 |
|    ent_coef        | 0.000143 |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 472577   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 32       |
|    time_elapsed    | 15030    |
|    total_timesteps | 484578   |
| train/             |          |
|    actor_loss      | 0.0248   |
|    critic_loss     | 0.000109 |
|    ent_coef        | 0.000151 |
|    ent_coef_loss   | -2.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 474577   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 32       |
|    time_elapsed    | 15062    |
|    total_timesteps | 486092   |
| train/             |          |
|    actor_loss      | 0.00763  |
|    critic_loss     | 0.000139 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | -0.845   |
|    learning_rate   | 0.0003   |
|    n_updates       | 476091   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 32       |
|    time_elapsed    | 15102    |
|    total_timesteps | 488092   |
| train/             |          |
|    actor_loss      | -0.00535 |
|    critic_loss     | 0.00015  |
|    ent_coef        | 0.000152 |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 0.0003   |
|    n_updates       | 478091   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Eval num_timesteps=490000, episode_reward=0.10 +/- 0.30
Episode length: 451.30 +/- 146.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -0.0226  |
|    critic_loss     | 0.000213 |
|    ent_coef        | 0.000158 |
|    ent_coef_loss   | 4.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 479999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 32       |
|    time_elapsed    | 15225    |
|    total_timesteps | 490092   |
| train/             |          |
|    actor_loss      | -0.0136  |
|    critic_loss     | 0.000156 |
|    ent_coef        | 0.000161 |
|    ent_coef_loss   | 0.386    |
|    learning_rate   | 0.0003   |
|    n_updates       | 480091   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 32       |
|    time_elapsed    | 15272    |
|    total_timesteps | 492092   |
| train/             |          |
|    actor_loss      | 0.00634  |
|    critic_loss     | 0.00467  |
|    ent_coef        | 0.000156 |
|    ent_coef_loss   | -1.82    |
|    learning_rate   | 0.0003   |
|    n_updates       | 482091   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 32       |
|    time_elapsed    | 15313    |
|    total_timesteps | 494092   |
| train/             |          |
|    actor_loss      | -0.0187  |
|    critic_loss     | 0.000126 |
|    ent_coef        | 0.000154 |
|    ent_coef_loss   | -0.487   |
|    learning_rate   | 0.0003   |
|    n_updates       | 484091   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 32       |
|    time_elapsed    | 15351    |
|    total_timesteps | 496092   |
| train/             |          |
|    actor_loss      | 0.00216  |
|    critic_loss     | 0.000117 |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | -0.501   |
|    learning_rate   | 0.0003   |
|    n_updates       | 486091   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 32       |
|    time_elapsed    | 15389    |
|    total_timesteps | 498092   |
| train/             |          |
|    actor_loss      | -0.0489  |
|    critic_loss     | 0.0018   |
|    ent_coef        | 0.000146 |
|    ent_coef_loss   | -1.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 488091   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=500000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -0.0221  |
|    critic_loss     | 0.000275 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 1.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 489999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 32       |
|    time_elapsed    | 15503    |
|    total_timesteps | 500092   |
| train/             |          |
|    actor_loss      | -0.0258  |
|    critic_loss     | 0.000289 |
|    ent_coef        | 0.000154 |
|    ent_coef_loss   | 0.211    |
|    learning_rate   | 0.0003   |
|    n_updates       | 490091   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 32       |
|    time_elapsed    | 15548    |
|    total_timesteps | 502092   |
| train/             |          |
|    actor_loss      | -0.00321 |
|    critic_loss     | 0.000292 |
|    ent_coef        | 0.000155 |
|    ent_coef_loss   | 3.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 492091   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 32       |
|    time_elapsed    | 15601    |
|    total_timesteps | 504092   |
| train/             |          |
|    actor_loss      | -0.0178  |
|    critic_loss     | 0.000226 |
|    ent_coef        | 0.000175 |
|    ent_coef_loss   | -0.562   |
|    learning_rate   | 0.0003   |
|    n_updates       | 494091   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 32       |
|    time_elapsed    | 15641    |
|    total_timesteps | 506092   |
| train/             |          |
|    actor_loss      | 0.0181   |
|    critic_loss     | 0.000173 |
|    ent_coef        | 0.00018  |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 496091   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 32       |
|    time_elapsed    | 15686    |
|    total_timesteps | 508092   |
| train/             |          |
|    actor_loss      | 0.00665  |
|    critic_loss     | 0.00166  |
|    ent_coef        | 0.000187 |
|    ent_coef_loss   | -2.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 498091   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=510000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -0.0325  |
|    critic_loss     | 0.000236 |
|    ent_coef        | 0.000191 |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 0.0003   |
|    n_updates       | 499999   |
---------------------------------
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 32       |
|    time_elapsed    | 15799    |
|    total_timesteps | 510092   |
| train/             |          |
|    actor_loss      | 0.0248   |
|    critic_loss     | 0.000274 |
|    ent_coef        | 0.000191 |
|    ent_coef_loss   | -0.409   |
|    learning_rate   | 0.0003   |
|    n_updates       | 500091   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 32       |
|    time_elapsed    | 15847    |
|    total_timesteps | 512092   |
| train/             |          |
|    actor_loss      | -0.0289  |
|    critic_loss     | 0.00044  |
|    ent_coef        | 0.000189 |
|    ent_coef_loss   | -0.737   |
|    learning_rate   | 0.0003   |
|    n_updates       | 502091   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 32       |
|    time_elapsed    | 15894    |
|    total_timesteps | 514092   |
| train/             |          |
|    actor_loss      | 0.0132   |
|    critic_loss     | 0.000342 |
|    ent_coef        | 0.000195 |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 504091   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 32       |
|    time_elapsed    | 15917    |
|    total_timesteps | 515104   |
| train/             |          |
|    actor_loss      | -0.00504 |
|    critic_loss     | 0.00772  |
|    ent_coef        | 0.000193 |
|    ent_coef_loss   | 0.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 505103   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 32       |
|    time_elapsed    | 15961    |
|    total_timesteps | 517104   |
| train/             |          |
|    actor_loss      | -0.00957 |
|    critic_loss     | 0.000375 |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | -0.627   |
|    learning_rate   | 0.0003   |
|    n_updates       | 507103   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 32       |
|    time_elapsed    | 16013    |
|    total_timesteps | 519104   |
| train/             |          |
|    actor_loss      | -0.00802 |
|    critic_loss     | 0.000324 |
|    ent_coef        | 0.000201 |
|    ent_coef_loss   | -0.229   |
|    learning_rate   | 0.0003   |
|    n_updates       | 509103   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=520000, episode_reward=0.20 +/- 0.40
Episode length: 401.20 +/- 197.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -0.00801 |
|    critic_loss     | 0.000498 |
|    ent_coef        | 0.000202 |
|    ent_coef_loss   | 1.3      |
|    learning_rate   | 0.0003   |
|    n_updates       | 509999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 462      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 32       |
|    time_elapsed    | 16125    |
|    total_timesteps | 520610   |
| train/             |          |
|    actor_loss      | -0.0655  |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000203 |
|    ent_coef_loss   | 5.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 510609   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 32       |
|    time_elapsed    | 16165    |
|    total_timesteps | 522610   |
| train/             |          |
|    actor_loss      | -0.0147  |
|    critic_loss     | 0.000423 |
|    ent_coef        | 0.000197 |
|    ent_coef_loss   | -1.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 512609   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 32       |
|    time_elapsed    | 16204    |
|    total_timesteps | 524119   |
| train/             |          |
|    actor_loss      | -0.0474  |
|    critic_loss     | 0.000342 |
|    ent_coef        | 0.000202 |
|    ent_coef_loss   | -0.266   |
|    learning_rate   | 0.0003   |
|    n_updates       | 514118   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 32       |
|    time_elapsed    | 16261    |
|    total_timesteps | 526119   |
| train/             |          |
|    actor_loss      | -0.0699  |
|    critic_loss     | 0.000406 |
|    ent_coef        | 0.000199 |
|    ent_coef_loss   | -0.00459 |
|    learning_rate   | 0.0003   |
|    n_updates       | 516118   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 32       |
|    time_elapsed    | 16304    |
|    total_timesteps | 528119   |
| train/             |          |
|    actor_loss      | -0.0376  |
|    critic_loss     | 0.000513 |
|    ent_coef        | 0.000221 |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 518118   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=530000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -0.00217 |
|    critic_loss     | 0.00278  |
|    ent_coef        | 0.000218 |
|    ent_coef_loss   | 0.752    |
|    learning_rate   | 0.0003   |
|    n_updates       | 519999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 32       |
|    time_elapsed    | 16444    |
|    total_timesteps | 530119   |
| train/             |          |
|    actor_loss      | -0.0329  |
|    critic_loss     | 0.00133  |
|    ent_coef        | 0.000223 |
|    ent_coef_loss   | 2.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 520118   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 32       |
|    time_elapsed    | 16484    |
|    total_timesteps | 532119   |
| train/             |          |
|    actor_loss      | -0.0108  |
|    critic_loss     | 0.00139  |
|    ent_coef        | 0.00022  |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 522118   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 32       |
|    time_elapsed    | 16523    |
|    total_timesteps | 534119   |
| train/             |          |
|    actor_loss      | -0.0107  |
|    critic_loss     | 0.000436 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | -0.0774  |
|    learning_rate   | 0.0003   |
|    n_updates       | 524118   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 32       |
|    time_elapsed    | 16551    |
|    total_timesteps | 535130   |
| train/             |          |
|    actor_loss      | -0.0725  |
|    critic_loss     | 0.000901 |
|    ent_coef        | 0.000253 |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 525129   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 32       |
|    time_elapsed    | 16607    |
|    total_timesteps | 537130   |
| train/             |          |
|    actor_loss      | -0.0297  |
|    critic_loss     | 0.000467 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | -0.965   |
|    learning_rate   | 0.0003   |
|    n_updates       | 527129   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 32       |
|    time_elapsed    | 16677    |
|    total_timesteps | 539130   |
| train/             |          |
|    actor_loss      | -0.0116  |
|    critic_loss     | 0.000553 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 529129   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Eval num_timesteps=540000, episode_reward=0.40 +/- 0.49
Episode length: 302.40 +/- 242.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 302      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -0.146   |
|    critic_loss     | 0.000808 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | -0.646   |
|    learning_rate   | 0.0003   |
|    n_updates       | 529999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 32       |
|    time_elapsed    | 16804    |
|    total_timesteps | 540636   |
| train/             |          |
|    actor_loss      | -0.0211  |
|    critic_loss     | 0.00187  |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 3.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 530635   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 32       |
|    time_elapsed    | 16843    |
|    total_timesteps | 542141   |
| train/             |          |
|    actor_loss      | -0.0323  |
|    critic_loss     | 0.000549 |
|    ent_coef        | 0.000247 |
|    ent_coef_loss   | -3.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 532140   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 32       |
|    time_elapsed    | 16873    |
|    total_timesteps | 543647   |
| train/             |          |
|    actor_loss      | 0.00373  |
|    critic_loss     | 0.00051  |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -3.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 533646   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 32       |
|    time_elapsed    | 16917    |
|    total_timesteps | 545647   |
| train/             |          |
|    actor_loss      | 0.00869  |
|    critic_loss     | 0.000472 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 535646   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 32       |
|    time_elapsed    | 16951    |
|    total_timesteps | 547152   |
| train/             |          |
|    actor_loss      | -0.0588  |
|    critic_loss     | 0.00118  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | 3.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 537151   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 32       |
|    time_elapsed    | 16991    |
|    total_timesteps | 548659   |
| train/             |          |
|    actor_loss      | -0.123   |
|    critic_loss     | 0.00103  |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 2.83     |
|    learning_rate   | 0.0003   |
|    n_updates       | 538658   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 32       |
|    time_elapsed    | 17022    |
|    total_timesteps | 549672   |
| train/             |          |
|    actor_loss      | 0.0146   |
|    critic_loss     | 0.00375  |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 539671   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -0.00415 |
|    critic_loss     | 0.000596 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -0.794   |
|    learning_rate   | 0.0003   |
|    n_updates       | 539999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 32       |
|    time_elapsed    | 17146    |
|    total_timesteps | 551672   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.000797 |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 541671   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 32       |
|    time_elapsed    | 17179    |
|    total_timesteps | 553179   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.000793 |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | -0.485   |
|    learning_rate   | 0.0003   |
|    n_updates       | 543178   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 32       |
|    time_elapsed    | 17217    |
|    total_timesteps | 555179   |
| train/             |          |
|    actor_loss      | -0.0142  |
|    critic_loss     | 0.000914 |
|    ent_coef        | 0.000322 |
|    ent_coef_loss   | -3.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 545178   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 32       |
|    time_elapsed    | 17255    |
|    total_timesteps | 556685   |
| train/             |          |
|    actor_loss      | -0.0292  |
|    critic_loss     | 0.000678 |
|    ent_coef        | 0.000337 |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 0.0003   |
|    n_updates       | 546684   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 32       |
|    time_elapsed    | 17287    |
|    total_timesteps | 558190   |
| train/             |          |
|    actor_loss      | -0.0332  |
|    critic_loss     | 0.000671 |
|    ent_coef        | 0.000334 |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 548189   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=560000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -0.0664  |
|    critic_loss     | 0.00108  |
|    ent_coef        | 0.000357 |
|    ent_coef_loss   | -0.654   |
|    learning_rate   | 0.0003   |
|    n_updates       | 549999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 32       |
|    time_elapsed    | 17413    |
|    total_timesteps | 560190   |
| train/             |          |
|    actor_loss      | -0.0658  |
|    critic_loss     | 0.00305  |
|    ent_coef        | 0.000355 |
|    ent_coef_loss   | -0.366   |
|    learning_rate   | 0.0003   |
|    n_updates       | 550189   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 32       |
|    time_elapsed    | 17452    |
|    total_timesteps | 562190   |
| train/             |          |
|    actor_loss      | -0.209   |
|    critic_loss     | 0.00183  |
|    ent_coef        | 0.000356 |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 552189   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 32       |
|    time_elapsed    | 17489    |
|    total_timesteps | 564190   |
| train/             |          |
|    actor_loss      | -0.0893  |
|    critic_loss     | 0.00604  |
|    ent_coef        | 0.000366 |
|    ent_coef_loss   | -2.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 554189   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 32       |
|    time_elapsed    | 17535    |
|    total_timesteps | 566190   |
| train/             |          |
|    actor_loss      | -0.0181  |
|    critic_loss     | 0.00216  |
|    ent_coef        | 0.000359 |
|    ent_coef_loss   | -0.688   |
|    learning_rate   | 0.0003   |
|    n_updates       | 556189   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 32       |
|    time_elapsed    | 17582    |
|    total_timesteps | 568190   |
| train/             |          |
|    actor_loss      | -0.0268  |
|    critic_loss     | 0.0023   |
|    ent_coef        | 0.000377 |
|    ent_coef_loss   | 0.833    |
|    learning_rate   | 0.0003   |
|    n_updates       | 558189   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 32       |
|    time_elapsed    | 17607    |
|    total_timesteps | 569204   |
| train/             |          |
|    actor_loss      | -0.0216  |
|    critic_loss     | 0.00164  |
|    ent_coef        | 0.000396 |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 559203   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=570000, episode_reward=0.20 +/- 0.40
Episode length: 401.20 +/- 197.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -0.122   |
|    critic_loss     | 0.00261  |
|    ent_coef        | 0.000401 |
|    ent_coef_loss   | 0.859    |
|    learning_rate   | 0.0003   |
|    n_updates       | 559999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 32       |
|    time_elapsed    | 17731    |
|    total_timesteps | 571145   |
| train/             |          |
|    actor_loss      | -0.0165  |
|    critic_loss     | 0.00118  |
|    ent_coef        | 0.000391 |
|    ent_coef_loss   | 0.178    |
|    learning_rate   | 0.0003   |
|    n_updates       | 561144   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 32       |
|    time_elapsed    | 17794    |
|    total_timesteps | 572976   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 0.00228  |
|    ent_coef        | 0.000432 |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 562975   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 32       |
|    time_elapsed    | 17820    |
|    total_timesteps | 573991   |
| train/             |          |
|    actor_loss      | -0.124   |
|    critic_loss     | 0.00262  |
|    ent_coef        | 0.000436 |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 563990   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 32       |
|    time_elapsed    | 17852    |
|    total_timesteps | 575496   |
| train/             |          |
|    actor_loss      | -0.0507  |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.000436 |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 565495   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 32       |
|    time_elapsed    | 17885    |
|    total_timesteps | 577002   |
| train/             |          |
|    actor_loss      | -0.0268  |
|    critic_loss     | 0.00154  |
|    ent_coef        | 0.000423 |
|    ent_coef_loss   | 0.813    |
|    learning_rate   | 0.0003   |
|    n_updates       | 567001   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 32       |
|    time_elapsed    | 17932    |
|    total_timesteps | 579002   |
| train/             |          |
|    actor_loss      | -0.166   |
|    critic_loss     | 0.00269  |
|    ent_coef        | 0.00044  |
|    ent_coef_loss   | 3.88     |
|    learning_rate   | 0.0003   |
|    n_updates       | 569001   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=580000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -0.0289  |
|    critic_loss     | 0.00692  |
|    ent_coef        | 0.000442 |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 569999   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 32       |
|    time_elapsed    | 18064    |
|    total_timesteps | 581002   |
| train/             |          |
|    actor_loss      | 0.0656   |
|    critic_loss     | 0.00125  |
|    ent_coef        | 0.000444 |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 0.0003   |
|    n_updates       | 571001   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 32       |
|    time_elapsed    | 18112    |
|    total_timesteps | 583002   |
| train/             |          |
|    actor_loss      | -0.0526  |
|    critic_loss     | 0.00183  |
|    ent_coef        | 0.000455 |
|    ent_coef_loss   | -4.78    |
|    learning_rate   | 0.0003   |
|    n_updates       | 573001   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 32       |
|    time_elapsed    | 18158    |
|    total_timesteps | 585002   |
| train/             |          |
|    actor_loss      | -0.03    |
|    critic_loss     | 0.00291  |
|    ent_coef        | 0.00043  |
|    ent_coef_loss   | -0.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 575001   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 32       |
|    time_elapsed    | 18199    |
|    total_timesteps | 586508   |
| train/             |          |
|    actor_loss      | 0.0636   |
|    critic_loss     | 0.00317  |
|    ent_coef        | 0.000463 |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 576507   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 32       |
|    time_elapsed    | 18239    |
|    total_timesteps | 588508   |
| train/             |          |
|    actor_loss      | -0.0717  |
|    critic_loss     | 0.00423  |
|    ent_coef        | 0.000463 |
|    ent_coef_loss   | 3.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 578507   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 32       |
|    time_elapsed    | 18273    |
|    total_timesteps | 589531   |
| train/             |          |
|    actor_loss      | 0.043    |
|    critic_loss     | 0.00243  |
|    ent_coef        | 0.000435 |
|    ent_coef_loss   | -3.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 579530   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=590000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -0.0283  |
|    critic_loss     | 0.00709  |
|    ent_coef        | 0.000426 |
|    ent_coef_loss   | -2.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 579999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 32       |
|    time_elapsed    | 18386    |
|    total_timesteps | 591531   |
| train/             |          |
|    actor_loss      | 0.0151   |
|    critic_loss     | 0.00238  |
|    ent_coef        | 0.000446 |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 581530   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 32       |
|    time_elapsed    | 18434    |
|    total_timesteps | 593531   |
| train/             |          |
|    actor_loss      | -0.0906  |
|    critic_loss     | 0.00371  |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 583530   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 32       |
|    time_elapsed    | 18477    |
|    total_timesteps | 595531   |
| train/             |          |
|    actor_loss      | 0.0717   |
|    critic_loss     | 0.00287  |
|    ent_coef        | 0.000477 |
|    ent_coef_loss   | 1.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 585530   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 32       |
|    time_elapsed    | 18516    |
|    total_timesteps | 597531   |
| train/             |          |
|    actor_loss      | 0.142    |
|    critic_loss     | 0.0995   |
|    ent_coef        | 0.000474 |
|    ent_coef_loss   | -2.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 587530   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 32       |
|    time_elapsed    | 18557    |
|    total_timesteps | 599531   |
| train/             |          |
|    actor_loss      | -0.00531 |
|    critic_loss     | 0.00177  |
|    ent_coef        | 0.000439 |
|    ent_coef_loss   | -4.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 589530   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=600000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -0.094   |
|    critic_loss     | 0.00178  |
|    ent_coef        | 0.000463 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 589999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 448      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 32       |
|    time_elapsed    | 18679    |
|    total_timesteps | 601531   |
| train/             |          |
|    actor_loss      | -0.0502  |
|    critic_loss     | 0.011    |
|    ent_coef        | 0.000463 |
|    ent_coef_loss   | 2.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 591530   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 32       |
|    time_elapsed    | 18717    |
|    total_timesteps | 603531   |
| train/             |          |
|    actor_loss      | -0.0288  |
|    critic_loss     | 0.00243  |
|    ent_coef        | 0.00048  |
|    ent_coef_loss   | -0.526   |
|    learning_rate   | 0.0003   |
|    n_updates       | 593530   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 448      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 32       |
|    time_elapsed    | 18755    |
|    total_timesteps | 605040   |
| train/             |          |
|    actor_loss      | 0.112    |
|    critic_loss     | 0.00319  |
|    ent_coef        | 0.000484 |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 0.0003   |
|    n_updates       | 595039   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 32       |
|    time_elapsed    | 18780    |
|    total_timesteps | 606051   |
| train/             |          |
|    actor_loss      | -0.0129  |
|    critic_loss     | 0.00336  |
|    ent_coef        | 0.000489 |
|    ent_coef_loss   | 0.113    |
|    learning_rate   | 0.0003   |
|    n_updates       | 596050   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 32       |
|    time_elapsed    | 18805    |
|    total_timesteps | 607064   |
| train/             |          |
|    actor_loss      | 0.00788  |
|    critic_loss     | 0.00492  |
|    ent_coef        | 0.00049  |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 597063   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 32       |
|    time_elapsed    | 18841    |
|    total_timesteps | 608569   |
| train/             |          |
|    actor_loss      | -0.0166  |
|    critic_loss     | 0.0032   |
|    ent_coef        | 0.000523 |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 598568   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 32       |
|    time_elapsed    | 18877    |
|    total_timesteps | 609585   |
| train/             |          |
|    actor_loss      | 0.0755   |
|    critic_loss     | 0.00257  |
|    ent_coef        | 0.000517 |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 599584   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=610000, episode_reward=0.20 +/- 0.40
Episode length: 401.10 +/- 197.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -0.128   |
|    critic_loss     | 0.0229   |
|    ent_coef        | 0.000523 |
|    ent_coef_loss   | -1.54    |
|    learning_rate   | 0.0003   |
|    n_updates       | 599999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 32       |
|    time_elapsed    | 19024    |
|    total_timesteps | 611585   |
| train/             |          |
|    actor_loss      | -0.192   |
|    critic_loss     | 0.00296  |
|    ent_coef        | 0.00054  |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 601584   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 32       |
|    time_elapsed    | 19080    |
|    total_timesteps | 613585   |
| train/             |          |
|    actor_loss      | -0.0266  |
|    critic_loss     | 0.00292  |
|    ent_coef        | 0.000543 |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 0.0003   |
|    n_updates       | 603584   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 421      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 32       |
|    time_elapsed    | 19112    |
|    total_timesteps | 615092   |
| train/             |          |
|    actor_loss      | -0.0713  |
|    critic_loss     | 0.00606  |
|    ent_coef        | 0.000565 |
|    ent_coef_loss   | 0.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 605091   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 32       |
|    time_elapsed    | 19158    |
|    total_timesteps | 617092   |
| train/             |          |
|    actor_loss      | 0.0562   |
|    critic_loss     | 0.00402  |
|    ent_coef        | 0.000576 |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 607091   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 32       |
|    time_elapsed    | 19184    |
|    total_timesteps | 618110   |
| train/             |          |
|    actor_loss      | 0.0124   |
|    critic_loss     | 0.00555  |
|    ent_coef        | 0.000568 |
|    ent_coef_loss   | 0.483    |
|    learning_rate   | 0.0003   |
|    n_updates       | 608109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=620000, episode_reward=0.30 +/- 0.46
Episode length: 351.90 +/- 226.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | 0.118    |
|    critic_loss     | 0.00267  |
|    ent_coef        | 0.000574 |
|    ent_coef_loss   | -2.98    |
|    learning_rate   | 0.0003   |
|    n_updates       | 609999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 32       |
|    time_elapsed    | 19289    |
|    total_timesteps | 620110   |
| train/             |          |
|    actor_loss      | 0.0662   |
|    critic_loss     | 0.00484  |
|    ent_coef        | 0.000573 |
|    ent_coef_loss   | -3.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 610109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 32       |
|    time_elapsed    | 19339    |
|    total_timesteps | 622110   |
| train/             |          |
|    actor_loss      | 0.0338   |
|    critic_loss     | 0.00911  |
|    ent_coef        | 0.000599 |
|    ent_coef_loss   | 0.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 612109   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 32       |
|    time_elapsed    | 19388    |
|    total_timesteps | 624110   |
| train/             |          |
|    actor_loss      | -0.00663 |
|    critic_loss     | 0.0046   |
|    ent_coef        | 0.000681 |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 614109   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 421      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 32       |
|    time_elapsed    | 19417    |
|    total_timesteps | 625122   |
| train/             |          |
|    actor_loss      | 0.0833   |
|    critic_loss     | 0.00548  |
|    ent_coef        | 0.000706 |
|    ent_coef_loss   | -3.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 615121   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 421      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 32       |
|    time_elapsed    | 19464    |
|    total_timesteps | 627122   |
| train/             |          |
|    actor_loss      | 0.033    |
|    critic_loss     | 0.00348  |
|    ent_coef        | 0.000729 |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 617121   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 32       |
|    time_elapsed    | 19504    |
|    total_timesteps | 629122   |
| train/             |          |
|    actor_loss      | 0.024    |
|    critic_loss     | 0.00408  |
|    ent_coef        | 0.000707 |
|    ent_coef_loss   | 0.693    |
|    learning_rate   | 0.0003   |
|    n_updates       | 619121   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=630000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | 0.126    |
|    critic_loss     | 0.0041   |
|    ent_coef        | 0.000702 |
|    ent_coef_loss   | -0.489   |
|    learning_rate   | 0.0003   |
|    n_updates       | 619999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 421      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 32       |
|    time_elapsed    | 19607    |
|    total_timesteps | 630628   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.00689  |
|    ent_coef        | 0.000702 |
|    ent_coef_loss   | -5.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 620627   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 32       |
|    time_elapsed    | 19641    |
|    total_timesteps | 631831   |
| train/             |          |
|    actor_loss      | -0.0204  |
|    critic_loss     | 0.00474  |
|    ent_coef        | 0.000732 |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 0.0003   |
|    n_updates       | 621830   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 32       |
|    time_elapsed    | 19681    |
|    total_timesteps | 633831   |
| train/             |          |
|    actor_loss      | -0.0235  |
|    critic_loss     | 0.00474  |
|    ent_coef        | 0.000716 |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 623830   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 32       |
|    time_elapsed    | 19717    |
|    total_timesteps | 635338   |
| train/             |          |
|    actor_loss      | 0.0929   |
|    critic_loss     | 0.0112   |
|    ent_coef        | 0.000722 |
|    ent_coef_loss   | -0.268   |
|    learning_rate   | 0.0003   |
|    n_updates       | 625337   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 32       |
|    time_elapsed    | 19750    |
|    total_timesteps | 636845   |
| train/             |          |
|    actor_loss      | -0.00886 |
|    critic_loss     | 0.0068   |
|    ent_coef        | 0.000706 |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 626844   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 32       |
|    time_elapsed    | 19794    |
|    total_timesteps | 638845   |
| train/             |          |
|    actor_loss      | -0.0403  |
|    critic_loss     | 0.0117   |
|    ent_coef        | 0.000682 |
|    ent_coef_loss   | -0.0806  |
|    learning_rate   | 0.0003   |
|    n_updates       | 628844   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 32       |
|    time_elapsed    | 19811    |
|    total_timesteps | 639380   |
| train/             |          |
|    actor_loss      | 0.0537   |
|    critic_loss     | 0.0063   |
|    ent_coef        | 0.000698 |
|    ent_coef_loss   | 3.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 629379   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=640000, episode_reward=0.30 +/- 0.46
Episode length: 355.50 +/- 220.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 356      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | 0.106    |
|    critic_loss     | 0.00493  |
|    ent_coef        | 0.000722 |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 0.0003   |
|    n_updates       | 629999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 395      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 32       |
|    time_elapsed    | 19934    |
|    total_timesteps | 641053   |
| train/             |          |
|    actor_loss      | -0.204   |
|    critic_loss     | 0.0104   |
|    ent_coef        | 0.000696 |
|    ent_coef_loss   | -0.416   |
|    learning_rate   | 0.0003   |
|    n_updates       | 631052   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 32       |
|    time_elapsed    | 19985    |
|    total_timesteps | 642679   |
| train/             |          |
|    actor_loss      | -0.247   |
|    critic_loss     | 0.00861  |
|    ent_coef        | 0.00072  |
|    ent_coef_loss   | 2.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 632678   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 32       |
|    time_elapsed    | 20018    |
|    total_timesteps | 644188   |
| train/             |          |
|    actor_loss      | 0.0325   |
|    critic_loss     | 0.00986  |
|    ent_coef        | 0.000714 |
|    ent_coef_loss   | -2.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 634187   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 401      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 32       |
|    time_elapsed    | 20055    |
|    total_timesteps | 646188   |
| train/             |          |
|    actor_loss      | 0.0288   |
|    critic_loss     | 0.0072   |
|    ent_coef        | 0.000777 |
|    ent_coef_loss   | 3.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 636187   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 32       |
|    time_elapsed    | 20091    |
|    total_timesteps | 647904   |
| train/             |          |
|    actor_loss      | 0.246    |
|    critic_loss     | 0.00719  |
|    ent_coef        | 0.000763 |
|    ent_coef_loss   | -0.244   |
|    learning_rate   | 0.0003   |
|    n_updates       | 637903   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 32       |
|    time_elapsed    | 20131    |
|    total_timesteps | 649904   |
| train/             |          |
|    actor_loss      | -0.128   |
|    critic_loss     | 0.0132   |
|    ent_coef        | 0.000737 |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 639903   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=650000, episode_reward=0.30 +/- 0.46
Episode length: 353.60 +/- 223.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 354      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -0.00619 |
|    critic_loss     | 0.0134   |
|    ent_coef        | 0.000732 |
|    ent_coef_loss   | 3.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 639999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 32       |
|    time_elapsed    | 20246    |
|    total_timesteps | 651904   |
| train/             |          |
|    actor_loss      | -0.0443  |
|    critic_loss     | 0.0178   |
|    ent_coef        | 0.000718 |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 641903   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 32       |
|    time_elapsed    | 20282    |
|    total_timesteps | 653412   |
| train/             |          |
|    actor_loss      | 0.118    |
|    critic_loss     | 0.00493  |
|    ent_coef        | 0.000746 |
|    ent_coef_loss   | 0.451    |
|    learning_rate   | 0.0003   |
|    n_updates       | 643411   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 32       |
|    time_elapsed    | 20307    |
|    total_timesteps | 654437   |
| train/             |          |
|    actor_loss      | 0.129    |
|    critic_loss     | 0.0126   |
|    ent_coef        | 0.000757 |
|    ent_coef_loss   | 0.431    |
|    learning_rate   | 0.0003   |
|    n_updates       | 644436   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 32       |
|    time_elapsed    | 20343    |
|    total_timesteps | 655943   |
| train/             |          |
|    actor_loss      | 0.147    |
|    critic_loss     | 0.0137   |
|    ent_coef        | 0.000752 |
|    ent_coef_loss   | 4.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 645942   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 32       |
|    time_elapsed    | 20382    |
|    total_timesteps | 657943   |
| train/             |          |
|    actor_loss      | 0.0773   |
|    critic_loss     | 0.00643  |
|    ent_coef        | 0.000769 |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 647942   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 32       |
|    time_elapsed    | 20433    |
|    total_timesteps | 659943   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.0173   |
|    ent_coef        | 0.000802 |
|    ent_coef_loss   | -0.913   |
|    learning_rate   | 0.0003   |
|    n_updates       | 649942   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=660000, episode_reward=0.10 +/- 0.30
Episode length: 451.20 +/- 146.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -0.00534 |
|    critic_loss     | 0.0143   |
|    ent_coef        | 0.000802 |
|    ent_coef_loss   | -0.584   |
|    learning_rate   | 0.0003   |
|    n_updates       | 649999   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 32       |
|    time_elapsed    | 20524    |
|    total_timesteps | 660977   |
| train/             |          |
|    actor_loss      | -0.0451  |
|    critic_loss     | 0.0107   |
|    ent_coef        | 0.000829 |
|    ent_coef_loss   | 0.365    |
|    learning_rate   | 0.0003   |
|    n_updates       | 650976   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 32       |
|    time_elapsed    | 20570    |
|    total_timesteps | 662977   |
| train/             |          |
|    actor_loss      | -0.447   |
|    critic_loss     | 0.0409   |
|    ent_coef        | 0.000879 |
|    ent_coef_loss   | 4.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 652976   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 404      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 32       |
|    time_elapsed    | 20601    |
|    total_timesteps | 664501   |
| train/             |          |
|    actor_loss      | 0.191    |
|    critic_loss     | 0.00761  |
|    ent_coef        | 0.000884 |
|    ent_coef_loss   | -5.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 654500   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 32       |
|    time_elapsed    | 20638    |
|    total_timesteps | 666501   |
| train/             |          |
|    actor_loss      | -0.144   |
|    critic_loss     | 0.262    |
|    ent_coef        | 0.000906 |
|    ent_coef_loss   | -0.0206  |
|    learning_rate   | 0.0003   |
|    n_updates       | 656500   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 32       |
|    time_elapsed    | 20676    |
|    total_timesteps | 668501   |
| train/             |          |
|    actor_loss      | -0.312   |
|    critic_loss     | 0.0261   |
|    ent_coef        | 0.000914 |
|    ent_coef_loss   | 0.879    |
|    learning_rate   | 0.0003   |
|    n_updates       | 658500   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=670000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -0.52    |
|    critic_loss     | 0.0257   |
|    ent_coef        | 0.000982 |
|    ent_coef_loss   | 0.915    |
|    learning_rate   | 0.0003   |
|    n_updates       | 659999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 32       |
|    time_elapsed    | 20809    |
|    total_timesteps | 670501   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.0198   |
|    ent_coef        | 0.000992 |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 660500   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 32       |
|    time_elapsed    | 20841    |
|    total_timesteps | 672012   |
| train/             |          |
|    actor_loss      | 0.15     |
|    critic_loss     | 0.0151   |
|    ent_coef        | 0.000956 |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 662011   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 32       |
|    time_elapsed    | 20871    |
|    total_timesteps | 673518   |
| train/             |          |
|    actor_loss      | -0.662   |
|    critic_loss     | 0.0216   |
|    ent_coef        | 0.00101  |
|    ent_coef_loss   | 4.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 663517   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 32       |
|    time_elapsed    | 20910    |
|    total_timesteps | 675518   |
| train/             |          |
|    actor_loss      | -0.471   |
|    critic_loss     | 0.144    |
|    ent_coef        | 0.00106  |
|    ent_coef_loss   | 4.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 665517   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 422      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 32       |
|    time_elapsed    | 20958    |
|    total_timesteps | 677518   |
| train/             |          |
|    actor_loss      | -0.621   |
|    critic_loss     | 0.0162   |
|    ent_coef        | 0.00106  |
|    ent_coef_loss   | -2.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 667517   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 32       |
|    time_elapsed    | 20999    |
|    total_timesteps | 679518   |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 0.0231   |
|    ent_coef        | 0.0011   |
|    ent_coef_loss   | 0.238    |
|    learning_rate   | 0.0003   |
|    n_updates       | 669517   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=680000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | 0.0584   |
|    critic_loss     | 0.0263   |
|    ent_coef        | 0.00112  |
|    ent_coef_loss   | -1.88    |
|    learning_rate   | 0.0003   |
|    n_updates       | 669999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 32       |
|    time_elapsed    | 21152    |
|    total_timesteps | 681518   |
| train/             |          |
|    actor_loss      | 0.0284   |
|    critic_loss     | 0.0203   |
|    ent_coef        | 0.00118  |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 671517   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 32       |
|    time_elapsed    | 21191    |
|    total_timesteps | 683518   |
| train/             |          |
|    actor_loss      | 0.0227   |
|    critic_loss     | 0.0274   |
|    ent_coef        | 0.00124  |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 673517   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 32       |
|    time_elapsed    | 21225    |
|    total_timesteps | 685023   |
| train/             |          |
|    actor_loss      | 0.232    |
|    critic_loss     | 0.0291   |
|    ent_coef        | 0.00128  |
|    ent_coef_loss   | 0.941    |
|    learning_rate   | 0.0003   |
|    n_updates       | 675022   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 443      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 32       |
|    time_elapsed    | 21266    |
|    total_timesteps | 687023   |
| train/             |          |
|    actor_loss      | 0.234    |
|    critic_loss     | 0.0157   |
|    ent_coef        | 0.00139  |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 0.0003   |
|    n_updates       | 677022   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 438      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 32       |
|    time_elapsed    | 21292    |
|    total_timesteps | 688036   |
| train/             |          |
|    actor_loss      | -0.024   |
|    critic_loss     | 0.0229   |
|    ent_coef        | 0.00137  |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 678035   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=690000, episode_reward=0.30 +/- 0.46
Episode length: 367.10 +/- 206.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 367      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -0.197   |
|    critic_loss     | 0.115    |
|    ent_coef        | 0.00138  |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 679999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 438      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 32       |
|    time_elapsed    | 21408    |
|    total_timesteps | 690036   |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.0379   |
|    ent_coef        | 0.00138  |
|    ent_coef_loss   | 2.81     |
|    learning_rate   | 0.0003   |
|    n_updates       | 680035   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 32       |
|    time_elapsed    | 21453    |
|    total_timesteps | 691542   |
| train/             |          |
|    actor_loss      | -0.245   |
|    critic_loss     | 0.0733   |
|    ent_coef        | 0.00141  |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 681541   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 32       |
|    time_elapsed    | 21495    |
|    total_timesteps | 693542   |
| train/             |          |
|    actor_loss      | -0.0346  |
|    critic_loss     | 0.0289   |
|    ent_coef        | 0.00149  |
|    ent_coef_loss   | 3.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 683541   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 32       |
|    time_elapsed    | 21538    |
|    total_timesteps | 695542   |
| train/             |          |
|    actor_loss      | -0.409   |
|    critic_loss     | 0.0546   |
|    ent_coef        | 0.00151  |
|    ent_coef_loss   | -0.774   |
|    learning_rate   | 0.0003   |
|    n_updates       | 685541   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 32       |
|    time_elapsed    | 21570    |
|    total_timesteps | 697048   |
| train/             |          |
|    actor_loss      | -0.291   |
|    critic_loss     | 0.0415   |
|    ent_coef        | 0.00158  |
|    ent_coef_loss   | 0.657    |
|    learning_rate   | 0.0003   |
|    n_updates       | 687047   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 32       |
|    time_elapsed    | 21611    |
|    total_timesteps | 699048   |
| train/             |          |
|    actor_loss      | 0.0102   |
|    critic_loss     | 0.0417   |
|    ent_coef        | 0.00167  |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 689047   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | 0.154    |
|    critic_loss     | 0.0305   |
|    ent_coef        | 0.00168  |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 689999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 32       |
|    time_elapsed    | 21725    |
|    total_timesteps | 701048   |
| train/             |          |
|    actor_loss      | -0.289   |
|    critic_loss     | 0.0483   |
|    ent_coef        | 0.00172  |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 0.0003   |
|    n_updates       | 691047   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 32       |
|    time_elapsed    | 21769    |
|    total_timesteps | 703048   |
| train/             |          |
|    actor_loss      | -0.147   |
|    critic_loss     | 0.0543   |
|    ent_coef        | 0.00177  |
|    ent_coef_loss   | -2.53    |
|    learning_rate   | 0.0003   |
|    n_updates       | 693047   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 32       |
|    time_elapsed    | 21801    |
|    total_timesteps | 704555   |
| train/             |          |
|    actor_loss      | 0.101    |
|    critic_loss     | 0.0379   |
|    ent_coef        | 0.00191  |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 694554   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 32       |
|    time_elapsed    | 21841    |
|    total_timesteps | 706555   |
| train/             |          |
|    actor_loss      | 0.0852   |
|    critic_loss     | 0.0277   |
|    ent_coef        | 0.00189  |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 696554   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 32       |
|    time_elapsed    | 21888    |
|    total_timesteps | 708555   |
| train/             |          |
|    actor_loss      | -0.886   |
|    critic_loss     | 0.0454   |
|    ent_coef        | 0.00198  |
|    ent_coef_loss   | -0.587   |
|    learning_rate   | 0.0003   |
|    n_updates       | 698554   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=710000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -0.547   |
|    critic_loss     | 0.0836   |
|    ent_coef        | 0.00213  |
|    ent_coef_loss   | -0.616   |
|    learning_rate   | 0.0003   |
|    n_updates       | 699999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 32       |
|    time_elapsed    | 22011    |
|    total_timesteps | 710169   |
| train/             |          |
|    actor_loss      | -0.904   |
|    critic_loss     | 0.322    |
|    ent_coef        | 0.00212  |
|    ent_coef_loss   | 0.902    |
|    learning_rate   | 0.0003   |
|    n_updates       | 700168   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 32       |
|    time_elapsed    | 22061    |
|    total_timesteps | 712169   |
| train/             |          |
|    actor_loss      | -1.11    |
|    critic_loss     | 0.054    |
|    ent_coef        | 0.00209  |
|    ent_coef_loss   | 4.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 702168   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 32       |
|    time_elapsed    | 22115    |
|    total_timesteps | 714169   |
| train/             |          |
|    actor_loss      | -1.05    |
|    critic_loss     | 0.0805   |
|    ent_coef        | 0.00211  |
|    ent_coef_loss   | 4.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 704168   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 32       |
|    time_elapsed    | 22161    |
|    total_timesteps | 716054   |
| train/             |          |
|    actor_loss      | -0.472   |
|    critic_loss     | 0.104    |
|    ent_coef        | 0.00218  |
|    ent_coef_loss   | -0.175   |
|    learning_rate   | 0.0003   |
|    n_updates       | 706053   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 32       |
|    time_elapsed    | 22198    |
|    total_timesteps | 718054   |
| train/             |          |
|    actor_loss      | -0.442   |
|    critic_loss     | 0.0644   |
|    ent_coef        | 0.00232  |
|    ent_coef_loss   | 0.464    |
|    learning_rate   | 0.0003   |
|    n_updates       | 708053   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=720000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -0.0834  |
|    critic_loss     | 0.0814   |
|    ent_coef        | 0.00238  |
|    ent_coef_loss   | 3.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 709999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 32       |
|    time_elapsed    | 22341    |
|    total_timesteps | 720054   |
| train/             |          |
|    actor_loss      | -1.43    |
|    critic_loss     | 0.328    |
|    ent_coef        | 0.00239  |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 710053   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 32       |
|    time_elapsed    | 22389    |
|    total_timesteps | 722054   |
| train/             |          |
|    actor_loss      | -0.731   |
|    critic_loss     | 0.121    |
|    ent_coef        | 0.00279  |
|    ent_coef_loss   | 0.482    |
|    learning_rate   | 0.0003   |
|    n_updates       | 712053   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 32       |
|    time_elapsed    | 22436    |
|    total_timesteps | 724054   |
| train/             |          |
|    actor_loss      | -1.07    |
|    critic_loss     | 0.418    |
|    ent_coef        | 0.00275  |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 714053   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 32       |
|    time_elapsed    | 22476    |
|    total_timesteps | 726054   |
| train/             |          |
|    actor_loss      | -0.376   |
|    critic_loss     | 0.108    |
|    ent_coef        | 0.0028   |
|    ent_coef_loss   | -3.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 716053   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 32       |
|    time_elapsed    | 22524    |
|    total_timesteps | 728054   |
| train/             |          |
|    actor_loss      | -0.514   |
|    critic_loss     | 0.131    |
|    ent_coef        | 0.00275  |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 718053   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=730000, episode_reward=0.10 +/- 0.30
Episode length: 450.70 +/- 147.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -0.348   |
|    critic_loss     | 0.127    |
|    ent_coef        | 0.00287  |
|    ent_coef_loss   | 0.725    |
|    learning_rate   | 0.0003   |
|    n_updates       | 719999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 32       |
|    time_elapsed    | 22649    |
|    total_timesteps | 730054   |
| train/             |          |
|    actor_loss      | -1.48    |
|    critic_loss     | 0.271    |
|    ent_coef        | 0.00288  |
|    ent_coef_loss   | 4.22     |
|    learning_rate   | 0.0003   |
|    n_updates       | 720053   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 32       |
|    time_elapsed    | 22688    |
|    total_timesteps | 732054   |
| train/             |          |
|    actor_loss      | -0.337   |
|    critic_loss     | 0.189    |
|    ent_coef        | 0.00292  |
|    ent_coef_loss   | 0.168    |
|    learning_rate   | 0.0003   |
|    n_updates       | 722053   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 32       |
|    time_elapsed    | 22733    |
|    total_timesteps | 734018   |
| train/             |          |
|    actor_loss      | -0.625   |
|    critic_loss     | 0.1      |
|    ent_coef        | 0.00311  |
|    ent_coef_loss   | -0.514   |
|    learning_rate   | 0.0003   |
|    n_updates       | 724017   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 32       |
|    time_elapsed    | 22770    |
|    total_timesteps | 736018   |
| train/             |          |
|    actor_loss      | -0.0171  |
|    critic_loss     | 0.103    |
|    ent_coef        | 0.0032   |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 726017   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 32       |
|    time_elapsed    | 22810    |
|    total_timesteps | 737530   |
| train/             |          |
|    actor_loss      | -1.15    |
|    critic_loss     | 0.287    |
|    ent_coef        | 0.00316  |
|    ent_coef_loss   | 1.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 727529   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 32       |
|    time_elapsed    | 22849    |
|    total_timesteps | 739530   |
| train/             |          |
|    actor_loss      | -1.64    |
|    critic_loss     | 0.263    |
|    ent_coef        | 0.00326  |
|    ent_coef_loss   | 4.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 729529   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=740000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -1.6     |
|    critic_loss     | 1.18     |
|    ent_coef        | 0.00327  |
|    ent_coef_loss   | 3.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 729999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 32       |
|    time_elapsed    | 22980    |
|    total_timesteps | 741530   |
| train/             |          |
|    actor_loss      | -0.86    |
|    critic_loss     | 0.377    |
|    ent_coef        | 0.0032   |
|    ent_coef_loss   | -2.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 731529   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 32       |
|    time_elapsed    | 23015    |
|    total_timesteps | 742543   |
| train/             |          |
|    actor_loss      | -1.13    |
|    critic_loss     | 0.277    |
|    ent_coef        | 0.00342  |
|    ent_coef_loss   | 2.62     |
|    learning_rate   | 0.0003   |
|    n_updates       | 732542   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 32       |
|    time_elapsed    | 23047    |
|    total_timesteps | 744080   |
| train/             |          |
|    actor_loss      | -0.873   |
|    critic_loss     | 0.206    |
|    ent_coef        | 0.00346  |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 734079   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 32       |
|    time_elapsed    | 23084    |
|    total_timesteps | 746080   |
| train/             |          |
|    actor_loss      | -2.07    |
|    critic_loss     | 0.153    |
|    ent_coef        | 0.00362  |
|    ent_coef_loss   | 0.281    |
|    learning_rate   | 0.0003   |
|    n_updates       | 736079   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 32       |
|    time_elapsed    | 23105    |
|    total_timesteps | 746619   |
| train/             |          |
|    actor_loss      | -0.304   |
|    critic_loss     | 0.15     |
|    ent_coef        | 0.00355  |
|    ent_coef_loss   | -1.77    |
|    learning_rate   | 0.0003   |
|    n_updates       | 736618   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 32       |
|    time_elapsed    | 23150    |
|    total_timesteps | 748619   |
| train/             |          |
|    actor_loss      | -1.86    |
|    critic_loss     | 0.185    |
|    ent_coef        | 0.00343  |
|    ent_coef_loss   | 1.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 738618   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=750000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -1.57    |
|    critic_loss     | 0.747    |
|    ent_coef        | 0.00381  |
|    ent_coef_loss   | -4.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 739999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 32       |
|    time_elapsed    | 23259    |
|    total_timesteps | 750126   |
| train/             |          |
|    actor_loss      | -0.363   |
|    critic_loss     | 0.194    |
|    ent_coef        | 0.00378  |
|    ent_coef_loss   | -3.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 740125   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 32       |
|    time_elapsed    | 23298    |
|    total_timesteps | 752126   |
| train/             |          |
|    actor_loss      | -1.37    |
|    critic_loss     | 0.159    |
|    ent_coef        | 0.00368  |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 742125   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 32       |
|    time_elapsed    | 23338    |
|    total_timesteps | 753643   |
| train/             |          |
|    actor_loss      | -2.08    |
|    critic_loss     | 0.256    |
|    ent_coef        | 0.004    |
|    ent_coef_loss   | 2.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 743642   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 32       |
|    time_elapsed    | 23386    |
|    total_timesteps | 755148   |
| train/             |          |
|    actor_loss      | -0.96    |
|    critic_loss     | 0.234    |
|    ent_coef        | 0.00438  |
|    ent_coef_loss   | 2.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 745147   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 32       |
|    time_elapsed    | 23427    |
|    total_timesteps | 757148   |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.244    |
|    ent_coef        | 0.00422  |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 747147   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 32       |
|    time_elapsed    | 23467    |
|    total_timesteps | 759148   |
| train/             |          |
|    actor_loss      | -1.66    |
|    critic_loss     | 0.343    |
|    ent_coef        | 0.00451  |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 0.0003   |
|    n_updates       | 749147   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=760000, episode_reward=0.10 +/- 0.30
Episode length: 453.60 +/- 139.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -1.79    |
|    critic_loss     | 0.416    |
|    ent_coef        | 0.00429  |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 749999   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 32       |
|    time_elapsed    | 23618    |
|    total_timesteps | 761148   |
| train/             |          |
|    actor_loss      | -1.4     |
|    critic_loss     | 0.262    |
|    ent_coef        | 0.00446  |
|    ent_coef_loss   | -0.568   |
|    learning_rate   | 0.0003   |
|    n_updates       | 751147   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 32       |
|    time_elapsed    | 23653    |
|    total_timesteps | 762925   |
| train/             |          |
|    actor_loss      | -2.65    |
|    critic_loss     | 0.286    |
|    ent_coef        | 0.00476  |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 0.0003   |
|    n_updates       | 752924   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 32       |
|    time_elapsed    | 23690    |
|    total_timesteps | 764925   |
| train/             |          |
|    actor_loss      | -1.23    |
|    critic_loss     | 0.413    |
|    ent_coef        | 0.00465  |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 0.0003   |
|    n_updates       | 754924   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 32       |
|    time_elapsed    | 23728    |
|    total_timesteps | 766925   |
| train/             |          |
|    actor_loss      | -6.42    |
|    critic_loss     | 0.663    |
|    ent_coef        | 0.00503  |
|    ent_coef_loss   | 0.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 756924   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 32       |
|    time_elapsed    | 23774    |
|    total_timesteps | 768925   |
| train/             |          |
|    actor_loss      | -2.72    |
|    critic_loss     | 0.391    |
|    ent_coef        | 0.00546  |
|    ent_coef_loss   | 1.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 758924   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=770000, episode_reward=0.30 +/- 0.46
Episode length: 351.80 +/- 226.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -3.79    |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.00534  |
|    ent_coef_loss   | 0.794    |
|    learning_rate   | 0.0003   |
|    n_updates       | 759999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 32       |
|    time_elapsed    | 23862    |
|    total_timesteps | 770235   |
| train/             |          |
|    actor_loss      | -2.95    |
|    critic_loss     | 0.674    |
|    ent_coef        | 0.00537  |
|    ent_coef_loss   | 0.253    |
|    learning_rate   | 0.0003   |
|    n_updates       | 760234   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 32       |
|    time_elapsed    | 23909    |
|    total_timesteps | 772235   |
| train/             |          |
|    actor_loss      | -5.06    |
|    critic_loss     | 1.29     |
|    ent_coef        | 0.0057   |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 0.0003   |
|    n_updates       | 762234   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 32       |
|    time_elapsed    | 23941    |
|    total_timesteps | 773741   |
| train/             |          |
|    actor_loss      | -1.85    |
|    critic_loss     | 0.75     |
|    ent_coef        | 0.00543  |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 0.0003   |
|    n_updates       | 763740   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 32       |
|    time_elapsed    | 23984    |
|    total_timesteps | 775741   |
| train/             |          |
|    actor_loss      | -3.27    |
|    critic_loss     | 0.366    |
|    ent_coef        | 0.00585  |
|    ent_coef_loss   | 2.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 765740   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 32       |
|    time_elapsed    | 24022    |
|    total_timesteps | 777741   |
| train/             |          |
|    actor_loss      | -3.27    |
|    critic_loss     | 0.586    |
|    ent_coef        | 0.00643  |
|    ent_coef_loss   | -0.297   |
|    learning_rate   | 0.0003   |
|    n_updates       | 767740   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 32       |
|    time_elapsed    | 24055    |
|    total_timesteps | 779246   |
| train/             |          |
|    actor_loss      | -2.34    |
|    critic_loss     | 2.58     |
|    ent_coef        | 0.00662  |
|    ent_coef_loss   | 0.845    |
|    learning_rate   | 0.0003   |
|    n_updates       | 769245   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Eval num_timesteps=780000, episode_reward=0.10 +/- 0.30
Episode length: 450.80 +/- 147.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -2.18    |
|    critic_loss     | 0.481    |
|    ent_coef        | 0.00682  |
|    ent_coef_loss   | -0.713   |
|    learning_rate   | 0.0003   |
|    n_updates       | 769999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 32       |
|    time_elapsed    | 24169    |
|    total_timesteps | 780752   |
| train/             |          |
|    actor_loss      | -5.94    |
|    critic_loss     | 0.787    |
|    ent_coef        | 0.00676  |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 770751   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 32       |
|    time_elapsed    | 24200    |
|    total_timesteps | 782260   |
| train/             |          |
|    actor_loss      | -6.01    |
|    critic_loss     | 1.06     |
|    ent_coef        | 0.00675  |
|    ent_coef_loss   | 1.22     |
|    learning_rate   | 0.0003   |
|    n_updates       | 772259   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 422      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 32       |
|    time_elapsed    | 24234    |
|    total_timesteps | 783766   |
| train/             |          |
|    actor_loss      | -3.09    |
|    critic_loss     | 1.12     |
|    ent_coef        | 0.00725  |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 773765   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 32       |
|    time_elapsed    | 24278    |
|    total_timesteps | 785766   |
| train/             |          |
|    actor_loss      | -7.08    |
|    critic_loss     | 1.18     |
|    ent_coef        | 0.00752  |
|    ent_coef_loss   | 0.0378   |
|    learning_rate   | 0.0003   |
|    n_updates       | 775765   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 32       |
|    time_elapsed    | 24316    |
|    total_timesteps | 787766   |
| train/             |          |
|    actor_loss      | -1.64    |
|    critic_loss     | 0.837    |
|    ent_coef        | 0.00757  |
|    ent_coef_loss   | -0.209   |
|    learning_rate   | 0.0003   |
|    n_updates       | 777765   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 32       |
|    time_elapsed    | 24358    |
|    total_timesteps | 789766   |
| train/             |          |
|    actor_loss      | -2.23    |
|    critic_loss     | 0.764    |
|    ent_coef        | 0.00826  |
|    ent_coef_loss   | 0.834    |
|    learning_rate   | 0.0003   |
|    n_updates       | 779765   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=790000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -5.71    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0082   |
|    ent_coef_loss   | 0.914    |
|    learning_rate   | 0.0003   |
|    n_updates       | 779999   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 32       |
|    time_elapsed    | 24465    |
|    total_timesteps | 791766   |
| train/             |          |
|    actor_loss      | -6.98    |
|    critic_loss     | 0.995    |
|    ent_coef        | 0.00812  |
|    ent_coef_loss   | 0.666    |
|    learning_rate   | 0.0003   |
|    n_updates       | 781765   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 32       |
|    time_elapsed    | 24508    |
|    total_timesteps | 793766   |
| train/             |          |
|    actor_loss      | -2.22    |
|    critic_loss     | 0.985    |
|    ent_coef        | 0.00855  |
|    ent_coef_loss   | -0.0592  |
|    learning_rate   | 0.0003   |
|    n_updates       | 783765   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 32       |
|    time_elapsed    | 24551    |
|    total_timesteps | 795766   |
| train/             |          |
|    actor_loss      | -4.82    |
|    critic_loss     | 1.02     |
|    ent_coef        | 0.00846  |
|    ent_coef_loss   | 2.34     |
|    learning_rate   | 0.0003   |
|    n_updates       | 785765   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 32       |
|    time_elapsed    | 24597    |
|    total_timesteps | 797766   |
| train/             |          |
|    actor_loss      | -7.63    |
|    critic_loss     | 2.51     |
|    ent_coef        | 0.00895  |
|    ent_coef_loss   | 0.263    |
|    learning_rate   | 0.0003   |
|    n_updates       | 787765   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 32       |
|    time_elapsed    | 24638    |
|    total_timesteps | 799766   |
| train/             |          |
|    actor_loss      | -4.35    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.00876  |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 789765   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Eval num_timesteps=800000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -14.1    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.00866  |
|    ent_coef_loss   | 0.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 789999   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 32       |
|    time_elapsed    | 24765    |
|    total_timesteps | 801766   |
| train/             |          |
|    actor_loss      | -3.89    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.0087   |
|    ent_coef_loss   | 0.324    |
|    learning_rate   | 0.0003   |
|    n_updates       | 791765   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 32       |
|    time_elapsed    | 24802    |
|    total_timesteps | 803766   |
| train/             |          |
|    actor_loss      | -3.16    |
|    critic_loss     | 1.18     |
|    ent_coef        | 0.00877  |
|    ent_coef_loss   | -4.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 793765   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 32       |
|    time_elapsed    | 24842    |
|    total_timesteps | 805273   |
| train/             |          |
|    actor_loss      | -5.41    |
|    critic_loss     | 0.741    |
|    ent_coef        | 0.00859  |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 795272   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 32       |
|    time_elapsed    | 24888    |
|    total_timesteps | 807273   |
| train/             |          |
|    actor_loss      | -6.89    |
|    critic_loss     | 0.906    |
|    ent_coef        | 0.00926  |
|    ent_coef_loss   | 0.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 797272   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 32       |
|    time_elapsed    | 24944    |
|    total_timesteps | 809273   |
| train/             |          |
|    actor_loss      | -4.27    |
|    critic_loss     | 1.45     |
|    ent_coef        | 0.00965  |
|    ent_coef_loss   | 0.481    |
|    learning_rate   | 0.0003   |
|    n_updates       | 799272   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=810000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -2.52    |
|    critic_loss     | 7.34     |
|    ent_coef        | 0.00997  |
|    ent_coef_loss   | -0.229   |
|    learning_rate   | 0.0003   |
|    n_updates       | 799999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 32       |
|    time_elapsed    | 25073    |
|    total_timesteps | 811273   |
| train/             |          |
|    actor_loss      | -1.12    |
|    critic_loss     | 1.02     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -2       |
|    learning_rate   | 0.0003   |
|    n_updates       | 801272   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 32       |
|    time_elapsed    | 25117    |
|    total_timesteps | 813273   |
| train/             |          |
|    actor_loss      | -7.46    |
|    critic_loss     | 1.83     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | 0.178    |
|    learning_rate   | 0.0003   |
|    n_updates       | 803272   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 32       |
|    time_elapsed    | 25154    |
|    total_timesteps | 815273   |
| train/             |          |
|    actor_loss      | -4.76    |
|    critic_loss     | 1.25     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 0.791    |
|    learning_rate   | 0.0003   |
|    n_updates       | 805272   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 32       |
|    time_elapsed    | 25198    |
|    total_timesteps | 817273   |
| train/             |          |
|    actor_loss      | -5.66    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 807272   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 32       |
|    time_elapsed    | 25246    |
|    total_timesteps | 819273   |
| train/             |          |
|    actor_loss      | -2.86    |
|    critic_loss     | 1.03     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 1.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 809272   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=820000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -6.95    |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 2.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 809999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 32       |
|    time_elapsed    | 25364    |
|    total_timesteps | 821273   |
| train/             |          |
|    actor_loss      | -10.9    |
|    critic_loss     | 8.38     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 2.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 811272   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 32       |
|    time_elapsed    | 25403    |
|    total_timesteps | 823273   |
| train/             |          |
|    actor_loss      | -5.63    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.823   |
|    learning_rate   | 0.0003   |
|    n_updates       | 813272   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 32       |
|    time_elapsed    | 25457    |
|    total_timesteps | 825273   |
| train/             |          |
|    actor_loss      | -4.43    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 815272   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 32       |
|    time_elapsed    | 25499    |
|    total_timesteps | 826946   |
| train/             |          |
|    actor_loss      | -5.02    |
|    critic_loss     | 1.1      |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -1.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 816945   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 32       |
|    time_elapsed    | 25554    |
|    total_timesteps | 828946   |
| train/             |          |
|    actor_loss      | -8.45    |
|    critic_loss     | 1.07     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 818945   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=830000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -2.88    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 819999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 32       |
|    time_elapsed    | 25678    |
|    total_timesteps | 830946   |
| train/             |          |
|    actor_loss      | -11.8    |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 0.375    |
|    learning_rate   | 0.0003   |
|    n_updates       | 820945   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 32       |
|    time_elapsed    | 25710    |
|    total_timesteps | 832452   |
| train/             |          |
|    actor_loss      | -2.61    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 0.468    |
|    learning_rate   | 0.0003   |
|    n_updates       | 822451   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 32       |
|    time_elapsed    | 25748    |
|    total_timesteps | 834452   |
| train/             |          |
|    actor_loss      | -7.94    |
|    critic_loss     | 2.07     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.114    |
|    learning_rate   | 0.0003   |
|    n_updates       | 824451   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 32       |
|    time_elapsed    | 25793    |
|    total_timesteps | 836452   |
| train/             |          |
|    actor_loss      | -5.28    |
|    critic_loss     | 1.81     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 0.0436   |
|    learning_rate   | 0.0003   |
|    n_updates       | 826451   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 32       |
|    time_elapsed    | 25845    |
|    total_timesteps | 838452   |
| train/             |          |
|    actor_loss      | -2.01    |
|    critic_loss     | 1.19     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 828451   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=840000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -3.77    |
|    critic_loss     | 2.6      |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 829999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 32       |
|    time_elapsed    | 25983    |
|    total_timesteps | 840452   |
| train/             |          |
|    actor_loss      | -2.42    |
|    critic_loss     | 2.21     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -1.45    |
|    learning_rate   | 0.0003   |
|    n_updates       | 830451   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 32       |
|    time_elapsed    | 26030    |
|    total_timesteps | 842452   |
| train/             |          |
|    actor_loss      | -3.02    |
|    critic_loss     | 1.56     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 0.579    |
|    learning_rate   | 0.0003   |
|    n_updates       | 832451   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 32       |
|    time_elapsed    | 26072    |
|    total_timesteps | 844452   |
| train/             |          |
|    actor_loss      | -9.62    |
|    critic_loss     | 2.15     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 0.284    |
|    learning_rate   | 0.0003   |
|    n_updates       | 834451   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 32       |
|    time_elapsed    | 26122    |
|    total_timesteps | 846452   |
| train/             |          |
|    actor_loss      | -3.89    |
|    critic_loss     | 1.71     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -0.249   |
|    learning_rate   | 0.0003   |
|    n_updates       | 836451   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 32       |
|    time_elapsed    | 26168    |
|    total_timesteps | 848452   |
| train/             |          |
|    actor_loss      | -1.46    |
|    critic_loss     | 2.05     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -1.82    |
|    learning_rate   | 0.0003   |
|    n_updates       | 838451   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=850000, episode_reward=0.10 +/- 0.30
Episode length: 450.50 +/- 148.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -2.41    |
|    critic_loss     | 1.26     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 0.0003   |
|    n_updates       | 839999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 32       |
|    time_elapsed    | 26279    |
|    total_timesteps | 850452   |
| train/             |          |
|    actor_loss      | -1.59    |
|    critic_loss     | 11.9     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 0.0003   |
|    n_updates       | 840451   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 32       |
|    time_elapsed    | 26331    |
|    total_timesteps | 851958   |
| train/             |          |
|    actor_loss      | -2.86    |
|    critic_loss     | 2.1      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 841957   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 32       |
|    time_elapsed    | 26368    |
|    total_timesteps | 853465   |
| train/             |          |
|    actor_loss      | -5.88    |
|    critic_loss     | 3.3      |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 843464   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 32       |
|    time_elapsed    | 26399    |
|    total_timesteps | 854971   |
| train/             |          |
|    actor_loss      | -5.7     |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 844970   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 32       |
|    time_elapsed    | 26426    |
|    total_timesteps | 855989   |
| train/             |          |
|    actor_loss      | -7.27    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 845988   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 32       |
|    time_elapsed    | 26470    |
|    total_timesteps | 857901   |
| train/             |          |
|    actor_loss      | -0.929   |
|    critic_loss     | 2.18     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 847900   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 32       |
|    time_elapsed    | 26509    |
|    total_timesteps | 859901   |
| train/             |          |
|    actor_loss      | -1.96    |
|    critic_loss     | 2.23     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 0.504    |
|    learning_rate   | 0.0003   |
|    n_updates       | 849900   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Eval num_timesteps=860000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -3.18    |
|    critic_loss     | 43.6     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.939    |
|    learning_rate   | 0.0003   |
|    n_updates       | 849999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 32       |
|    time_elapsed    | 26649    |
|    total_timesteps | 861901   |
| train/             |          |
|    actor_loss      | -2.47    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -0.241   |
|    learning_rate   | 0.0003   |
|    n_updates       | 851900   |
---------------------------------
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 32       |
|    time_elapsed    | 26699    |
|    total_timesteps | 863901   |
| train/             |          |
|    actor_loss      | -0.93    |
|    critic_loss     | 1.71     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -0.795   |
|    learning_rate   | 0.0003   |
|    n_updates       | 853900   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 32       |
|    time_elapsed    | 26743    |
|    total_timesteps | 865901   |
| train/             |          |
|    actor_loss      | 0.364    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.104    |
|    learning_rate   | 0.0003   |
|    n_updates       | 855900   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 32       |
|    time_elapsed    | 26791    |
|    total_timesteps | 867901   |
| train/             |          |
|    actor_loss      | 1.1      |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -2.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 857900   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 32       |
|    time_elapsed    | 26828    |
|    total_timesteps | 869901   |
| train/             |          |
|    actor_loss      | 0.86     |
|    critic_loss     | 0.989    |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 859900   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Eval num_timesteps=870000, episode_reward=0.10 +/- 0.30
Episode length: 450.60 +/- 148.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -1.19    |
|    critic_loss     | 189      |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 0.396    |
|    learning_rate   | 0.0003   |
|    n_updates       | 859999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 32       |
|    time_elapsed    | 26951    |
|    total_timesteps | 871901   |
| train/             |          |
|    actor_loss      | -3.51    |
|    critic_loss     | 1.94     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 861900   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 32       |
|    time_elapsed    | 27003    |
|    total_timesteps | 873901   |
| train/             |          |
|    actor_loss      | 0.897    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 863900   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 32       |
|    time_elapsed    | 27048    |
|    total_timesteps | 875901   |
| train/             |          |
|    actor_loss      | 3.04     |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -4.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 865900   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 32       |
|    time_elapsed    | 27086    |
|    total_timesteps | 877901   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.48     |
|    ent_coef        | 0.00996  |
|    ent_coef_loss   | -0.248   |
|    learning_rate   | 0.0003   |
|    n_updates       | 867900   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 32       |
|    time_elapsed    | 27135    |
|    total_timesteps | 879901   |
| train/             |          |
|    actor_loss      | 2.61     |
|    critic_loss     | 1.47     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 869900   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=880000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | 1.89     |
|    critic_loss     | 2.46     |
|    ent_coef        | 0.00977  |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 0.0003   |
|    n_updates       | 869999   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 32       |
|    time_elapsed    | 27273    |
|    total_timesteps | 881901   |
| train/             |          |
|    actor_loss      | 0.423    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0094   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 871900   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 32       |
|    time_elapsed    | 27322    |
|    total_timesteps | 883901   |
| train/             |          |
|    actor_loss      | 1.8      |
|    critic_loss     | 1.16     |
|    ent_coef        | 0.00974  |
|    ent_coef_loss   | 0.0846   |
|    learning_rate   | 0.0003   |
|    n_updates       | 873900   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 32       |
|    time_elapsed    | 27352    |
|    total_timesteps | 885406   |
| train/             |          |
|    actor_loss      | 3.79     |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.00933  |
|    ent_coef_loss   | 0.172    |
|    learning_rate   | 0.0003   |
|    n_updates       | 875405   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 32       |
|    time_elapsed    | 27390    |
|    total_timesteps | 887406   |
| train/             |          |
|    actor_loss      | 3.46     |
|    critic_loss     | 1.37     |
|    ent_coef        | 0.00913  |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 877405   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 32       |
|    time_elapsed    | 27428    |
|    total_timesteps | 889406   |
| train/             |          |
|    actor_loss      | 3.3      |
|    critic_loss     | 0.735    |
|    ent_coef        | 0.00902  |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 879405   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=890000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | 2.8      |
|    critic_loss     | 1.59     |
|    ent_coef        | 0.00896  |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 879999   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 32       |
|    time_elapsed    | 27578    |
|    total_timesteps | 891406   |
| train/             |          |
|    actor_loss      | 5.21     |
|    critic_loss     | 1.29     |
|    ent_coef        | 0.0089   |
|    ent_coef_loss   | -3.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 881405   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 32       |
|    time_elapsed    | 27616    |
|    total_timesteps | 893406   |
| train/             |          |
|    actor_loss      | 0.739    |
|    critic_loss     | 1.05     |
|    ent_coef        | 0.00851  |
|    ent_coef_loss   | 0.896    |
|    learning_rate   | 0.0003   |
|    n_updates       | 883405   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 32       |
|    time_elapsed    | 27655    |
|    total_timesteps | 895406   |
| train/             |          |
|    actor_loss      | -8.13    |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 4.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 885405   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 32       |
|    time_elapsed    | 27701    |
|    total_timesteps | 897406   |
| train/             |          |
|    actor_loss      | 2.7      |
|    critic_loss     | 1.93     |
|    ent_coef        | 0.00831  |
|    ent_coef_loss   | -0.489   |
|    learning_rate   | 0.0003   |
|    n_updates       | 887405   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1960     |
|    fps             | 32       |
|    time_elapsed    | 27740    |
|    total_timesteps | 899406   |
| train/             |          |
|    actor_loss      | 5.48     |
|    critic_loss     | 1.11     |
|    ent_coef        | 0.0077   |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 889405   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg3
Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | 4.54     |
|    critic_loss     | 2.12     |
|    ent_coef        | 0.00793  |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 889999   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 32       |
|    time_elapsed    | 27886    |
|    total_timesteps | 901406   |
| train/             |          |
|    actor_loss      | 4        |
|    critic_loss     | 1.55     |
|    ent_coef        | 0.00782  |
|    ent_coef_loss   | -0.807   |
|    learning_rate   | 0.0003   |
|    n_updates       | 891405   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 32       |
|    time_elapsed    | 27916    |
|    total_timesteps | 902430   |
| train/             |          |
|    actor_loss      | 5.5      |
|    critic_loss     | 1.04     |
|    ent_coef        | 0.00791  |
|    ent_coef_loss   | 1.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 892429   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 32       |
|    time_elapsed    | 27958    |
|    total_timesteps | 904430   |
| train/             |          |
|    actor_loss      | 4.48     |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.00771  |
|    ent_coef_loss   | -0.261   |
|    learning_rate   | 0.0003   |
|    n_updates       | 894429   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 32       |
|    time_elapsed    | 28008    |
|    total_timesteps | 906430   |
| train/             |          |
|    actor_loss      | 5.58     |
|    critic_loss     | 0.779    |
|    ent_coef        | 0.00756  |
|    ent_coef_loss   | -0.918   |
|    learning_rate   | 0.0003   |
|    n_updates       | 896429   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 32       |
|    time_elapsed    | 28060    |
|    total_timesteps | 908430   |
| train/             |          |
|    actor_loss      | 4.26     |
|    critic_loss     | 0.854    |
|    ent_coef        | 0.00773  |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 898429   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 32       |
|    time_elapsed    | 28093    |
|    total_timesteps | 909937   |
| train/             |          |
|    actor_loss      | 4.34     |
|    critic_loss     | 0.983    |
|    ent_coef        | 0.00759  |
|    ent_coef_loss   | 0.262    |
|    learning_rate   | 0.0003   |
|    n_updates       | 899936   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=910000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | 3.27     |
|    critic_loss     | 1.13     |
|    ent_coef        | 0.0076   |
|    ent_coef_loss   | 0.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 899999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 32       |
|    time_elapsed    | 28216    |
|    total_timesteps | 911937   |
| train/             |          |
|    actor_loss      | 3.21     |
|    critic_loss     | 0.855    |
|    ent_coef        | 0.00727  |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 901936   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 32       |
|    time_elapsed    | 28271    |
|    total_timesteps | 913937   |
| train/             |          |
|    actor_loss      | 4.2      |
|    critic_loss     | 0.71     |
|    ent_coef        | 0.00717  |
|    ent_coef_loss   | -0.0426  |
|    learning_rate   | 0.0003   |
|    n_updates       | 903936   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 1996     |
|    fps             | 32       |
|    time_elapsed    | 28312    |
|    total_timesteps | 915444   |
| train/             |          |
|    actor_loss      | 5.71     |
|    critic_loss     | 0.606    |
|    ent_coef        | 0.00685  |
|    ent_coef_loss   | -3.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 905443   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 32       |
|    time_elapsed    | 28352    |
|    total_timesteps | 917444   |
| train/             |          |
|    actor_loss      | 2.93     |
|    critic_loss     | 1.05     |
|    ent_coef        | 0.00714  |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 907443   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 32       |
|    time_elapsed    | 28394    |
|    total_timesteps | 919444   |
| train/             |          |
|    actor_loss      | 3.59     |
|    critic_loss     | 1.06     |
|    ent_coef        | 0.00719  |
|    ent_coef_loss   | 0.851    |
|    learning_rate   | 0.0003   |
|    n_updates       | 909443   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Eval num_timesteps=920000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | 6.78     |
|    critic_loss     | 0.94     |
|    ent_coef        | 0.00685  |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 909999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 32       |
|    time_elapsed    | 28520    |
|    total_timesteps | 921444   |
| train/             |          |
|    actor_loss      | 2.83     |
|    critic_loss     | 1.48     |
|    ent_coef        | 0.00714  |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 911443   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 32       |
|    time_elapsed    | 28562    |
|    total_timesteps | 923444   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.007    |
|    ent_coef_loss   | -0.176   |
|    learning_rate   | 0.0003   |
|    n_updates       | 913443   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 32       |
|    time_elapsed    | 28606    |
|    total_timesteps | 925444   |
| train/             |          |
|    actor_loss      | 3.12     |
|    critic_loss     | 0.953    |
|    ent_coef        | 0.00702  |
|    ent_coef_loss   | -0.881   |
|    learning_rate   | 0.0003   |
|    n_updates       | 915443   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 32       |
|    time_elapsed    | 28648    |
|    total_timesteps | 927444   |
| train/             |          |
|    actor_loss      | 5.06     |
|    critic_loss     | 0.778    |
|    ent_coef        | 0.00693  |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 917443   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube3 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 32       |
|    time_elapsed    | 28685    |
|    total_timesteps | 928949   |
| train/             |          |
|    actor_loss      | 3.64     |
|    critic_loss     | 1.06     |
|    ent_coef        | 0.00718  |
|    ent_coef_loss   | 0.617    |
|    learning_rate   | 0.0003   |
|    n_updates       | 918948   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Eval num_timesteps=930000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.00699  |
|    ent_coef_loss   | 0.744    |
|    learning_rate   | 0.0003   |
|    n_updates       | 919999   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 32       |
|    time_elapsed    | 28803    |
|    total_timesteps | 930949   |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 1.01     |
|    ent_coef        | 0.00683  |
|    ent_coef_loss   | 1.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 920948   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2032     |
|    fps             | 32       |
|    time_elapsed    | 28851    |
|    total_timesteps | 932949   |
| train/             |          |
|    actor_loss      | 5.46     |
|    critic_loss     | 1.09     |
|    ent_coef        | 0.00694  |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 922948   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2036     |
|    fps             | 32       |
|    time_elapsed    | 28892    |
|    total_timesteps | 934949   |
| train/             |          |
|    actor_loss      | 0.181    |
|    critic_loss     | 2.15     |
|    ent_coef        | 0.00698  |
|    ent_coef_loss   | -0.916   |
|    learning_rate   | 0.0003   |
|    n_updates       | 924948   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2040     |
|    fps             | 32       |
|    time_elapsed    | 28932    |
|    total_timesteps | 936949   |
| train/             |          |
|    actor_loss      | 1.18     |
|    critic_loss     | 1.31     |
|    ent_coef        | 0.00675  |
|    ent_coef_loss   | -1.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 926948   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2044     |
|    fps             | 32       |
|    time_elapsed    | 28976    |
|    total_timesteps | 938949   |
| train/             |          |
|    actor_loss      | 3.65     |
|    critic_loss     | 0.977    |
|    ent_coef        | 0.00702  |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 928948   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Eval num_timesteps=940000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.07     |
|    ent_coef        | 0.00677  |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 929999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 32       |
|    time_elapsed    | 29121    |
|    total_timesteps | 940455   |
| train/             |          |
|    actor_loss      | 3.2      |
|    critic_loss     | 1.23     |
|    ent_coef        | 0.00655  |
|    ent_coef_loss   | 0.674    |
|    learning_rate   | 0.0003   |
|    n_updates       | 930454   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 32       |
|    time_elapsed    | 29161    |
|    total_timesteps | 942455   |
| train/             |          |
|    actor_loss      | 1.57     |
|    critic_loss     | 0.926    |
|    ent_coef        | 0.00672  |
|    ent_coef_loss   | 0.967    |
|    learning_rate   | 0.0003   |
|    n_updates       | 932454   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 32       |
|    time_elapsed    | 29216    |
|    total_timesteps | 944455   |
| train/             |          |
|    actor_loss      | 2.94     |
|    critic_loss     | 0.824    |
|    ent_coef        | 0.00722  |
|    ent_coef_loss   | 3.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 934454   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 32       |
|    time_elapsed    | 29275    |
|    total_timesteps | 946455   |
| train/             |          |
|    actor_loss      | -2       |
|    critic_loss     | 1.18     |
|    ent_coef        | 0.00686  |
|    ent_coef_loss   | -0.731   |
|    learning_rate   | 0.0003   |
|    n_updates       | 936454   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 32       |
|    time_elapsed    | 29314    |
|    total_timesteps | 948455   |
| train/             |          |
|    actor_loss      | 2.37     |
|    critic_loss     | 1.95     |
|    ent_coef        | 0.00708  |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 938454   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Eval num_timesteps=950000, episode_reward=0.10 +/- 0.30
Episode length: 450.70 +/- 147.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | 2.37     |
|    critic_loss     | 0.79     |
|    ent_coef        | 0.0071   |
|    ent_coef_loss   | 0.764    |
|    learning_rate   | 0.0003   |
|    n_updates       | 939999   |
---------------------------------
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 32       |
|    time_elapsed    | 29444    |
|    total_timesteps | 950455   |
| train/             |          |
|    actor_loss      | 2.7      |
|    critic_loss     | 1.38     |
|    ent_coef        | 0.00701  |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 940454   |
---------------------------------
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 2072     |
|    fps             | 32       |
|    time_elapsed    | 29497    |
|    total_timesteps | 952455   |
| train/             |          |
|    actor_loss      | 5.1      |
|    critic_loss     | 0.986    |
|    ent_coef        | 0.00703  |
|    ent_coef_loss   | 0.283    |
|    learning_rate   | 0.0003   |
|    n_updates       | 942454   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2076     |
|    fps             | 32       |
|    time_elapsed    | 29528    |
|    total_timesteps | 953961   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.65     |
|    ent_coef        | 0.00741  |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 943960   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 32       |
|    time_elapsed    | 29568    |
|    total_timesteps | 955961   |
| train/             |          |
|    actor_loss      | 3.42     |
|    critic_loss     | 1.33     |
|    ent_coef        | 0.00713  |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 945960   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 32       |
|    time_elapsed    | 29613    |
|    total_timesteps | 957496   |
| train/             |          |
|    actor_loss      | 0.883    |
|    critic_loss     | 1.45     |
|    ent_coef        | 0.00709  |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 947495   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2088     |
|    fps             | 32       |
|    time_elapsed    | 29645    |
|    total_timesteps | 959003   |
| train/             |          |
|    actor_loss      | 2.41     |
|    critic_loss     | 1.76     |
|    ent_coef        | 0.00746  |
|    ent_coef_loss   | -1.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 949002   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Eval num_timesteps=960000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | 3.72     |
|    critic_loss     | 1.41     |
|    ent_coef        | 0.00717  |
|    ent_coef_loss   | 0.91     |
|    learning_rate   | 0.0003   |
|    n_updates       | 949999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2092     |
|    fps             | 32       |
|    time_elapsed    | 29780    |
|    total_timesteps | 961003   |
| train/             |          |
|    actor_loss      | -0.896   |
|    critic_loss     | 2        |
|    ent_coef        | 0.0069   |
|    ent_coef_loss   | 0.238    |
|    learning_rate   | 0.0003   |
|    n_updates       | 951002   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 32       |
|    time_elapsed    | 29826    |
|    total_timesteps | 963003   |
| train/             |          |
|    actor_loss      | 5.05     |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.0075   |
|    ent_coef_loss   | 0.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 953002   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2100     |
|    fps             | 32       |
|    time_elapsed    | 29871    |
|    total_timesteps | 965003   |
| train/             |          |
|    actor_loss      | 4.8      |
|    critic_loss     | 0.805    |
|    ent_coef        | 0.00696  |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 955002   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2104     |
|    fps             | 32       |
|    time_elapsed    | 29916    |
|    total_timesteps | 967003   |
| train/             |          |
|    actor_loss      | 4.94     |
|    critic_loss     | 0.988    |
|    ent_coef        | 0.00748  |
|    ent_coef_loss   | 0.309    |
|    learning_rate   | 0.0003   |
|    n_updates       | 957002   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2108     |
|    fps             | 32       |
|    time_elapsed    | 29969    |
|    total_timesteps | 969003   |
| train/             |          |
|    actor_loss      | -3.72    |
|    critic_loss     | 2.08     |
|    ent_coef        | 0.00779  |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 959002   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg3
Eval num_timesteps=970000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | 4.3      |
|    critic_loss     | 1.01     |
|    ent_coef        | 0.00754  |
|    ent_coef_loss   | -0.703   |
|    learning_rate   | 0.0003   |
|    n_updates       | 959999   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2112     |
|    fps             | 32       |
|    time_elapsed    | 30112    |
|    total_timesteps | 971003   |
| train/             |          |
|    actor_loss      | 3.63     |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.00777  |
|    ent_coef_loss   | -0.173   |
|    learning_rate   | 0.0003   |
|    n_updates       | 961002   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 32       |
|    time_elapsed    | 30159    |
|    total_timesteps | 973003   |
| train/             |          |
|    actor_loss      | 1.8      |
|    critic_loss     | 0.725    |
|    ent_coef        | 0.00773  |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 963002   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2120     |
|    fps             | 32       |
|    time_elapsed    | 30205    |
|    total_timesteps | 975003   |
| train/             |          |
|    actor_loss      | 2.79     |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.00747  |
|    ent_coef_loss   | -0.627   |
|    learning_rate   | 0.0003   |
|    n_updates       | 965002   |
---------------------------------
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 32       |
|    time_elapsed    | 30262    |
|    total_timesteps | 977003   |
| train/             |          |
|    actor_loss      | 1.54     |
|    critic_loss     | 0.986    |
|    ent_coef        | 0.00775  |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 967002   |
---------------------------------
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 2128     |
|    fps             | 32       |
|    time_elapsed    | 30302    |
|    total_timesteps | 979003   |
| train/             |          |
|    actor_loss      | 3.88     |
|    critic_loss     | 1.48     |
|    ent_coef        | 0.00796  |
|    ent_coef_loss   | 0.428    |
|    learning_rate   | 0.0003   |
|    n_updates       | 969002   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=980000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | 4.85     |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | -0.921   |
|    learning_rate   | 0.0003   |
|    n_updates       | 969999   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube2 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 2132     |
|    fps             | 32       |
|    time_elapsed    | 30424    |
|    total_timesteps | 981003   |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 1.59     |
|    ent_coef        | 0.00797  |
|    ent_coef_loss   | -0.105   |
|    learning_rate   | 0.0003   |
|    n_updates       | 971002   |
---------------------------------
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 2136     |
|    fps             | 32       |
|    time_elapsed    | 30457    |
|    total_timesteps | 982510   |
| train/             |          |
|    actor_loss      | 4.55     |
|    critic_loss     | 0.856    |
|    ent_coef        | 0.00814  |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 972509   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2140     |
|    fps             | 32       |
|    time_elapsed    | 30493    |
|    total_timesteps | 984020   |
| train/             |          |
|    actor_loss      | 0.975    |
|    critic_loss     | 1.62     |
|    ent_coef        | 0.00792  |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 974019   |
---------------------------------
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 2144     |
|    fps             | 32       |
|    time_elapsed    | 30524    |
|    total_timesteps | 985527   |
| train/             |          |
|    actor_loss      | -0.698   |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 1.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 975526   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2148     |
|    fps             | 32       |
|    time_elapsed    | 30567    |
|    total_timesteps | 987527   |
| train/             |          |
|    actor_loss      | -3.56    |
|    critic_loss     | 3.89     |
|    ent_coef        | 0.00756  |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 977526   |
---------------------------------
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 2152     |
|    fps             | 32       |
|    time_elapsed    | 30606    |
|    total_timesteps | 989527   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.28     |
|    ent_coef        | 0.00809  |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 979526   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube1 and drop it on peg1
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on cube3
Task: Pick cube2 and drop it on peg2
Eval num_timesteps=990000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | 4.26     |
|    critic_loss     | 1.34     |
|    ent_coef        | 0.0081   |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 979999   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 2156     |
|    fps             | 32       |
|    time_elapsed    | 30712    |
|    total_timesteps | 991037   |
| train/             |          |
|    actor_loss      | -1.7     |
|    critic_loss     | 94.8     |
|    ent_coef        | 0.00811  |
|    ent_coef_loss   | 0.859    |
|    learning_rate   | 0.0003   |
|    n_updates       | 981036   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube3 and drop it on peg3
Task: Pick cube1 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 2160     |
|    fps             | 32       |
|    time_elapsed    | 30759    |
|    total_timesteps | 993037   |
| train/             |          |
|    actor_loss      | 3.14     |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.00866  |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 983036   |
---------------------------------
Task: Pick cube1 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on peg1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 32       |
|    time_elapsed    | 30797    |
|    total_timesteps | 994542   |
| train/             |          |
|    actor_loss      | 3.29     |
|    critic_loss     | 1.52     |
|    ent_coef        | 0.00871  |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 0.0003   |
|    n_updates       | 984541   |
---------------------------------
Task: Pick cube2 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg3
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 2168     |
|    fps             | 32       |
|    time_elapsed    | 30849    |
|    total_timesteps | 996542   |
| train/             |          |
|    actor_loss      | 4.64     |
|    critic_loss     | 1.58     |
|    ent_coef        | 0.0085   |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 986541   |
---------------------------------
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg1
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on cube2
Task: Pick cube1 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 2172     |
|    fps             | 32       |
|    time_elapsed    | 30901    |
|    total_timesteps | 998542   |
| train/             |          |
|    actor_loss      | 1.57     |
|    critic_loss     | 5.81     |
|    ent_coef        | 0.00887  |
|    ent_coef_loss   | -3.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 988541   |
---------------------------------
Task: Pick cube1 and drop it on cube2
Task: Pick cube3 and drop it on peg1
Task: Pick cube2 and drop it on cube3
Task: Pick cube2 and drop it on peg2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 2176     |
|    fps             | 32       |
|    time_elapsed    | 30935    |
|    total_timesteps | 999555   |
| train/             |          |
|    actor_loss      | 2.54     |
|    critic_loss     | 3.52     |
|    ent_coef        | 0.00932  |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 989554   |
---------------------------------
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg2
Task: Pick cube1 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Task: Pick cube1 and drop it on cube2
Task: Pick cube2 and drop it on peg1
Task: Pick cube2 and drop it on peg3
Task: Pick cube3 and drop it on peg2
Task: Pick cube3 and drop it on peg2
Task: Pick cube1 and drop it on peg2
Task: Pick cube2 and drop it on cube3
Task: Pick cube1 and drop it on peg3
Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 1000000  |
| train/             |          |
|    actor_loss      | 0.757    |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.00937  |
|    ent_coef_loss   | 0.296    |
|    learning_rate   | 0.0003   |
|    n_updates       | 989999   |
---------------------------------
 100%  1,000,000/1,000,000  [ 8:36:55 < 0:00:00 , ? it/s ]
Training ReachDrop
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to ./logs/SAC_32
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 4        |
|    fps             | 81       |
|    time_elapsed    | 24       |
|    total_timesteps | 2000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 438      |
|    ep_rew_mean     | 0.125    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 81       |
|    time_elapsed    | 43       |
|    total_timesteps | 3504     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 0.0833   |
| time/              |          |
|    episodes        | 12       |
|    fps             | 63       |
|    time_elapsed    | 86       |
|    total_timesteps | 5504     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 16       |
|    fps             | 64       |
|    time_elapsed    | 116      |
|    total_timesteps | 7504     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 61       |
|    time_elapsed    | 155      |
|    total_timesteps | 9504     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0417   |
| time/              |          |
|    episodes        | 24       |
|    fps             | 41       |
|    time_elapsed    | 274      |
|    total_timesteps | 11504    |
| train/             |          |
|    actor_loss      | -16.3    |
|    critic_loss     | 0.735    |
|    ent_coef        | 0.637    |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 1503     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 0.0357   |
| time/              |          |
|    episodes        | 28       |
|    fps             | 43       |
|    time_elapsed    | 312      |
|    total_timesteps | 13504    |
| train/             |          |
|    actor_loss      | -24.9    |
|    critic_loss     | 1.8      |
|    ent_coef        | 0.35     |
|    ent_coef_loss   | -7.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 3503     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.0312   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 44       |
|    time_elapsed    | 348      |
|    total_timesteps | 15504    |
| train/             |          |
|    actor_loss      | -27.3    |
|    critic_loss     | 10       |
|    ent_coef        | 0.193    |
|    ent_coef_loss   | -10.8    |
|    learning_rate   | 0.0003   |
|    n_updates       | 5503     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 486      |
|    ep_rew_mean     | 0.0278   |
| time/              |          |
|    episodes        | 36       |
|    fps             | 45       |
|    time_elapsed    | 385      |
|    total_timesteps | 17504    |
| train/             |          |
|    actor_loss      | -27.9    |
|    critic_loss     | 0.116    |
|    ent_coef        | 0.108    |
|    ent_coef_loss   | -13.4    |
|    learning_rate   | 0.0003   |
|    n_updates       | 7503     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.025    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 46       |
|    time_elapsed    | 420      |
|    total_timesteps | 19504    |
| train/             |          |
|    actor_loss      | -26.9    |
|    critic_loss     | 0.205    |
|    ent_coef        | 0.0615   |
|    ent_coef_loss   | -13.3    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9503     |
---------------------------------
Eval num_timesteps=20000, episode_reward=0.10 +/- 0.30
Episode length: 453.10 +/- 140.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 453      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -26.7    |
|    critic_loss     | 0.382    |
|    ent_coef        | 0.0537   |
|    ent_coef_loss   | -13.5    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.0455   |
| time/              |          |
|    episodes        | 44       |
|    fps             | 40       |
|    time_elapsed    | 522      |
|    total_timesteps | 21019    |
| train/             |          |
|    actor_loss      | -25.9    |
|    critic_loss     | 1.62     |
|    ent_coef        | 0.0409   |
|    ent_coef_loss   | -13.2    |
|    learning_rate   | 0.0003   |
|    n_updates       | 11018    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.0417   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 40       |
|    time_elapsed    | 562      |
|    total_timesteps | 23019    |
| train/             |          |
|    actor_loss      | -24.6    |
|    critic_loss     | 0.141    |
|    ent_coef        | 0.0248   |
|    ent_coef_loss   | -9.95    |
|    learning_rate   | 0.0003   |
|    n_updates       | 13018    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 472      |
|    ep_rew_mean     | 0.0577   |
| time/              |          |
|    episodes        | 52       |
|    fps             | 40       |
|    time_elapsed    | 598      |
|    total_timesteps | 24520    |
| train/             |          |
|    actor_loss      | -23.5    |
|    critic_loss     | 0.159    |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | -7.99    |
|    learning_rate   | 0.0003   |
|    n_updates       | 14519    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.0536   |
| time/              |          |
|    episodes        | 56       |
|    fps             | 40       |
|    time_elapsed    | 652      |
|    total_timesteps | 26520    |
| train/             |          |
|    actor_loss      | -22.5    |
|    critic_loss     | 0.148    |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -6.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 16519    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.0667   |
| time/              |          |
|    episodes        | 60       |
|    fps             | 40       |
|    time_elapsed    | 683      |
|    total_timesteps | 28021    |
| train/             |          |
|    actor_loss      | -21.4    |
|    critic_loss     | 0.163    |
|    ent_coef        | 0.00894  |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 18020    |
---------------------------------
Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -19.6    |
|    critic_loss     | 0.0803   |
|    ent_coef        | 0.00755  |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 19999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 64       |
|    fps             | 37       |
|    time_elapsed    | 799      |
|    total_timesteps | 30021    |
| train/             |          |
|    actor_loss      | -20      |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.00755  |
|    ent_coef_loss   | 0.969    |
|    learning_rate   | 0.0003   |
|    n_updates       | 20020    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.0588   |
| time/              |          |
|    episodes        | 68       |
|    fps             | 38       |
|    time_elapsed    | 835      |
|    total_timesteps | 32021    |
| train/             |          |
|    actor_loss      | -19      |
|    critic_loss     | 0.0695   |
|    ent_coef        | 0.00699  |
|    ent_coef_loss   | -0.937   |
|    learning_rate   | 0.0003   |
|    n_updates       | 22020    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 0.0694   |
| time/              |          |
|    episodes        | 72       |
|    fps             | 38       |
|    time_elapsed    | 865      |
|    total_timesteps | 33528    |
| train/             |          |
|    actor_loss      | -17.4    |
|    critic_loss     | 0.0663   |
|    ent_coef        | 0.00614  |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 23527    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 0.0658   |
| time/              |          |
|    episodes        | 76       |
|    fps             | 39       |
|    time_elapsed    | 909      |
|    total_timesteps | 35528    |
| train/             |          |
|    actor_loss      | -17.1    |
|    critic_loss     | 0.0556   |
|    ent_coef        | 0.00601  |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 25527    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 80       |
|    fps             | 39       |
|    time_elapsed    | 944      |
|    total_timesteps | 37528    |
| train/             |          |
|    actor_loss      | -15.7    |
|    critic_loss     | 0.0646   |
|    ent_coef        | 0.00485  |
|    ent_coef_loss   | -0.216   |
|    learning_rate   | 0.0003   |
|    n_updates       | 27527    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.0595   |
| time/              |          |
|    episodes        | 84       |
|    fps             | 40       |
|    time_elapsed    | 981      |
|    total_timesteps | 39528    |
| train/             |          |
|    actor_loss      | -14.4    |
|    critic_loss     | 0.466    |
|    ent_coef        | 0.00455  |
|    ent_coef_loss   | 0.795    |
|    learning_rate   | 0.0003   |
|    n_updates       | 29527    |
---------------------------------
Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -14      |
|    critic_loss     | 0.0547   |
|    ent_coef        | 0.00443  |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 0.0795   |
| time/              |          |
|    episodes        | 88       |
|    fps             | 37       |
|    time_elapsed    | 1086     |
|    total_timesteps | 40530    |
| train/             |          |
|    actor_loss      | -13.5    |
|    critic_loss     | 0.0336   |
|    ent_coef        | 0.00421  |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 0.0003   |
|    n_updates       | 30529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 462      |
|    ep_rew_mean     | 0.0761   |
| time/              |          |
|    episodes        | 92       |
|    fps             | 37       |
|    time_elapsed    | 1124     |
|    total_timesteps | 42530    |
| train/             |          |
|    actor_loss      | -12.8    |
|    critic_loss     | 0.0279   |
|    ent_coef        | 0.00378  |
|    ent_coef_loss   | 2.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 32529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 0.0729   |
| time/              |          |
|    episodes        | 96       |
|    fps             | 38       |
|    time_elapsed    | 1169     |
|    total_timesteps | 44530    |
| train/             |          |
|    actor_loss      | -12.1    |
|    critic_loss     | 0.0371   |
|    ent_coef        | 0.00324  |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 34529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 38       |
|    time_elapsed    | 1218     |
|    total_timesteps | 46530    |
| train/             |          |
|    actor_loss      | -10.7    |
|    critic_loss     | 0.0254   |
|    ent_coef        | 0.00284  |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 36529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 38       |
|    time_elapsed    | 1257     |
|    total_timesteps | 48530    |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.0277   |
|    ent_coef        | 0.00269  |
|    ent_coef_loss   | 0.724    |
|    learning_rate   | 0.0003   |
|    n_updates       | 38529    |
---------------------------------
Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.023    |
|    ent_coef        | 0.00256  |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 36       |
|    time_elapsed    | 1371     |
|    total_timesteps | 50530    |
| train/             |          |
|    actor_loss      | -9.44    |
|    critic_loss     | 0.037    |
|    ent_coef        | 0.00266  |
|    ent_coef_loss   | -0.959   |
|    learning_rate   | 0.0003   |
|    n_updates       | 40529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 37       |
|    time_elapsed    | 1404     |
|    total_timesteps | 52530    |
| train/             |          |
|    actor_loss      | -8.83    |
|    critic_loss     | 0.0149   |
|    ent_coef        | 0.00222  |
|    ent_coef_loss   | -0.838   |
|    learning_rate   | 0.0003   |
|    n_updates       | 42529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 37       |
|    time_elapsed    | 1438     |
|    total_timesteps | 54530    |
| train/             |          |
|    actor_loss      | -8.19    |
|    critic_loss     | 0.235    |
|    ent_coef        | 0.00234  |
|    ent_coef_loss   | 0.521    |
|    learning_rate   | 0.0003   |
|    n_updates       | 44529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 38       |
|    time_elapsed    | 1473     |
|    total_timesteps | 56530    |
| train/             |          |
|    actor_loss      | -7.73    |
|    critic_loss     | 0.0265   |
|    ent_coef        | 0.0022   |
|    ent_coef_loss   | -0.993   |
|    learning_rate   | 0.0003   |
|    n_updates       | 46529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 38       |
|    time_elapsed    | 1513     |
|    total_timesteps | 58530    |
| train/             |          |
|    actor_loss      | -6.98    |
|    critic_loss     | 0.00734  |
|    ent_coef        | 0.00203  |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 48529    |
---------------------------------
Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -6.67    |
|    critic_loss     | 0.00695  |
|    ent_coef        | 0.002    |
|    ent_coef_loss   | 0.428    |
|    learning_rate   | 0.0003   |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 37       |
|    time_elapsed    | 1628     |
|    total_timesteps | 60530    |
| train/             |          |
|    actor_loss      | -6.64    |
|    critic_loss     | 0.44     |
|    ent_coef        | 0.00205  |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 50529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 37       |
|    time_elapsed    | 1662     |
|    total_timesteps | 62530    |
| train/             |          |
|    actor_loss      | -6.19    |
|    critic_loss     | 0.01     |
|    ent_coef        | 0.00189  |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 52529    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 37       |
|    time_elapsed    | 1708     |
|    total_timesteps | 64031    |
| train/             |          |
|    actor_loss      | -5.71    |
|    critic_loss     | 0.00455  |
|    ent_coef        | 0.00169  |
|    ent_coef_loss   | -0.534   |
|    learning_rate   | 0.0003   |
|    n_updates       | 54030    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 37       |
|    time_elapsed    | 1743     |
|    total_timesteps | 66031    |
| train/             |          |
|    actor_loss      | -5.28    |
|    critic_loss     | 0.00676  |
|    ent_coef        | 0.00163  |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 56030    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 38       |
|    time_elapsed    | 1788     |
|    total_timesteps | 68031    |
| train/             |          |
|    actor_loss      | -4.92    |
|    critic_loss     | 0.0048   |
|    ent_coef        | 0.00137  |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 58030    |
---------------------------------
Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -4.48    |
|    critic_loss     | 0.00369  |
|    ent_coef        | 0.0013   |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 59999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 36       |
|    time_elapsed    | 1904     |
|    total_timesteps | 70031    |
| train/             |          |
|    actor_loss      | -4.34    |
|    critic_loss     | 0.125    |
|    ent_coef        | 0.00129  |
|    ent_coef_loss   | -0.426   |
|    learning_rate   | 0.0003   |
|    n_updates       | 60030    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 37       |
|    time_elapsed    | 1944     |
|    total_timesteps | 72031    |
| train/             |          |
|    actor_loss      | -4.14    |
|    critic_loss     | 0.00347  |
|    ent_coef        | 0.00106  |
|    ent_coef_loss   | 0.272    |
|    learning_rate   | 0.0003   |
|    n_updates       | 62030    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 37       |
|    time_elapsed    | 1973     |
|    total_timesteps | 73533    |
| train/             |          |
|    actor_loss      | -3.88    |
|    critic_loss     | 0.0035   |
|    ent_coef        | 0.00107  |
|    ent_coef_loss   | -0.0764  |
|    learning_rate   | 0.0003   |
|    n_updates       | 63532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 37       |
|    time_elapsed    | 2008     |
|    total_timesteps | 75533    |
| train/             |          |
|    actor_loss      | -3.58    |
|    critic_loss     | 0.00197  |
|    ent_coef        | 0.000887 |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 65532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 37       |
|    time_elapsed    | 2048     |
|    total_timesteps | 77533    |
| train/             |          |
|    actor_loss      | -3.26    |
|    critic_loss     | 0.00162  |
|    ent_coef        | 0.000813 |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 67532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 38       |
|    time_elapsed    | 2084     |
|    total_timesteps | 79533    |
| train/             |          |
|    actor_loss      | -2.95    |
|    critic_loss     | 0.00143  |
|    ent_coef        | 0.00074  |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 69532    |
---------------------------------
Eval num_timesteps=80000, episode_reward=0.40 +/- 0.49
Episode length: 303.20 +/- 241.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 303      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -3       |
|    critic_loss     | 0.00168  |
|    ent_coef        | 0.000747 |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 69999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 37       |
|    time_elapsed    | 2173     |
|    total_timesteps | 81533    |
| train/             |          |
|    actor_loss      | -2.69    |
|    critic_loss     | 0.00108  |
|    ent_coef        | 0.000722 |
|    ent_coef_loss   | -2.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 71532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 37       |
|    time_elapsed    | 2208     |
|    total_timesteps | 83533    |
| train/             |          |
|    actor_loss      | -2.48    |
|    critic_loss     | 0.000577 |
|    ent_coef        | 0.000656 |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 73532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 38       |
|    time_elapsed    | 2249     |
|    total_timesteps | 85533    |
| train/             |          |
|    actor_loss      | -2.23    |
|    critic_loss     | 0.00078  |
|    ent_coef        | 0.000635 |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 75532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 38       |
|    time_elapsed    | 2297     |
|    total_timesteps | 87533    |
| train/             |          |
|    actor_loss      | -2.08    |
|    critic_loss     | 0.00119  |
|    ent_coef        | 0.000539 |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 77532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 38       |
|    time_elapsed    | 2332     |
|    total_timesteps | 89533    |
| train/             |          |
|    actor_loss      | -1.89    |
|    critic_loss     | 0.00833  |
|    ent_coef        | 0.000474 |
|    ent_coef_loss   | -0.504   |
|    learning_rate   | 0.0003   |
|    n_updates       | 79532    |
---------------------------------
Eval num_timesteps=90000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -1.88    |
|    critic_loss     | 0.000833 |
|    ent_coef        | 0.00047  |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 79999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 37       |
|    time_elapsed    | 2434     |
|    total_timesteps | 91533    |
| train/             |          |
|    actor_loss      | -1.7     |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000467 |
|    ent_coef_loss   | 1.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 81532    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 37       |
|    time_elapsed    | 2470     |
|    total_timesteps | 93034    |
| train/             |          |
|    actor_loss      | -1.56    |
|    critic_loss     | 0.00143  |
|    ent_coef        | 0.00038  |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 83033    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 37       |
|    time_elapsed    | 2521     |
|    total_timesteps | 95034    |
| train/             |          |
|    actor_loss      | -1.49    |
|    critic_loss     | 0.00313  |
|    ent_coef        | 0.000304 |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 85033    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 37       |
|    time_elapsed    | 2570     |
|    total_timesteps | 97034    |
| train/             |          |
|    actor_loss      | -1.34    |
|    critic_loss     | 0.00274  |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 87033    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 37       |
|    time_elapsed    | 2609     |
|    total_timesteps | 99034    |
| train/             |          |
|    actor_loss      | -1.24    |
|    critic_loss     | 0.000443 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 89033    |
---------------------------------
Eval num_timesteps=100000, episode_reward=0.10 +/- 0.30
Episode length: 450.40 +/- 148.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -1.21    |
|    critic_loss     | 0.000361 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 0.0003   |
|    n_updates       | 89999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 37       |
|    time_elapsed    | 2712     |
|    total_timesteps | 101034   |
| train/             |          |
|    actor_loss      | -1.13    |
|    critic_loss     | 0.000372 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 91033    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 37       |
|    time_elapsed    | 2740     |
|    total_timesteps | 102550   |
| train/             |          |
|    actor_loss      | -1.03    |
|    critic_loss     | 0.00039  |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | -3.62    |
|    learning_rate   | 0.0003   |
|    n_updates       | 92549    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 37       |
|    time_elapsed    | 2777     |
|    total_timesteps | 104550   |
| train/             |          |
|    actor_loss      | -0.955   |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 94549    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 37       |
|    time_elapsed    | 2807     |
|    total_timesteps | 106051   |
| train/             |          |
|    actor_loss      | -0.882   |
|    critic_loss     | 0.00026  |
|    ent_coef        | 0.000212 |
|    ent_coef_loss   | 0.808    |
|    learning_rate   | 0.0003   |
|    n_updates       | 96050    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 38       |
|    time_elapsed    | 2842     |
|    total_timesteps | 108051   |
| train/             |          |
|    actor_loss      | -0.801   |
|    critic_loss     | 0.000177 |
|    ent_coef        | 0.000189 |
|    ent_coef_loss   | -0.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 98050    |
---------------------------------
Eval num_timesteps=110000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -0.721   |
|    critic_loss     | 0.000262 |
|    ent_coef        | 0.000157 |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 99999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 37       |
|    time_elapsed    | 2954     |
|    total_timesteps | 110051   |
| train/             |          |
|    actor_loss      | -0.72    |
|    critic_loss     | 0.00249  |
|    ent_coef        | 0.000157 |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 100050   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 37       |
|    time_elapsed    | 2982     |
|    total_timesteps | 111552   |
| train/             |          |
|    actor_loss      | -0.691   |
|    critic_loss     | 0.000456 |
|    ent_coef        | 0.000144 |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 101551   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 37       |
|    time_elapsed    | 3015     |
|    total_timesteps | 113053   |
| train/             |          |
|    actor_loss      | -0.625   |
|    critic_loss     | 0.000555 |
|    ent_coef        | 0.000191 |
|    ent_coef_loss   | 14.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 103052   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 37       |
|    time_elapsed    | 3055     |
|    total_timesteps | 114556   |
| train/             |          |
|    actor_loss      | -0.547   |
|    critic_loss     | 0.000951 |
|    ent_coef        | 0.000143 |
|    ent_coef_loss   | -5.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 104555   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 37       |
|    time_elapsed    | 3099     |
|    total_timesteps | 116057   |
| train/             |          |
|    actor_loss      | -0.502   |
|    critic_loss     | 0.000105 |
|    ent_coef        | 0.000113 |
|    ent_coef_loss   | 0.608    |
|    learning_rate   | 0.0003   |
|    n_updates       | 106056   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 252      |
|    fps             | 37       |
|    time_elapsed    | 3139     |
|    total_timesteps | 118057   |
| train/             |          |
|    actor_loss      | -0.451   |
|    critic_loss     | 0.000112 |
|    ent_coef        | 0.000105 |
|    ent_coef_loss   | 0.181    |
|    learning_rate   | 0.0003   |
|    n_updates       | 108056   |
---------------------------------
Eval num_timesteps=120000, episode_reward=0.10 +/- 0.30
Episode length: 450.20 +/- 149.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -0.407   |
|    critic_loss     | 9.97e-05 |
|    ent_coef        | 9.86e-05 |
|    ent_coef_loss   | -1.81    |
|    learning_rate   | 0.0003   |
|    n_updates       | 109999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 256      |
|    fps             | 36       |
|    time_elapsed    | 3274     |
|    total_timesteps | 120057   |
| train/             |          |
|    actor_loss      | -0.408   |
|    critic_loss     | 0.000116 |
|    ent_coef        | 9.82e-05 |
|    ent_coef_loss   | 0.328    |
|    learning_rate   | 0.0003   |
|    n_updates       | 110056   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 455      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 260      |
|    fps             | 36       |
|    time_elapsed    | 3300     |
|    total_timesteps | 121060   |
| train/             |          |
|    actor_loss      | -0.395   |
|    critic_loss     | 0.000128 |
|    ent_coef        | 0.000104 |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 111059   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 36       |
|    time_elapsed    | 3327     |
|    total_timesteps | 122562   |
| train/             |          |
|    actor_loss      | -0.353   |
|    critic_loss     | 0.000178 |
|    ent_coef        | 0.000112 |
|    ent_coef_loss   | -1.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 112561   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 268      |
|    fps             | 36       |
|    time_elapsed    | 3356     |
|    total_timesteps | 124063   |
| train/             |          |
|    actor_loss      | -0.345   |
|    critic_loss     | 9.48e-05 |
|    ent_coef        | 0.00012  |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 114062   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 272      |
|    fps             | 36       |
|    time_elapsed    | 3394     |
|    total_timesteps | 125565   |
| train/             |          |
|    actor_loss      | -0.322   |
|    critic_loss     | 0.000361 |
|    ent_coef        | 0.00011  |
|    ent_coef_loss   | -0.797   |
|    learning_rate   | 0.0003   |
|    n_updates       | 115564   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 276      |
|    fps             | 36       |
|    time_elapsed    | 3437     |
|    total_timesteps | 127066   |
| train/             |          |
|    actor_loss      | -0.303   |
|    critic_loss     | 8.48e-05 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -5.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 117065   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 37       |
|    time_elapsed    | 3469     |
|    total_timesteps | 128567   |
| train/             |          |
|    actor_loss      | -0.286   |
|    critic_loss     | 0.00112  |
|    ent_coef        | 0.000109 |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 0.0003   |
|    n_updates       | 118566   |
---------------------------------
Eval num_timesteps=130000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -0.267   |
|    critic_loss     | 5.58e-05 |
|    ent_coef        | 0.000102 |
|    ent_coef_loss   | -5.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 36       |
|    time_elapsed    | 3591     |
|    total_timesteps | 130068   |
| train/             |          |
|    actor_loss      | -0.258   |
|    critic_loss     | 0.000187 |
|    ent_coef        | 9.89e-05 |
|    ent_coef_loss   | -4.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 120067   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 36       |
|    time_elapsed    | 3618     |
|    total_timesteps | 131070   |
| train/             |          |
|    actor_loss      | -0.254   |
|    critic_loss     | 0.000287 |
|    ent_coef        | 9.8e-05  |
|    ent_coef_loss   | 0.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 121069   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 36       |
|    time_elapsed    | 3662     |
|    total_timesteps | 133070   |
| train/             |          |
|    actor_loss      | -0.231   |
|    critic_loss     | 0.000118 |
|    ent_coef        | 0.000103 |
|    ent_coef_loss   | 0.943    |
|    learning_rate   | 0.0003   |
|    n_updates       | 123069   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 36       |
|    time_elapsed    | 3706     |
|    total_timesteps | 135070   |
| train/             |          |
|    actor_loss      | -0.226   |
|    critic_loss     | 7.34e-05 |
|    ent_coef        | 9.77e-05 |
|    ent_coef_loss   | 5.55     |
|    learning_rate   | 0.0003   |
|    n_updates       | 125069   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 36       |
|    time_elapsed    | 3754     |
|    total_timesteps | 137070   |
| train/             |          |
|    actor_loss      | -0.206   |
|    critic_loss     | 6.43e-05 |
|    ent_coef        | 0.000107 |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 127069   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 36       |
|    time_elapsed    | 3796     |
|    total_timesteps | 139070   |
| train/             |          |
|    actor_loss      | -0.197   |
|    critic_loss     | 0.000316 |
|    ent_coef        | 0.000115 |
|    ent_coef_loss   | -5.93    |
|    learning_rate   | 0.0003   |
|    n_updates       | 129069   |
---------------------------------
Eval num_timesteps=140000, episode_reward=0.20 +/- 0.40
Episode length: 406.30 +/- 187.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 406      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -0.193   |
|    critic_loss     | 0.000375 |
|    ent_coef        | 0.00011  |
|    ent_coef_loss   | -4.49    |
|    learning_rate   | 0.0003   |
|    n_updates       | 129999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 36       |
|    time_elapsed    | 3883     |
|    total_timesteps | 140072   |
| train/             |          |
|    actor_loss      | -0.194   |
|    critic_loss     | 5.46e-05 |
|    ent_coef        | 0.000108 |
|    ent_coef_loss   | 0.748    |
|    learning_rate   | 0.0003   |
|    n_updates       | 130071   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 36       |
|    time_elapsed    | 3941     |
|    total_timesteps | 142072   |
| train/             |          |
|    actor_loss      | -0.19    |
|    critic_loss     | 5.06e-05 |
|    ent_coef        | 0.000107 |
|    ent_coef_loss   | -0.716   |
|    learning_rate   | 0.0003   |
|    n_updates       | 132071   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 36       |
|    time_elapsed    | 3974     |
|    total_timesteps | 144072   |
| train/             |          |
|    actor_loss      | -0.171   |
|    critic_loss     | 8.02e-05 |
|    ent_coef        | 9.54e-05 |
|    ent_coef_loss   | -0.148   |
|    learning_rate   | 0.0003   |
|    n_updates       | 134071   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 400      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 36       |
|    time_elapsed    | 3988     |
|    total_timesteps | 144585   |
| train/             |          |
|    actor_loss      | -0.182   |
|    critic_loss     | 4.81e-05 |
|    ent_coef        | 0.000101 |
|    ent_coef_loss   | 3.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 134584   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 400      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 36       |
|    time_elapsed    | 4017     |
|    total_timesteps | 146088   |
| train/             |          |
|    actor_loss      | -0.171   |
|    critic_loss     | 0.000131 |
|    ent_coef        | 0.000133 |
|    ent_coef_loss   | 6.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 136087   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 36       |
|    time_elapsed    | 4039     |
|    total_timesteps | 147092   |
| train/             |          |
|    actor_loss      | -0.161   |
|    critic_loss     | 0.000306 |
|    ent_coef        | 0.000128 |
|    ent_coef_loss   | -5.9     |
|    learning_rate   | 0.0003   |
|    n_updates       | 137091   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 36       |
|    time_elapsed    | 4070     |
|    total_timesteps | 148593   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00117  |
|    ent_coef        | 0.000101 |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 138592   |
---------------------------------
Eval num_timesteps=150000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 9.96e-05 |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 139999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 35       |
|    time_elapsed    | 4196     |
|    total_timesteps | 150593   |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 8.1e-05  |
|    ent_coef        | 0.000105 |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 140592   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 35       |
|    time_elapsed    | 4226     |
|    total_timesteps | 152094   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 0.00043  |
|    ent_coef        | 0.000102 |
|    ent_coef_loss   | -2.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 142093   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 344      |
|    fps             | 36       |
|    time_elapsed    | 4257     |
|    total_timesteps | 153595   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 7.4e-05  |
|    ent_coef        | 9.79e-05 |
|    ent_coef_loss   | -4.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 143594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 348      |
|    fps             | 36       |
|    time_elapsed    | 4288     |
|    total_timesteps | 155096   |
| train/             |          |
|    actor_loss      | -0.135   |
|    critic_loss     | 5.95e-05 |
|    ent_coef        | 9.5e-05  |
|    ent_coef_loss   | 0.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 145095   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 352      |
|    fps             | 36       |
|    time_elapsed    | 4347     |
|    total_timesteps | 157096   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 7.72e-05 |
|    ent_coef        | 9.59e-05 |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 0.0003   |
|    n_updates       | 147095   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 356      |
|    fps             | 36       |
|    time_elapsed    | 4378     |
|    total_timesteps | 158099   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 7.07e-05 |
|    ent_coef        | 9.41e-05 |
|    ent_coef_loss   | 3.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 148098   |
---------------------------------
Eval num_timesteps=160000, episode_reward=0.50 +/- 0.50
Episode length: 250.90 +/- 249.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 6.27e-05 |
|    ent_coef        | 9.74e-05 |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 149999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 360      |
|    fps             | 35       |
|    time_elapsed    | 4472     |
|    total_timesteps | 160099   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 6.79e-05 |
|    ent_coef        | 9.93e-05 |
|    ent_coef_loss   | -3.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 150098   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 364      |
|    fps             | 35       |
|    time_elapsed    | 4517     |
|    total_timesteps | 161600   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 0.00106  |
|    ent_coef        | 0.000106 |
|    ent_coef_loss   | 10.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 151599   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 368      |
|    fps             | 35       |
|    time_elapsed    | 4539     |
|    total_timesteps | 162616   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 5.66e-05 |
|    ent_coef        | 0.000112 |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 152615   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 372      |
|    fps             | 35       |
|    time_elapsed    | 4576     |
|    total_timesteps | 164154   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 0.000106 |
|    ent_coef        | 0.000115 |
|    ent_coef_loss   | -1.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 154153   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 376      |
|    fps             | 35       |
|    time_elapsed    | 4607     |
|    total_timesteps | 165657   |
| train/             |          |
|    actor_loss      | -0.124   |
|    critic_loss     | 0.000104 |
|    ent_coef        | 0.000112 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 155656   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 380      |
|    fps             | 36       |
|    time_elapsed    | 4648     |
|    total_timesteps | 167657   |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 0.000136 |
|    ent_coef        | 0.000125 |
|    ent_coef_loss   | 4.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 157656   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 384      |
|    fps             | 36       |
|    time_elapsed    | 4663     |
|    total_timesteps | 168163   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 7.01e-05 |
|    ent_coef        | 0.000121 |
|    ent_coef_loss   | -3.73    |
|    learning_rate   | 0.0003   |
|    n_updates       | 158162   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 388      |
|    fps             | 36       |
|    time_elapsed    | 4692     |
|    total_timesteps | 169166   |
| train/             |          |
|    actor_loss      | -0.146   |
|    critic_loss     | 0.000117 |
|    ent_coef        | 0.000119 |
|    ent_coef_loss   | -0.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 159165   |
---------------------------------
Eval num_timesteps=170000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -0.13    |
|    critic_loss     | 8.15e-05 |
|    ent_coef        | 0.000117 |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 159999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 35       |
|    time_elapsed    | 4807     |
|    total_timesteps | 171166   |
| train/             |          |
|    actor_loss      | -0.161   |
|    critic_loss     | 0.000138 |
|    ent_coef        | 0.000127 |
|    ent_coef_loss   | 3.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 161165   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 376      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 396      |
|    fps             | 35       |
|    time_elapsed    | 4838     |
|    total_timesteps | 172667   |
| train/             |          |
|    actor_loss      | -0.157   |
|    critic_loss     | 0.00019  |
|    ent_coef        | 0.000149 |
|    ent_coef_loss   | 4.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 162666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 400      |
|    fps             | 35       |
|    time_elapsed    | 4880     |
|    total_timesteps | 174168   |
| train/             |          |
|    actor_loss      | -0.147   |
|    critic_loss     | 0.000876 |
|    ent_coef        | 0.000157 |
|    ent_coef_loss   | 0.419    |
|    learning_rate   | 0.0003   |
|    n_updates       | 164167   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 404      |
|    fps             | 35       |
|    time_elapsed    | 4919     |
|    total_timesteps | 175669   |
| train/             |          |
|    actor_loss      | -0.166   |
|    critic_loss     | 0.000255 |
|    ent_coef        | 0.000167 |
|    ent_coef_loss   | 5.47     |
|    learning_rate   | 0.0003   |
|    n_updates       | 165668   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 35       |
|    time_elapsed    | 4949     |
|    total_timesteps | 177170   |
| train/             |          |
|    actor_loss      | -0.187   |
|    critic_loss     | 0.00044  |
|    ent_coef        | 0.000183 |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 167169   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 35       |
|    time_elapsed    | 4983     |
|    total_timesteps | 178671   |
| train/             |          |
|    actor_loss      | -0.169   |
|    critic_loss     | 0.000454 |
|    ent_coef        | 0.000199 |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 168670   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 416      |
|    fps             | 35       |
|    time_elapsed    | 5007     |
|    total_timesteps | 179906   |
| train/             |          |
|    actor_loss      | -0.196   |
|    critic_loss     | 0.000307 |
|    ent_coef        | 0.0002   |
|    ent_coef_loss   | 4.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 169905   |
---------------------------------
Eval num_timesteps=180000, episode_reward=0.30 +/- 0.46
Episode length: 350.30 +/- 228.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -0.236   |
|    critic_loss     | 0.000336 |
|    ent_coef        | 0.0002   |
|    ent_coef_loss   | 6.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 420      |
|    fps             | 35       |
|    time_elapsed    | 5116     |
|    total_timesteps | 181906   |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 0.000249 |
|    ent_coef        | 0.000216 |
|    ent_coef_loss   | 0.00965  |
|    learning_rate   | 0.0003   |
|    n_updates       | 171905   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 424      |
|    fps             | 35       |
|    time_elapsed    | 5149     |
|    total_timesteps | 183408   |
| train/             |          |
|    actor_loss      | -0.194   |
|    critic_loss     | 0.000154 |
|    ent_coef        | 0.000224 |
|    ent_coef_loss   | 0.446    |
|    learning_rate   | 0.0003   |
|    n_updates       | 173407   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 428      |
|    fps             | 35       |
|    time_elapsed    | 5195     |
|    total_timesteps | 184909   |
| train/             |          |
|    actor_loss      | -0.229   |
|    critic_loss     | 0.000226 |
|    ent_coef        | 0.000239 |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 174908   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 35       |
|    time_elapsed    | 5235     |
|    total_timesteps | 186909   |
| train/             |          |
|    actor_loss      | -0.228   |
|    critic_loss     | 0.000433 |
|    ent_coef        | 0.000246 |
|    ent_coef_loss   | 1.3      |
|    learning_rate   | 0.0003   |
|    n_updates       | 176908   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 436      |
|    fps             | 35       |
|    time_elapsed    | 5298     |
|    total_timesteps | 188909   |
| train/             |          |
|    actor_loss      | -0.228   |
|    critic_loss     | 0.000197 |
|    ent_coef        | 0.000239 |
|    ent_coef_loss   | -3.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 178908   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 440      |
|    fps             | 35       |
|    time_elapsed    | 5321     |
|    total_timesteps | 189912   |
| train/             |          |
|    actor_loss      | -0.251   |
|    critic_loss     | 0.000273 |
|    ent_coef        | 0.000242 |
|    ent_coef_loss   | 0.244    |
|    learning_rate   | 0.0003   |
|    n_updates       | 179911   |
---------------------------------
Eval num_timesteps=190000, episode_reward=0.40 +/- 0.49
Episode length: 300.70 +/- 244.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 301      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -0.205   |
|    critic_loss     | 0.000256 |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | -7.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 179999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 444      |
|    fps             | 35       |
|    time_elapsed    | 5418     |
|    total_timesteps | 191413   |
| train/             |          |
|    actor_loss      | -0.266   |
|    critic_loss     | 0.000333 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | 0.869    |
|    learning_rate   | 0.0003   |
|    n_updates       | 181412   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 448      |
|    fps             | 35       |
|    time_elapsed    | 5455     |
|    total_timesteps | 193413   |
| train/             |          |
|    actor_loss      | -0.277   |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 183412   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 452      |
|    fps             | 35       |
|    time_elapsed    | 5489     |
|    total_timesteps | 194349   |
| train/             |          |
|    actor_loss      | -0.26    |
|    critic_loss     | 0.000244 |
|    ent_coef        | 0.000232 |
|    ent_coef_loss   | 2.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 184348   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 456      |
|    fps             | 35       |
|    time_elapsed    | 5527     |
|    total_timesteps | 196349   |
| train/             |          |
|    actor_loss      | -0.266   |
|    critic_loss     | 0.00025  |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 3.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 186348   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 460      |
|    fps             | 35       |
|    time_elapsed    | 5567     |
|    total_timesteps | 198349   |
| train/             |          |
|    actor_loss      | -0.261   |
|    critic_loss     | 0.000424 |
|    ent_coef        | 0.000242 |
|    ent_coef_loss   | -2.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 188348   |
---------------------------------
Eval num_timesteps=200000, episode_reward=0.10 +/- 0.30
Episode length: 450.20 +/- 149.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -0.318   |
|    critic_loss     | 0.000914 |
|    ent_coef        | 0.000246 |
|    ent_coef_loss   | -0.384   |
|    learning_rate   | 0.0003   |
|    n_updates       | 189999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 464      |
|    fps             | 35       |
|    time_elapsed    | 5694     |
|    total_timesteps | 200349   |
| train/             |          |
|    actor_loss      | -0.212   |
|    critic_loss     | 0.000206 |
|    ent_coef        | 0.000253 |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 190348   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 468      |
|    fps             | 35       |
|    time_elapsed    | 5729     |
|    total_timesteps | 202349   |
| train/             |          |
|    actor_loss      | -0.272   |
|    critic_loss     | 0.000838 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 192348   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 472      |
|    fps             | 35       |
|    time_elapsed    | 5757     |
|    total_timesteps | 203853   |
| train/             |          |
|    actor_loss      | -0.275   |
|    critic_loss     | 0.00261  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 193852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 476      |
|    fps             | 35       |
|    time_elapsed    | 5800     |
|    total_timesteps | 205853   |
| train/             |          |
|    actor_loss      | -0.276   |
|    critic_loss     | 0.000625 |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | -1.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 195852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 480      |
|    fps             | 35       |
|    time_elapsed    | 5829     |
|    total_timesteps | 207355   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.000337 |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | -0.409   |
|    learning_rate   | 0.0003   |
|    n_updates       | 197354   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 484      |
|    fps             | 35       |
|    time_elapsed    | 5861     |
|    total_timesteps | 208357   |
| train/             |          |
|    actor_loss      | -0.227   |
|    critic_loss     | 0.00109  |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 198356   |
---------------------------------
Eval num_timesteps=210000, episode_reward=0.30 +/- 0.46
Episode length: 350.70 +/- 228.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 351      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -0.205   |
|    critic_loss     | 0.000316 |
|    ent_coef        | 0.000313 |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 199999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 412      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 488      |
|    fps             | 35       |
|    time_elapsed    | 5955     |
|    total_timesteps | 210357   |
| train/             |          |
|    actor_loss      | -0.325   |
|    critic_loss     | 0.000379 |
|    ent_coef        | 0.000317 |
|    ent_coef_loss   | 2.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 200356   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 492      |
|    fps             | 35       |
|    time_elapsed    | 5984     |
|    total_timesteps | 211361   |
| train/             |          |
|    actor_loss      | -0.309   |
|    critic_loss     | 0.000289 |
|    ent_coef        | 0.000323 |
|    ent_coef_loss   | -0.131   |
|    learning_rate   | 0.0003   |
|    n_updates       | 201360   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 496      |
|    fps             | 35       |
|    time_elapsed    | 6009     |
|    total_timesteps | 212365   |
| train/             |          |
|    actor_loss      | -0.293   |
|    critic_loss     | 0.000534 |
|    ent_coef        | 0.000317 |
|    ent_coef_loss   | 0.838    |
|    learning_rate   | 0.0003   |
|    n_updates       | 202364   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 500      |
|    fps             | 35       |
|    time_elapsed    | 6034     |
|    total_timesteps | 213512   |
| train/             |          |
|    actor_loss      | -0.36    |
|    critic_loss     | 0.000259 |
|    ent_coef        | 0.000315 |
|    ent_coef_loss   | 3.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 203511   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 504      |
|    fps             | 35       |
|    time_elapsed    | 6070     |
|    total_timesteps | 215013   |
| train/             |          |
|    actor_loss      | -0.304   |
|    critic_loss     | 0.000403 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 205012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 508      |
|    fps             | 35       |
|    time_elapsed    | 6113     |
|    total_timesteps | 217013   |
| train/             |          |
|    actor_loss      | -0.303   |
|    critic_loss     | 0.00029  |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 207012   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 512      |
|    fps             | 35       |
|    time_elapsed    | 6159     |
|    total_timesteps | 218514   |
| train/             |          |
|    actor_loss      | -0.292   |
|    critic_loss     | 0.000347 |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 208513   |
---------------------------------
Eval num_timesteps=220000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -0.319   |
|    critic_loss     | 0.00064  |
|    ent_coef        | 0.000304 |
|    ent_coef_loss   | -3.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 209999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 406      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 35       |
|    time_elapsed    | 6264     |
|    total_timesteps | 220514   |
| train/             |          |
|    actor_loss      | -0.288   |
|    critic_loss     | 0.00325  |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | 0.313    |
|    learning_rate   | 0.0003   |
|    n_updates       | 210513   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 520      |
|    fps             | 35       |
|    time_elapsed    | 6282     |
|    total_timesteps | 221044   |
| train/             |          |
|    actor_loss      | -0.353   |
|    critic_loss     | 0.000437 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -0.966   |
|    learning_rate   | 0.0003   |
|    n_updates       | 211043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 524      |
|    fps             | 35       |
|    time_elapsed    | 6338     |
|    total_timesteps | 223044   |
| train/             |          |
|    actor_loss      | -0.273   |
|    critic_loss     | 0.000535 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | 0.497    |
|    learning_rate   | 0.0003   |
|    n_updates       | 213043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 528      |
|    fps             | 35       |
|    time_elapsed    | 6375     |
|    total_timesteps | 224046   |
| train/             |          |
|    actor_loss      | -0.308   |
|    critic_loss     | 0.0101   |
|    ent_coef        | 0.000316 |
|    ent_coef_loss   | -0.338   |
|    learning_rate   | 0.0003   |
|    n_updates       | 214045   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 35       |
|    time_elapsed    | 6415     |
|    total_timesteps | 226046   |
| train/             |          |
|    actor_loss      | -0.355   |
|    critic_loss     | 0.000561 |
|    ent_coef        | 0.000338 |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 0.0003   |
|    n_updates       | 216045   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 536      |
|    fps             | 35       |
|    time_elapsed    | 6455     |
|    total_timesteps | 228046   |
| train/             |          |
|    actor_loss      | -0.34    |
|    critic_loss     | 0.000494 |
|    ent_coef        | 0.000359 |
|    ent_coef_loss   | 4.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 218045   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    episodes        | 540      |
|    fps             | 35       |
|    time_elapsed    | 6483     |
|    total_timesteps | 229555   |
| train/             |          |
|    actor_loss      | -0.286   |
|    critic_loss     | 0.000728 |
|    ent_coef        | 0.000367 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 219554   |
---------------------------------
Eval num_timesteps=230000, episode_reward=0.30 +/- 0.46
Episode length: 350.40 +/- 228.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -0.265   |
|    critic_loss     | 0.000528 |
|    ent_coef        | 0.000363 |
|    ent_coef_loss   | -0.539   |
|    learning_rate   | 0.0003   |
|    n_updates       | 219999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 544      |
|    fps             | 35       |
|    time_elapsed    | 6583     |
|    total_timesteps | 230558   |
| train/             |          |
|    actor_loss      | -0.311   |
|    critic_loss     | 0.000441 |
|    ent_coef        | 0.000363 |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 220557   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 548      |
|    fps             | 35       |
|    time_elapsed    | 6618     |
|    total_timesteps | 232558   |
| train/             |          |
|    actor_loss      | -0.281   |
|    critic_loss     | 0.00082  |
|    ent_coef        | 0.000401 |
|    ent_coef_loss   | -0.226   |
|    learning_rate   | 0.0003   |
|    n_updates       | 222557   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 35       |
|    time_elapsed    | 6663     |
|    total_timesteps | 234558   |
| train/             |          |
|    actor_loss      | -0.269   |
|    critic_loss     | 0.000583 |
|    ent_coef        | 0.000405 |
|    ent_coef_loss   | 0.0121   |
|    learning_rate   | 0.0003   |
|    n_updates       | 224557   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 556      |
|    fps             | 35       |
|    time_elapsed    | 6691     |
|    total_timesteps | 236059   |
| train/             |          |
|    actor_loss      | -0.327   |
|    critic_loss     | 0.000503 |
|    ent_coef        | 0.0004   |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 226058   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 560      |
|    fps             | 35       |
|    time_elapsed    | 6721     |
|    total_timesteps | 237067   |
| train/             |          |
|    actor_loss      | -0.353   |
|    critic_loss     | 0.000653 |
|    ent_coef        | 0.000389 |
|    ent_coef_loss   | 0.598    |
|    learning_rate   | 0.0003   |
|    n_updates       | 227066   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 564      |
|    fps             | 35       |
|    time_elapsed    | 6738     |
|    total_timesteps | 237757   |
| train/             |          |
|    actor_loss      | -0.348   |
|    critic_loss     | 0.000503 |
|    ent_coef        | 0.000394 |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 227756   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 568      |
|    fps             | 35       |
|    time_elapsed    | 6769     |
|    total_timesteps | 239258   |
| train/             |          |
|    actor_loss      | -0.345   |
|    critic_loss     | 0.000641 |
|    ent_coef        | 0.000389 |
|    ent_coef_loss   | 3.72     |
|    learning_rate   | 0.0003   |
|    n_updates       | 229257   |
---------------------------------
Eval num_timesteps=240000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -0.316   |
|    critic_loss     | 0.000494 |
|    ent_coef        | 0.000389 |
|    ent_coef_loss   | -0.582   |
|    learning_rate   | 0.0003   |
|    n_updates       | 229999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 572      |
|    fps             | 35       |
|    time_elapsed    | 6868     |
|    total_timesteps | 240759   |
| train/             |          |
|    actor_loss      | -0.291   |
|    critic_loss     | 0.000815 |
|    ent_coef        | 0.000378 |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 230758   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 576      |
|    fps             | 35       |
|    time_elapsed    | 6915     |
|    total_timesteps | 242759   |
| train/             |          |
|    actor_loss      | -0.355   |
|    critic_loss     | 0.000776 |
|    ent_coef        | 0.000372 |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 0.0003   |
|    n_updates       | 232758   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 580      |
|    fps             | 35       |
|    time_elapsed    | 6948     |
|    total_timesteps | 244263   |
| train/             |          |
|    actor_loss      | -0.331   |
|    critic_loss     | 0.00551  |
|    ent_coef        | 0.000391 |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 0.0003   |
|    n_updates       | 234262   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 584      |
|    fps             | 35       |
|    time_elapsed    | 6979     |
|    total_timesteps | 245774   |
| train/             |          |
|    actor_loss      | -0.353   |
|    critic_loss     | 0.000938 |
|    ent_coef        | 0.000377 |
|    ent_coef_loss   | 0.00212  |
|    learning_rate   | 0.0003   |
|    n_updates       | 235773   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 588      |
|    fps             | 35       |
|    time_elapsed    | 7005     |
|    total_timesteps | 246780   |
| train/             |          |
|    actor_loss      | -0.329   |
|    critic_loss     | 0.000634 |
|    ent_coef        | 0.00039  |
|    ent_coef_loss   | 0.579    |
|    learning_rate   | 0.0003   |
|    n_updates       | 236779   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 592      |
|    fps             | 35       |
|    time_elapsed    | 7040     |
|    total_timesteps | 248780   |
| train/             |          |
|    actor_loss      | -0.349   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000369 |
|    ent_coef_loss   | 3.68     |
|    learning_rate   | 0.0003   |
|    n_updates       | 238779   |
---------------------------------
Eval num_timesteps=250000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -0.386   |
|    critic_loss     | 0.00083  |
|    ent_coef        | 0.000377 |
|    ent_coef_loss   | 0.624    |
|    learning_rate   | 0.0003   |
|    n_updates       | 239999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 596      |
|    fps             | 35       |
|    time_elapsed    | 7123     |
|    total_timesteps | 250282   |
| train/             |          |
|    actor_loss      | -0.351   |
|    critic_loss     | 0.000563 |
|    ent_coef        | 0.000381 |
|    ent_coef_loss   | 0.0836   |
|    learning_rate   | 0.0003   |
|    n_updates       | 240281   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 600      |
|    fps             | 35       |
|    time_elapsed    | 7146     |
|    total_timesteps | 251238   |
| train/             |          |
|    actor_loss      | -0.346   |
|    critic_loss     | 0.00134  |
|    ent_coef        | 0.000404 |
|    ent_coef_loss   | -0.0829  |
|    learning_rate   | 0.0003   |
|    n_updates       | 241237   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 604      |
|    fps             | 35       |
|    time_elapsed    | 7174     |
|    total_timesteps | 252266   |
| train/             |          |
|    actor_loss      | -0.369   |
|    critic_loss     | 0.00069  |
|    ent_coef        | 0.000413 |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 242265   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 608      |
|    fps             | 35       |
|    time_elapsed    | 7211     |
|    total_timesteps | 254266   |
| train/             |          |
|    actor_loss      | -0.35    |
|    critic_loss     | 0.000588 |
|    ent_coef        | 0.000439 |
|    ent_coef_loss   | -0.274   |
|    learning_rate   | 0.0003   |
|    n_updates       | 244265   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 612      |
|    fps             | 35       |
|    time_elapsed    | 7246     |
|    total_timesteps | 255880   |
| train/             |          |
|    actor_loss      | -0.394   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000466 |
|    ent_coef_loss   | -0.639   |
|    learning_rate   | 0.0003   |
|    n_updates       | 245879   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 616      |
|    fps             | 35       |
|    time_elapsed    | 7275     |
|    total_timesteps | 257381   |
| train/             |          |
|    actor_loss      | -0.374   |
|    critic_loss     | 0.000948 |
|    ent_coef        | 0.000484 |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 247380   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 620      |
|    fps             | 35       |
|    time_elapsed    | 7315     |
|    total_timesteps | 258424   |
| train/             |          |
|    actor_loss      | -0.369   |
|    critic_loss     | 0.000818 |
|    ent_coef        | 0.00049  |
|    ent_coef_loss   | 1.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 248423   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 624      |
|    fps             | 35       |
|    time_elapsed    | 7343     |
|    total_timesteps | 259427   |
| train/             |          |
|    actor_loss      | -0.543   |
|    critic_loss     | 0.00221  |
|    ent_coef        | 0.000483 |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 249426   |
---------------------------------
Eval num_timesteps=260000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -0.413   |
|    critic_loss     | 0.00276  |
|    ent_coef        | 0.000509 |
|    ent_coef_loss   | 0.00983  |
|    learning_rate   | 0.0003   |
|    n_updates       | 249999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 628      |
|    fps             | 35       |
|    time_elapsed    | 7449     |
|    total_timesteps | 261427   |
| train/             |          |
|    actor_loss      | -0.598   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000552 |
|    ent_coef_loss   | 0.111    |
|    learning_rate   | 0.0003   |
|    n_updates       | 251426   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 632      |
|    fps             | 35       |
|    time_elapsed    | 7480     |
|    total_timesteps | 262928   |
| train/             |          |
|    actor_loss      | -0.535   |
|    critic_loss     | 0.00411  |
|    ent_coef        | 0.000663 |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 252927   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 636      |
|    fps             | 35       |
|    time_elapsed    | 7506     |
|    total_timesteps | 264429   |
| train/             |          |
|    actor_loss      | -0.652   |
|    critic_loss     | 0.0016   |
|    ent_coef        | 0.000719 |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 0.0003   |
|    n_updates       | 254428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 640      |
|    fps             | 35       |
|    time_elapsed    | 7541     |
|    total_timesteps | 266429   |
| train/             |          |
|    actor_loss      | -0.65    |
|    critic_loss     | 0.00136  |
|    ent_coef        | 0.000817 |
|    ent_coef_loss   | 0.393    |
|    learning_rate   | 0.0003   |
|    n_updates       | 256428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 644      |
|    fps             | 35       |
|    time_elapsed    | 7581     |
|    total_timesteps | 268429   |
| train/             |          |
|    actor_loss      | -0.802   |
|    critic_loss     | 0.00165  |
|    ent_coef        | 0.000836 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 258428   |
---------------------------------
Eval num_timesteps=270000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -0.866   |
|    critic_loss     | 0.0206   |
|    ent_coef        | 0.00072  |
|    ent_coef_loss   | -3.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 259999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 648      |
|    fps             | 35       |
|    time_elapsed    | 7691     |
|    total_timesteps | 270429   |
| train/             |          |
|    actor_loss      | -0.889   |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.0007   |
|    ent_coef_loss   | -0.326   |
|    learning_rate   | 0.0003   |
|    n_updates       | 260428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 652      |
|    fps             | 35       |
|    time_elapsed    | 7734     |
|    total_timesteps | 272429   |
| train/             |          |
|    actor_loss      | -0.961   |
|    critic_loss     | 0.0014   |
|    ent_coef        | 0.00061  |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 262428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 656      |
|    fps             | 35       |
|    time_elapsed    | 7777     |
|    total_timesteps | 274429   |
| train/             |          |
|    actor_loss      | -0.821   |
|    critic_loss     | 0.00141  |
|    ent_coef        | 0.000587 |
|    ent_coef_loss   | -4.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 264428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    episodes        | 660      |
|    fps             | 35       |
|    time_elapsed    | 7810     |
|    total_timesteps | 275931   |
| train/             |          |
|    actor_loss      | -0.86    |
|    critic_loss     | 0.0018   |
|    ent_coef        | 0.000549 |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 0.0003   |
|    n_updates       | 265930   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 664      |
|    fps             | 35       |
|    time_elapsed    | 7843     |
|    total_timesteps | 277931   |
| train/             |          |
|    actor_loss      | -0.771   |
|    critic_loss     | 0.0015   |
|    ent_coef        | 0.000515 |
|    ent_coef_loss   | -0.405   |
|    learning_rate   | 0.0003   |
|    n_updates       | 267930   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 668      |
|    fps             | 35       |
|    time_elapsed    | 7876     |
|    total_timesteps | 279931   |
| train/             |          |
|    actor_loss      | -0.871   |
|    critic_loss     | 0.00633  |
|    ent_coef        | 0.000525 |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 269930   |
---------------------------------
Eval num_timesteps=280000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -0.782   |
|    critic_loss     | 0.00385  |
|    ent_coef        | 0.000522 |
|    ent_coef_loss   | -1.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 269999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 35       |
|    time_elapsed    | 7981     |
|    total_timesteps | 281433   |
| train/             |          |
|    actor_loss      | -0.8     |
|    critic_loss     | 0.00141  |
|    ent_coef        | 0.000539 |
|    ent_coef_loss   | -0.558   |
|    learning_rate   | 0.0003   |
|    n_updates       | 271432   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 676      |
|    fps             | 35       |
|    time_elapsed    | 8019     |
|    total_timesteps | 283433   |
| train/             |          |
|    actor_loss      | -0.753   |
|    critic_loss     | 0.00138  |
|    ent_coef        | 0.0006   |
|    ent_coef_loss   | 0.468    |
|    learning_rate   | 0.0003   |
|    n_updates       | 273432   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 680      |
|    fps             | 35       |
|    time_elapsed    | 8049     |
|    total_timesteps | 284935   |
| train/             |          |
|    actor_loss      | -0.695   |
|    critic_loss     | 0.000875 |
|    ent_coef        | 0.000616 |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 274934   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 407      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 684      |
|    fps             | 35       |
|    time_elapsed    | 8081     |
|    total_timesteps | 286437   |
| train/             |          |
|    actor_loss      | -0.718   |
|    critic_loss     | 0.00124  |
|    ent_coef        | 0.000611 |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 276436   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 688      |
|    fps             | 35       |
|    time_elapsed    | 8115     |
|    total_timesteps | 288437   |
| train/             |          |
|    actor_loss      | -0.658   |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000601 |
|    ent_coef_loss   | 0.256    |
|    learning_rate   | 0.0003   |
|    n_updates       | 278436   |
---------------------------------
Eval num_timesteps=290000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -0.798   |
|    critic_loss     | 0.00121  |
|    ent_coef        | 0.000577 |
|    ent_coef_loss   | 1.73     |
|    learning_rate   | 0.0003   |
|    n_updates       | 279999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 692      |
|    fps             | 35       |
|    time_elapsed    | 8235     |
|    total_timesteps | 290437   |
| train/             |          |
|    actor_loss      | -0.739   |
|    critic_loss     | 0.00126  |
|    ent_coef        | 0.000577 |
|    ent_coef_loss   | -0.399   |
|    learning_rate   | 0.0003   |
|    n_updates       | 280436   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 412      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 696      |
|    fps             | 35       |
|    time_elapsed    | 8258     |
|    total_timesteps | 291439   |
| train/             |          |
|    actor_loss      | -0.764   |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.000543 |
|    ent_coef_loss   | 3.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 281438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 422      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 700      |
|    fps             | 35       |
|    time_elapsed    | 8296     |
|    total_timesteps | 293439   |
| train/             |          |
|    actor_loss      | -0.616   |
|    critic_loss     | 0.00168  |
|    ent_coef        | 0.000513 |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 283438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 704      |
|    fps             | 35       |
|    time_elapsed    | 8336     |
|    total_timesteps | 295439   |
| train/             |          |
|    actor_loss      | -0.605   |
|    critic_loss     | 0.00309  |
|    ent_coef        | 0.000498 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 285438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    episodes        | 708      |
|    fps             | 35       |
|    time_elapsed    | 8377     |
|    total_timesteps | 297439   |
| train/             |          |
|    actor_loss      | -0.661   |
|    critic_loss     | 0.00114  |
|    ent_coef        | 0.000491 |
|    ent_coef_loss   | 0.145    |
|    learning_rate   | 0.0003   |
|    n_updates       | 287438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 35       |
|    time_elapsed    | 8412     |
|    total_timesteps | 299439   |
| train/             |          |
|    actor_loss      | -0.583   |
|    critic_loss     | 0.000934 |
|    ent_coef        | 0.00042  |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 289438   |
---------------------------------
Eval num_timesteps=300000, episode_reward=0.10 +/- 0.30
Episode length: 450.10 +/- 149.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -0.611   |
|    critic_loss     | 0.00738  |
|    ent_coef        | 0.000416 |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 289999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    episodes        | 716      |
|    fps             | 35       |
|    time_elapsed    | 8537     |
|    total_timesteps | 301439   |
| train/             |          |
|    actor_loss      | -0.526   |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000436 |
|    ent_coef_loss   | 0.0973   |
|    learning_rate   | 0.0003   |
|    n_updates       | 291438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 720      |
|    fps             | 35       |
|    time_elapsed    | 8576     |
|    total_timesteps | 303439   |
| train/             |          |
|    actor_loss      | -0.535   |
|    critic_loss     | 0.00105  |
|    ent_coef        | 0.000417 |
|    ent_coef_loss   | -4.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 293438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 724      |
|    fps             | 35       |
|    time_elapsed    | 8615     |
|    total_timesteps | 305439   |
| train/             |          |
|    actor_loss      | -0.504   |
|    critic_loss     | 0.00144  |
|    ent_coef        | 0.000368 |
|    ent_coef_loss   | 2.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 295438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    episodes        | 728      |
|    fps             | 35       |
|    time_elapsed    | 8667     |
|    total_timesteps | 307439   |
| train/             |          |
|    actor_loss      | -0.541   |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | -0.347   |
|    learning_rate   | 0.0003   |
|    n_updates       | 297438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 35       |
|    time_elapsed    | 8710     |
|    total_timesteps | 309439   |
| train/             |          |
|    actor_loss      | -0.476   |
|    critic_loss     | 0.00175  |
|    ent_coef        | 0.000371 |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 299438   |
---------------------------------
Eval num_timesteps=310000, episode_reward=0.20 +/- 0.40
Episode length: 400.20 +/- 199.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -0.476   |
|    critic_loss     | 0.00356  |
|    ent_coef        | 0.000368 |
|    ent_coef_loss   | 5.79     |
|    learning_rate   | 0.0003   |
|    n_updates       | 299999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    episodes        | 736      |
|    fps             | 35       |
|    time_elapsed    | 8795     |
|    total_timesteps | 310942   |
| train/             |          |
|    actor_loss      | -0.399   |
|    critic_loss     | 0.00121  |
|    ent_coef        | 0.000371 |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 300941   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 455      |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 35       |
|    time_elapsed    | 8822     |
|    total_timesteps | 311945   |
| train/             |          |
|    actor_loss      | -0.411   |
|    critic_loss     | 0.00117  |
|    ent_coef        | 0.00036  |
|    ent_coef_loss   | 1.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 301944   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 744      |
|    fps             | 35       |
|    time_elapsed    | 8853     |
|    total_timesteps | 313446   |
| train/             |          |
|    actor_loss      | -0.441   |
|    critic_loss     | 0.00166  |
|    ent_coef        | 0.000364 |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 303445   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 748      |
|    fps             | 35       |
|    time_elapsed    | 8887     |
|    total_timesteps | 314948   |
| train/             |          |
|    actor_loss      | -0.393   |
|    critic_loss     | 0.00388  |
|    ent_coef        | 0.000377 |
|    ent_coef_loss   | 0.374    |
|    learning_rate   | 0.0003   |
|    n_updates       | 304947   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    episodes        | 752      |
|    fps             | 35       |
|    time_elapsed    | 8943     |
|    total_timesteps | 316948   |
| train/             |          |
|    actor_loss      | -0.388   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000376 |
|    ent_coef_loss   | 0.0526   |
|    learning_rate   | 0.0003   |
|    n_updates       | 306947   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 35       |
|    time_elapsed    | 8970     |
|    total_timesteps | 317951   |
| train/             |          |
|    actor_loss      | -0.289   |
|    critic_loss     | 0.00117  |
|    ent_coef        | 0.000383 |
|    ent_coef_loss   | -3.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 307950   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 760      |
|    fps             | 35       |
|    time_elapsed    | 8998     |
|    total_timesteps | 319452   |
| train/             |          |
|    actor_loss      | -0.439   |
|    critic_loss     | 0.00103  |
|    ent_coef        | 0.000357 |
|    ent_coef_loss   | 5.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 309451   |
---------------------------------
Eval num_timesteps=320000, episode_reward=0.10 +/- 0.30
Episode length: 450.20 +/- 149.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -0.335   |
|    critic_loss     | 0.00102  |
|    ent_coef        | 0.000367 |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 309999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    episodes        | 764      |
|    fps             | 35       |
|    time_elapsed    | 9097     |
|    total_timesteps | 321452   |
| train/             |          |
|    actor_loss      | -0.399   |
|    critic_loss     | 0.000693 |
|    ent_coef        | 0.000382 |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 311451   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 768      |
|    fps             | 35       |
|    time_elapsed    | 9118     |
|    total_timesteps | 322454   |
| train/             |          |
|    actor_loss      | -0.362   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000378 |
|    ent_coef_loss   | 0.438    |
|    learning_rate   | 0.0003   |
|    n_updates       | 312453   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    episodes        | 772      |
|    fps             | 35       |
|    time_elapsed    | 9146     |
|    total_timesteps | 323955   |
| train/             |          |
|    actor_loss      | -0.362   |
|    critic_loss     | 0.0187   |
|    ent_coef        | 0.000363 |
|    ent_coef_loss   | 4.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 313954   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 776      |
|    fps             | 35       |
|    time_elapsed    | 9181     |
|    total_timesteps | 325459   |
| train/             |          |
|    actor_loss      | -0.293   |
|    critic_loss     | 0.0254   |
|    ent_coef        | 0.000355 |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 315458   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    episodes        | 780      |
|    fps             | 35       |
|    time_elapsed    | 9210     |
|    total_timesteps | 326961   |
| train/             |          |
|    actor_loss      | -0.213   |
|    critic_loss     | 0.000714 |
|    ent_coef        | 0.000374 |
|    ent_coef_loss   | -3       |
|    learning_rate   | 0.0003   |
|    n_updates       | 316960   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 784      |
|    fps             | 35       |
|    time_elapsed    | 9231     |
|    total_timesteps | 327980   |
| train/             |          |
|    actor_loss      | -0.252   |
|    critic_loss     | 0.00864  |
|    ent_coef        | 0.000377 |
|    ent_coef_loss   | 0.763    |
|    learning_rate   | 0.0003   |
|    n_updates       | 317979   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    episodes        | 788      |
|    fps             | 35       |
|    time_elapsed    | 9275     |
|    total_timesteps | 329980   |
| train/             |          |
|    actor_loss      | -0.201   |
|    critic_loss     | 0.000819 |
|    ent_coef        | 0.000374 |
|    ent_coef_loss   | -3.45    |
|    learning_rate   | 0.0003   |
|    n_updates       | 319979   |
---------------------------------
Eval num_timesteps=330000, episode_reward=0.20 +/- 0.40
Episode length: 400.20 +/- 199.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -0.272   |
|    critic_loss     | 0.000675 |
|    ent_coef        | 0.000374 |
|    ent_coef_loss   | 0.931    |
|    learning_rate   | 0.0003   |
|    n_updates       | 319999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 401      |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    episodes        | 792      |
|    fps             | 35       |
|    time_elapsed    | 9351     |
|    total_timesteps | 330520   |
| train/             |          |
|    actor_loss      | -0.278   |
|    critic_loss     | 0.00266  |
|    ent_coef        | 0.000378 |
|    ent_coef_loss   | -0.415   |
|    learning_rate   | 0.0003   |
|    n_updates       | 320519   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 411      |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    episodes        | 796      |
|    fps             | 35       |
|    time_elapsed    | 9393     |
|    total_timesteps | 332520   |
| train/             |          |
|    actor_loss      | -0.276   |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.000379 |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 322519   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 0.19     |
| time/              |          |
|    episodes        | 800      |
|    fps             | 35       |
|    time_elapsed    | 9429     |
|    total_timesteps | 334226   |
| train/             |          |
|    actor_loss      | -0.242   |
|    critic_loss     | 0.000757 |
|    ent_coef        | 0.000381 |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 324225   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 398      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 804      |
|    fps             | 35       |
|    time_elapsed    | 9450     |
|    total_timesteps | 335229   |
| train/             |          |
|    actor_loss      | -0.273   |
|    critic_loss     | 0.00105  |
|    ent_coef        | 0.00041  |
|    ent_coef_loss   | 3.95     |
|    learning_rate   | 0.0003   |
|    n_updates       | 325228   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    episodes        | 808      |
|    fps             | 35       |
|    time_elapsed    | 9476     |
|    total_timesteps | 336231   |
| train/             |          |
|    actor_loss      | -0.227   |
|    critic_loss     | 0.000545 |
|    ent_coef        | 0.000401 |
|    ent_coef_loss   | -0.874   |
|    learning_rate   | 0.0003   |
|    n_updates       | 326230   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 812      |
|    fps             | 35       |
|    time_elapsed    | 9506     |
|    total_timesteps | 337233   |
| train/             |          |
|    actor_loss      | -0.298   |
|    critic_loss     | 0.000803 |
|    ent_coef        | 0.000371 |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 327232   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 816      |
|    fps             | 35       |
|    time_elapsed    | 9542     |
|    total_timesteps | 339233   |
| train/             |          |
|    actor_loss      | -0.289   |
|    critic_loss     | 0.00153  |
|    ent_coef        | 0.000376 |
|    ent_coef_loss   | 3        |
|    learning_rate   | 0.0003   |
|    n_updates       | 329232   |
---------------------------------
Eval num_timesteps=340000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -0.226   |
|    critic_loss     | 0.00751  |
|    ent_coef        | 0.000361 |
|    ent_coef_loss   | -2.78    |
|    learning_rate   | 0.0003   |
|    n_updates       | 329999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 820      |
|    fps             | 35       |
|    time_elapsed    | 9659     |
|    total_timesteps | 340236   |
| train/             |          |
|    actor_loss      | -0.218   |
|    critic_loss     | 0.000668 |
|    ent_coef        | 0.000371 |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 330235   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 824      |
|    fps             | 35       |
|    time_elapsed    | 9696     |
|    total_timesteps | 342236   |
| train/             |          |
|    actor_loss      | -0.253   |
|    critic_loss     | 0.00117  |
|    ent_coef        | 0.000371 |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 332235   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 828      |
|    fps             | 35       |
|    time_elapsed    | 9749     |
|    total_timesteps | 343741   |
| train/             |          |
|    actor_loss      | -0.291   |
|    critic_loss     | 0.000613 |
|    ent_coef        | 0.000348 |
|    ent_coef_loss   | 2.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 333740   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 832      |
|    fps             | 35       |
|    time_elapsed    | 9796     |
|    total_timesteps | 345243   |
| train/             |          |
|    actor_loss      | -0.207   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000333 |
|    ent_coef_loss   | 0.155    |
|    learning_rate   | 0.0003   |
|    n_updates       | 335242   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 836      |
|    fps             | 35       |
|    time_elapsed    | 9832     |
|    total_timesteps | 347243   |
| train/             |          |
|    actor_loss      | -0.214   |
|    critic_loss     | 0.00132  |
|    ent_coef        | 0.000309 |
|    ent_coef_loss   | 0.0924   |
|    learning_rate   | 0.0003   |
|    n_updates       | 337242   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 840      |
|    fps             | 35       |
|    time_elapsed    | 9860     |
|    total_timesteps | 348744   |
| train/             |          |
|    actor_loss      | -0.217   |
|    critic_loss     | 0.000737 |
|    ent_coef        | 0.000305 |
|    ent_coef_loss   | -3.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 338743   |
---------------------------------
Eval num_timesteps=350000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -0.196   |
|    critic_loss     | 0.000618 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | 0.994    |
|    learning_rate   | 0.0003   |
|    n_updates       | 339999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 844      |
|    fps             | 35       |
|    time_elapsed    | 9950     |
|    total_timesteps | 350245   |
| train/             |          |
|    actor_loss      | -0.234   |
|    critic_loss     | 0.0025   |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | 0.984    |
|    learning_rate   | 0.0003   |
|    n_updates       | 340244   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 848      |
|    fps             | 35       |
|    time_elapsed    | 9972     |
|    total_timesteps | 351247   |
| train/             |          |
|    actor_loss      | -0.215   |
|    critic_loss     | 0.000495 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 341246   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 0.3      |
| time/              |          |
|    episodes        | 852      |
|    fps             | 35       |
|    time_elapsed    | 9995     |
|    total_timesteps | 352265   |
| train/             |          |
|    actor_loss      | -0.217   |
|    critic_loss     | 0.000434 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 0.194    |
|    learning_rate   | 0.0003   |
|    n_updates       | 342264   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 856      |
|    fps             | 35       |
|    time_elapsed    | 10030    |
|    total_timesteps | 354265   |
| train/             |          |
|    actor_loss      | -0.158   |
|    critic_loss     | 0.00044  |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 344264   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 860      |
|    fps             | 35       |
|    time_elapsed    | 10080    |
|    total_timesteps | 356265   |
| train/             |          |
|    actor_loss      | -0.203   |
|    critic_loss     | 0.000484 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 4.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 346264   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 864      |
|    fps             | 35       |
|    time_elapsed    | 10121    |
|    total_timesteps | 357767   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.000466 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | -0.844   |
|    learning_rate   | 0.0003   |
|    n_updates       | 347766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 365      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 868      |
|    fps             | 35       |
|    time_elapsed    | 10157    |
|    total_timesteps | 358944   |
| train/             |          |
|    actor_loss      | -0.129   |
|    critic_loss     | 0.000565 |
|    ent_coef        | 0.000248 |
|    ent_coef_loss   | 2.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 348943   |
---------------------------------
Eval num_timesteps=360000, episode_reward=0.20 +/- 0.40
Episode length: 403.00 +/- 194.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 403      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -0.162   |
|    critic_loss     | 0.000374 |
|    ent_coef        | 0.000234 |
|    ent_coef_loss   | 5.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 349999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 872      |
|    fps             | 35       |
|    time_elapsed    | 10287    |
|    total_timesteps | 360944   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.00173  |
|    ent_coef        | 0.000237 |
|    ent_coef_loss   | -2.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 350943   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 876      |
|    fps             | 35       |
|    time_elapsed    | 10327    |
|    total_timesteps | 362446   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.000337 |
|    ent_coef        | 0.00024  |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 352445   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 880      |
|    fps             | 35       |
|    time_elapsed    | 10354    |
|    total_timesteps | 363563   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000351 |
|    ent_coef        | 0.000251 |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 353562   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 884      |
|    fps             | 35       |
|    time_elapsed    | 10384    |
|    total_timesteps | 365065   |
| train/             |          |
|    actor_loss      | -0.117   |
|    critic_loss     | 0.000459 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 355064   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 888      |
|    fps             | 35       |
|    time_elapsed    | 10414    |
|    total_timesteps | 366566   |
| train/             |          |
|    actor_loss      | -0.127   |
|    critic_loss     | 0.000562 |
|    ent_coef        | 0.000246 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 356565   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    episodes        | 892      |
|    fps             | 35       |
|    time_elapsed    | 10462    |
|    total_timesteps | 368566   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.000496 |
|    ent_coef        | 0.000229 |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 358565   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 896      |
|    fps             | 35       |
|    time_elapsed    | 10484    |
|    total_timesteps | 369568   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.000396 |
|    ent_coef        | 0.00024  |
|    ent_coef_loss   | -0.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 359567   |
---------------------------------
Eval num_timesteps=370000, episode_reward=0.20 +/- 0.40
Episode length: 400.20 +/- 199.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -0.105   |
|    critic_loss     | 0.000495 |
|    ent_coef        | 0.000232 |
|    ent_coef_loss   | 0.141    |
|    learning_rate   | 0.0003   |
|    n_updates       | 359999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 900      |
|    fps             | 35       |
|    time_elapsed    | 10582    |
|    total_timesteps | 370571   |
| train/             |          |
|    actor_loss      | -0.136   |
|    critic_loss     | 0.000491 |
|    ent_coef        | 0.000232 |
|    ent_coef_loss   | 2.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 360570   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 904      |
|    fps             | 34       |
|    time_elapsed    | 10633    |
|    total_timesteps | 372075   |
| train/             |          |
|    actor_loss      | -0.105   |
|    critic_loss     | 0.000344 |
|    ent_coef        | 0.000237 |
|    ent_coef_loss   | 3.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 362074   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 908      |
|    fps             | 34       |
|    time_elapsed    | 10669    |
|    total_timesteps | 373084   |
| train/             |          |
|    actor_loss      | -0.0945  |
|    critic_loss     | 0.000349 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | -4.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 363083   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 912      |
|    fps             | 34       |
|    time_elapsed    | 10692    |
|    total_timesteps | 374087   |
| train/             |          |
|    actor_loss      | -0.0903  |
|    critic_loss     | 0.000394 |
|    ent_coef        | 0.000236 |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 364086   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 916      |
|    fps             | 34       |
|    time_elapsed    | 10729    |
|    total_timesteps | 375090   |
| train/             |          |
|    actor_loss      | -0.0883  |
|    critic_loss     | 0.000364 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 365089   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 920      |
|    fps             | 34       |
|    time_elapsed    | 10781    |
|    total_timesteps | 377090   |
| train/             |          |
|    actor_loss      | -0.0665  |
|    critic_loss     | 0.000531 |
|    ent_coef        | 0.000235 |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 367089   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 924      |
|    fps             | 35       |
|    time_elapsed    | 10813    |
|    total_timesteps | 378591   |
| train/             |          |
|    actor_loss      | -0.0982  |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.000221 |
|    ent_coef_loss   | 0.147    |
|    learning_rate   | 0.0003   |
|    n_updates       | 368590   |
---------------------------------
Eval num_timesteps=380000, episode_reward=0.10 +/- 0.30
Episode length: 450.20 +/- 149.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -0.0904  |
|    critic_loss     | 0.000414 |
|    ent_coef        | 0.00023  |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 0.0003   |
|    n_updates       | 369999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 928      |
|    fps             | 34       |
|    time_elapsed    | 10937    |
|    total_timesteps | 380591   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.000454 |
|    ent_coef        | 0.000228 |
|    ent_coef_loss   | 4.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 370590   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 932      |
|    fps             | 34       |
|    time_elapsed    | 10957    |
|    total_timesteps | 381595   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.000342 |
|    ent_coef        | 0.000223 |
|    ent_coef_loss   | -1.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 371594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 936      |
|    fps             | 34       |
|    time_elapsed    | 10996    |
|    total_timesteps | 383595   |
| train/             |          |
|    actor_loss      | -0.114   |
|    critic_loss     | 0.000544 |
|    ent_coef        | 0.000218 |
|    ent_coef_loss   | 4.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 373594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 940      |
|    fps             | 34       |
|    time_elapsed    | 11019    |
|    total_timesteps | 384598   |
| train/             |          |
|    actor_loss      | -0.119   |
|    critic_loss     | 0.000508 |
|    ent_coef        | 0.000214 |
|    ent_coef_loss   | 3.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 374597   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    episodes        | 944      |
|    fps             | 34       |
|    time_elapsed    | 11046    |
|    total_timesteps | 386100   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.00232  |
|    ent_coef        | 0.000208 |
|    ent_coef_loss   | 2.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 376099   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 948      |
|    fps             | 34       |
|    time_elapsed    | 11075    |
|    total_timesteps | 387601   |
| train/             |          |
|    actor_loss      | -0.125   |
|    critic_loss     | 0.000352 |
|    ent_coef        | 0.000209 |
|    ent_coef_loss   | 2.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 377600   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 952      |
|    fps             | 35       |
|    time_elapsed    | 11108    |
|    total_timesteps | 389102   |
| train/             |          |
|    actor_loss      | -0.073   |
|    critic_loss     | 0.000388 |
|    ent_coef        | 0.000199 |
|    ent_coef_loss   | 1.05     |
|    learning_rate   | 0.0003   |
|    n_updates       | 379101   |
---------------------------------
Eval num_timesteps=390000, episode_reward=0.50 +/- 0.50
Episode length: 254.50 +/- 245.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 254      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -0.0806  |
|    critic_loss     | 0.000782 |
|    ent_coef        | 0.000206 |
|    ent_coef_loss   | 3.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 379999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 956      |
|    fps             | 34       |
|    time_elapsed    | 11199    |
|    total_timesteps | 390603   |
| train/             |          |
|    actor_loss      | -0.0817  |
|    critic_loss     | 0.000372 |
|    ent_coef        | 0.000209 |
|    ent_coef_loss   | -0.653   |
|    learning_rate   | 0.0003   |
|    n_updates       | 380602   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 363      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 960      |
|    fps             | 34       |
|    time_elapsed    | 11240    |
|    total_timesteps | 392603   |
| train/             |          |
|    actor_loss      | -0.0597  |
|    critic_loss     | 0.000605 |
|    ent_coef        | 0.000207 |
|    ent_coef_loss   | 0.754    |
|    learning_rate   | 0.0003   |
|    n_updates       | 382602   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 368      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 964      |
|    fps             | 34       |
|    time_elapsed    | 11278    |
|    total_timesteps | 394603   |
| train/             |          |
|    actor_loss      | -0.0729  |
|    critic_loss     | 0.00376  |
|    ent_coef        | 0.000205 |
|    ent_coef_loss   | 4.37     |
|    learning_rate   | 0.0003   |
|    n_updates       | 384602   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 968      |
|    fps             | 35       |
|    time_elapsed    | 11312    |
|    total_timesteps | 396105   |
| train/             |          |
|    actor_loss      | -0.0684  |
|    critic_loss     | 0.000307 |
|    ent_coef        | 0.000218 |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 386104   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 972      |
|    fps             | 35       |
|    time_elapsed    | 11361    |
|    total_timesteps | 398105   |
| train/             |          |
|    actor_loss      | -0.0901  |
|    critic_loss     | 0.000325 |
|    ent_coef        | 0.00022  |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 388104   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 976      |
|    fps             | 35       |
|    time_elapsed    | 11380    |
|    total_timesteps | 398610   |
| train/             |          |
|    actor_loss      | -0.0702  |
|    critic_loss     | 0.000362 |
|    ent_coef        | 0.000224 |
|    ent_coef_loss   | -0.807   |
|    learning_rate   | 0.0003   |
|    n_updates       | 388609   |
---------------------------------
Eval num_timesteps=400000, episode_reward=0.10 +/- 0.30
Episode length: 457.20 +/- 128.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 457      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -0.0903  |
|    critic_loss     | 0.015    |
|    ent_coef        | 0.000228 |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 0.0003   |
|    n_updates       | 389999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    episodes        | 980      |
|    fps             | 34       |
|    time_elapsed    | 11494    |
|    total_timesteps | 400610   |
| train/             |          |
|    actor_loss      | -0.0892  |
|    critic_loss     | 0.000489 |
|    ent_coef        | 0.000223 |
|    ent_coef_loss   | -0.463   |
|    learning_rate   | 0.0003   |
|    n_updates       | 390609   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 365      |
|    ep_rew_mean     | 0.27     |
| time/              |          |
|    episodes        | 984      |
|    fps             | 34       |
|    time_elapsed    | 11514    |
|    total_timesteps | 401613   |
| train/             |          |
|    actor_loss      | -0.0709  |
|    critic_loss     | 0.000464 |
|    ent_coef        | 0.00022  |
|    ent_coef_loss   | 1.83     |
|    learning_rate   | 0.0003   |
|    n_updates       | 391612   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    episodes        | 988      |
|    fps             | 34       |
|    time_elapsed    | 11550    |
|    total_timesteps | 402650   |
| train/             |          |
|    actor_loss      | -0.0722  |
|    critic_loss     | 0.000576 |
|    ent_coef        | 0.00023  |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 392649   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 0.31     |
| time/              |          |
|    episodes        | 992      |
|    fps             | 34       |
|    time_elapsed    | 11574    |
|    total_timesteps | 403469   |
| train/             |          |
|    actor_loss      | -0.0703  |
|    critic_loss     | 0.000601 |
|    ent_coef        | 0.000233 |
|    ent_coef_loss   | 1.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 393468   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 350      |
|    ep_rew_mean     | 0.31     |
| time/              |          |
|    episodes        | 996      |
|    fps             | 34       |
|    time_elapsed    | 11605    |
|    total_timesteps | 404525   |
| train/             |          |
|    actor_loss      | -0.0638  |
|    critic_loss     | 0.000421 |
|    ent_coef        | 0.000229 |
|    ent_coef_loss   | -2.9     |
|    learning_rate   | 0.0003   |
|    n_updates       | 394524   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 0.32     |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 34       |
|    time_elapsed    | 11623    |
|    total_timesteps | 405100   |
| train/             |          |
|    actor_loss      | -0.0713  |
|    critic_loss     | 0.000285 |
|    ent_coef        | 0.000228 |
|    ent_coef_loss   | 1.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 395099   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 0.34     |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 34       |
|    time_elapsed    | 11646    |
|    total_timesteps | 405634   |
| train/             |          |
|    actor_loss      | -0.0691  |
|    critic_loss     | 0.000324 |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | 0.278    |
|    learning_rate   | 0.0003   |
|    n_updates       | 395633   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 336      |
|    ep_rew_mean     | 0.34     |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 34       |
|    time_elapsed    | 11667    |
|    total_timesteps | 406637   |
| train/             |          |
|    actor_loss      | -0.0932  |
|    critic_loss     | 0.000464 |
|    ent_coef        | 0.000241 |
|    ent_coef_loss   | 2.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 396636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 0.34     |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 34       |
|    time_elapsed    | 11692    |
|    total_timesteps | 407753   |
| train/             |          |
|    actor_loss      | -0.0684  |
|    critic_loss     | 0.00032  |
|    ent_coef        | 0.000246 |
|    ent_coef_loss   | -3.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 397752   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 0.35     |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 34       |
|    time_elapsed    | 11714    |
|    total_timesteps | 408288   |
| train/             |          |
|    actor_loss      | -0.0781  |
|    critic_loss     | 0.000593 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | 3.91     |
|    learning_rate   | 0.0003   |
|    n_updates       | 398287   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 0.38     |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 34       |
|    time_elapsed    | 11730    |
|    total_timesteps | 408924   |
| train/             |          |
|    actor_loss      | -0.0735  |
|    critic_loss     | 0.000467 |
|    ent_coef        | 0.000245 |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 398923   |
---------------------------------
Eval num_timesteps=410000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -0.0749  |
|    critic_loss     | 0.00033  |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | 2.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 399999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 0.38     |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 34       |
|    time_elapsed    | 11840    |
|    total_timesteps | 410426   |
| train/             |          |
|    actor_loss      | -0.0733  |
|    critic_loss     | 0.000539 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -3.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 400425   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 0.4      |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 34       |
|    time_elapsed    | 11863    |
|    total_timesteps | 411429   |
| train/             |          |
|    actor_loss      | -0.0771  |
|    critic_loss     | 0.00045  |
|    ent_coef        | 0.000251 |
|    ent_coef_loss   | -3.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 401428   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 0.4      |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 34       |
|    time_elapsed    | 11898    |
|    total_timesteps | 412749   |
| train/             |          |
|    actor_loss      | -0.0841  |
|    critic_loss     | 0.000502 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 0.0264   |
|    learning_rate   | 0.0003   |
|    n_updates       | 402748   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 34       |
|    time_elapsed    | 11927    |
|    total_timesteps | 413943   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.000421 |
|    ent_coef        | 0.000254 |
|    ent_coef_loss   | 2.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 403942   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 34       |
|    time_elapsed    | 11956    |
|    total_timesteps | 414946   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.00228  |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | 5.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 404945   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 300      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 34       |
|    time_elapsed    | 11985    |
|    total_timesteps | 416102   |
| train/             |          |
|    actor_loss      | -0.105   |
|    critic_loss     | 0.000369 |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -0.788   |
|    learning_rate   | 0.0003   |
|    n_updates       | 406101   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 295      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 34       |
|    time_elapsed    | 12007    |
|    total_timesteps | 417104   |
| train/             |          |
|    actor_loss      | -0.115   |
|    critic_loss     | 0.00165  |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 0.166    |
|    learning_rate   | 0.0003   |
|    n_updates       | 407103   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 295      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 34       |
|    time_elapsed    | 12065    |
|    total_timesteps | 418605   |
| train/             |          |
|    actor_loss      | -0.128   |
|    critic_loss     | 0.000586 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | 0.865    |
|    learning_rate   | 0.0003   |
|    n_updates       | 408604   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 34       |
|    time_elapsed    | 12082    |
|    total_timesteps | 419239   |
| train/             |          |
|    actor_loss      | -0.117   |
|    critic_loss     | 0.000721 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 409238   |
---------------------------------
Eval num_timesteps=420000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -0.0993  |
|    critic_loss     | 0.000377 |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 409999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 34       |
|    time_elapsed    | 12170    |
|    total_timesteps | 420268   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000385 |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -3.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 410267   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 34       |
|    time_elapsed    | 12189    |
|    total_timesteps | 420965   |
| train/             |          |
|    actor_loss      | -0.0902  |
|    critic_loss     | 0.00047  |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 410964   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 34       |
|    time_elapsed    | 12239    |
|    total_timesteps | 422965   |
| train/             |          |
|    actor_loss      | -0.116   |
|    critic_loss     | 0.000457 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 412964   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 34       |
|    time_elapsed    | 12265    |
|    total_timesteps | 423469   |
| train/             |          |
|    actor_loss      | -0.0756  |
|    critic_loss     | 0.000263 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -1.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 413468   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 34       |
|    time_elapsed    | 12299    |
|    total_timesteps | 424970   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 0.000362 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 2.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 414969   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 34       |
|    time_elapsed    | 12331    |
|    total_timesteps | 425972   |
| train/             |          |
|    actor_loss      | -0.106   |
|    critic_loss     | 0.000341 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 415971   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 34       |
|    time_elapsed    | 12351    |
|    total_timesteps | 426540   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.000359 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -2.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 416539   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 34       |
|    time_elapsed    | 12371    |
|    total_timesteps | 427320   |
| train/             |          |
|    actor_loss      | -0.103   |
|    critic_loss     | 0.000318 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 417319   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 34       |
|    time_elapsed    | 12401    |
|    total_timesteps | 428383   |
| train/             |          |
|    actor_loss      | -0.131   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 0.986    |
|    learning_rate   | 0.0003   |
|    n_updates       | 418382   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 34       |
|    time_elapsed    | 12426    |
|    total_timesteps | 429495   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000332 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | -3.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 419494   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 34       |
|    time_elapsed    | 12434    |
|    total_timesteps | 429572   |
| train/             |          |
|    actor_loss      | -0.0991  |
|    critic_loss     | 0.000335 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 419571   |
---------------------------------
Eval num_timesteps=430000, episode_reward=0.60 +/- 0.49
Episode length: 213.40 +/- 234.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 213      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -0.112   |
|    critic_loss     | 0.000539 |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 419999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 34       |
|    time_elapsed    | 12502    |
|    total_timesteps | 430085   |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.000294 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 420084   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 34       |
|    time_elapsed    | 12513    |
|    total_timesteps | 430129   |
| train/             |          |
|    actor_loss      | -0.117   |
|    critic_loss     | 0.00037  |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -2       |
|    learning_rate   | 0.0003   |
|    n_updates       | 420128   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 34       |
|    time_elapsed    | 12538    |
|    total_timesteps | 431107   |
| train/             |          |
|    actor_loss      | -0.124   |
|    critic_loss     | 0.000332 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 421106   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 34       |
|    time_elapsed    | 12547    |
|    total_timesteps | 431160   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 0.000429 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 421159   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 34       |
|    time_elapsed    | 12575    |
|    total_timesteps | 432204   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.000454 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | -0.245   |
|    learning_rate   | 0.0003   |
|    n_updates       | 422203   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 34       |
|    time_elapsed    | 12606    |
|    total_timesteps | 433208   |
| train/             |          |
|    actor_loss      | -0.0897  |
|    critic_loss     | 0.000263 |
|    ent_coef        | 0.000253 |
|    ent_coef_loss   | -5.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 423207   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 34       |
|    time_elapsed    | 12657    |
|    total_timesteps | 434764   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.000404 |
|    ent_coef        | 0.000253 |
|    ent_coef_loss   | 2.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 424763   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 34       |
|    time_elapsed    | 12682    |
|    total_timesteps | 436015   |
| train/             |          |
|    actor_loss      | -0.0736  |
|    critic_loss     | 0.000409 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 426014   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 34       |
|    time_elapsed    | 12702    |
|    total_timesteps | 436520   |
| train/             |          |
|    actor_loss      | -0.163   |
|    critic_loss     | 0.000396 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 426519   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 34       |
|    time_elapsed    | 12741    |
|    total_timesteps | 437886   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 0.000669 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 3.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 427885   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 34       |
|    time_elapsed    | 12782    |
|    total_timesteps | 439457   |
| train/             |          |
|    actor_loss      | -0.135   |
|    critic_loss     | 0.00132  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 0.0509   |
|    learning_rate   | 0.0003   |
|    n_updates       | 429456   |
---------------------------------
Eval num_timesteps=440000, episode_reward=0.30 +/- 0.46
Episode length: 353.10 +/- 224.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 353      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -0.0813  |
|    critic_loss     | 0.000315 |
|    ent_coef        | 0.000251 |
|    ent_coef_loss   | -0.648   |
|    learning_rate   | 0.0003   |
|    n_updates       | 429999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 34       |
|    time_elapsed    | 12862    |
|    total_timesteps | 440959   |
| train/             |          |
|    actor_loss      | -0.0893  |
|    critic_loss     | 0.000456 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | -0.984   |
|    learning_rate   | 0.0003   |
|    n_updates       | 430958   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 34       |
|    time_elapsed    | 12898    |
|    total_timesteps | 442959   |
| train/             |          |
|    actor_loss      | -0.123   |
|    critic_loss     | 0.000981 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 5.04     |
|    learning_rate   | 0.0003   |
|    n_updates       | 432958   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 34       |
|    time_elapsed    | 12926    |
|    total_timesteps | 444212   |
| train/             |          |
|    actor_loss      | -0.118   |
|    critic_loss     | 0.000438 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 434211   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 34       |
|    time_elapsed    | 12952    |
|    total_timesteps | 445325   |
| train/             |          |
|    actor_loss      | -0.0976  |
|    critic_loss     | 0.000716 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -5.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 435324   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 259      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 34       |
|    time_elapsed    | 12984    |
|    total_timesteps | 446827   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000843 |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 436826   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 34       |
|    time_elapsed    | 13007    |
|    total_timesteps | 447539   |
| train/             |          |
|    actor_loss      | -0.107   |
|    critic_loss     | 0.000538 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | 0.541    |
|    learning_rate   | 0.0003   |
|    n_updates       | 437538   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 34       |
|    time_elapsed    | 13029    |
|    total_timesteps | 448568   |
| train/             |          |
|    actor_loss      | -0.0908  |
|    critic_loss     | 0.000371 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -1.13    |
|    learning_rate   | 0.0003   |
|    n_updates       | 438567   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 34       |
|    time_elapsed    | 13050    |
|    total_timesteps | 449653   |
| train/             |          |
|    actor_loss      | -0.151   |
|    critic_loss     | 0.000446 |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | -2.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 439652   |
---------------------------------
Eval num_timesteps=450000, episode_reward=0.30 +/- 0.46
Episode length: 358.20 +/- 216.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 358      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | 2.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 439999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 34       |
|    time_elapsed    | 13149    |
|    total_timesteps | 451638   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.000352 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -2.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 441637   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 34       |
|    time_elapsed    | 13164    |
|    total_timesteps | 452191   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.000528 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | -4.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 442190   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 34       |
|    time_elapsed    | 13198    |
|    total_timesteps | 453169   |
| train/             |          |
|    actor_loss      | -0.0879  |
|    critic_loss     | 0.000533 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -4.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 443168   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 34       |
|    time_elapsed    | 13224    |
|    total_timesteps | 454219   |
| train/             |          |
|    actor_loss      | -0.119   |
|    critic_loss     | 0.000479 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 0.0003   |
|    n_updates       | 444218   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 34       |
|    time_elapsed    | 13262    |
|    total_timesteps | 456037   |
| train/             |          |
|    actor_loss      | -0.114   |
|    critic_loss     | 0.00048  |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | -1.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 446036   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 280      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 34       |
|    time_elapsed    | 13300    |
|    total_timesteps | 457538   |
| train/             |          |
|    actor_loss      | -0.124   |
|    critic_loss     | 0.000611 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 447537   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 290      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 34       |
|    time_elapsed    | 13353    |
|    total_timesteps | 459091   |
| train/             |          |
|    actor_loss      | -0.128   |
|    critic_loss     | 0.000809 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 3.3      |
|    learning_rate   | 0.0003   |
|    n_updates       | 449090   |
---------------------------------
Eval num_timesteps=460000, episode_reward=0.60 +/- 0.49
Episode length: 201.00 +/- 244.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -0.0723  |
|    critic_loss     | 0.00221  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 449999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 305      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 34       |
|    time_elapsed    | 13435    |
|    total_timesteps | 460592   |
| train/             |          |
|    actor_loss      | -0.138   |
|    critic_loss     | 0.000523 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 3.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 450591   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 34       |
|    time_elapsed    | 13468    |
|    total_timesteps | 462186   |
| train/             |          |
|    actor_loss      | -0.0734  |
|    critic_loss     | 0.000463 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 0.231    |
|    learning_rate   | 0.0003   |
|    n_updates       | 452185   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 34       |
|    time_elapsed    | 13484    |
|    total_timesteps | 462689   |
| train/             |          |
|    actor_loss      | -0.122   |
|    critic_loss     | 0.00122  |
|    ent_coef        | 0.000308 |
|    ent_coef_loss   | -3.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 452688   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 34       |
|    time_elapsed    | 13505    |
|    total_timesteps | 463694   |
| train/             |          |
|    actor_loss      | -0.0948  |
|    critic_loss     | 0.00155  |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 0.354    |
|    learning_rate   | 0.0003   |
|    n_updates       | 453693   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 34       |
|    time_elapsed    | 13532    |
|    total_timesteps | 465195   |
| train/             |          |
|    actor_loss      | -0.188   |
|    critic_loss     | 0.00124  |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 0.431    |
|    learning_rate   | 0.0003   |
|    n_updates       | 455194   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 309      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 34       |
|    time_elapsed    | 13546    |
|    total_timesteps | 465700   |
| train/             |          |
|    actor_loss      | -0.125   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | 3.73     |
|    learning_rate   | 0.0003   |
|    n_updates       | 455699   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 34       |
|    time_elapsed    | 13567    |
|    total_timesteps | 466702   |
| train/             |          |
|    actor_loss      | -0.103   |
|    critic_loss     | 0.000752 |
|    ent_coef        | 0.000307 |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 456701   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 34       |
|    time_elapsed    | 13600    |
|    total_timesteps | 467884   |
| train/             |          |
|    actor_loss      | -0.0943  |
|    critic_loss     | 0.000501 |
|    ent_coef        | 0.000306 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 457883   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 34       |
|    time_elapsed    | 13625    |
|    total_timesteps | 468970   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.000622 |
|    ent_coef        | 0.000305 |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 458969   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 304      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 34       |
|    time_elapsed    | 13643    |
|    total_timesteps | 469819   |
| train/             |          |
|    actor_loss      | -0.116   |
|    critic_loss     | 0.000617 |
|    ent_coef        | 0.000315 |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 459818   |
---------------------------------
Eval num_timesteps=470000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -0.157   |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000318 |
|    ent_coef_loss   | -0.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 459999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 34       |
|    time_elapsed    | 13741    |
|    total_timesteps | 470756   |
| train/             |          |
|    actor_loss      | -0.116   |
|    critic_loss     | 0.000515 |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | -0.0462  |
|    learning_rate   | 0.0003   |
|    n_updates       | 460755   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 291      |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 34       |
|    time_elapsed    | 13767    |
|    total_timesteps | 472037   |
| train/             |          |
|    actor_loss      | -0.162   |
|    critic_loss     | 0.00546  |
|    ent_coef        | 0.000315 |
|    ent_coef_loss   | 3.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 462036   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 290      |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 34       |
|    time_elapsed    | 13810    |
|    total_timesteps | 473187   |
| train/             |          |
|    actor_loss      | -0.195   |
|    critic_loss     | 0.000968 |
|    ent_coef        | 0.000317 |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 463186   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 34       |
|    time_elapsed    | 13826    |
|    total_timesteps | 473691   |
| train/             |          |
|    actor_loss      | -0.138   |
|    critic_loss     | 0.000765 |
|    ent_coef        | 0.000312 |
|    ent_coef_loss   | -0.0804  |
|    learning_rate   | 0.0003   |
|    n_updates       | 463690   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 34       |
|    time_elapsed    | 13860    |
|    total_timesteps | 475194   |
| train/             |          |
|    actor_loss      | -0.148   |
|    critic_loss     | 0.000622 |
|    ent_coef        | 0.00033  |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 465193   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 34       |
|    time_elapsed    | 13895    |
|    total_timesteps | 477194   |
| train/             |          |
|    actor_loss      | -0.188   |
|    critic_loss     | 0.00301  |
|    ent_coef        | 0.000322 |
|    ent_coef_loss   | 0.464    |
|    learning_rate   | 0.0003   |
|    n_updates       | 467193   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 34       |
|    time_elapsed    | 13930    |
|    total_timesteps | 479194   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.00106  |
|    ent_coef        | 0.000326 |
|    ent_coef_loss   | 0.793    |
|    learning_rate   | 0.0003   |
|    n_updates       | 469193   |
---------------------------------
Eval num_timesteps=480000, episode_reward=0.30 +/- 0.46
Episode length: 350.70 +/- 228.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 351      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.000626 |
|    ent_coef        | 0.000342 |
|    ent_coef_loss   | -0.931   |
|    learning_rate   | 0.0003   |
|    n_updates       | 469999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 34       |
|    time_elapsed    | 14035    |
|    total_timesteps | 480949   |
| train/             |          |
|    actor_loss      | -0.183   |
|    critic_loss     | 0.000994 |
|    ent_coef        | 0.000338 |
|    ent_coef_loss   | 0.681    |
|    learning_rate   | 0.0003   |
|    n_updates       | 470948   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 34       |
|    time_elapsed    | 14062    |
|    total_timesteps | 482450   |
| train/             |          |
|    actor_loss      | -0.078   |
|    critic_loss     | 0.000799 |
|    ent_coef        | 0.000357 |
|    ent_coef_loss   | -0.242   |
|    learning_rate   | 0.0003   |
|    n_updates       | 472449   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 315      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 34       |
|    time_elapsed    | 14093    |
|    total_timesteps | 483654   |
| train/             |          |
|    actor_loss      | -0.158   |
|    critic_loss     | 0.000578 |
|    ent_coef        | 0.000359 |
|    ent_coef_loss   | -0.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 473653   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 34       |
|    time_elapsed    | 14112    |
|    total_timesteps | 484572   |
| train/             |          |
|    actor_loss      | -0.145   |
|    critic_loss     | 0.000662 |
|    ent_coef        | 0.00038  |
|    ent_coef_loss   | -2.14    |
|    learning_rate   | 0.0003   |
|    n_updates       | 474571   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 34       |
|    time_elapsed    | 14144    |
|    total_timesteps | 486147   |
| train/             |          |
|    actor_loss      | -0.151   |
|    critic_loss     | 0.0017   |
|    ent_coef        | 0.000358 |
|    ent_coef_loss   | 3.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 476146   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 34       |
|    time_elapsed    | 14195    |
|    total_timesteps | 488147   |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 0.000631 |
|    ent_coef        | 0.000354 |
|    ent_coef_loss   | -2.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 478146   |
---------------------------------
Eval num_timesteps=490000, episode_reward=0.80 +/- 0.40
Episode length: 105.60 +/- 197.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 106      |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -0.158   |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | -0.624   |
|    learning_rate   | 0.0003   |
|    n_updates       | 479999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 326      |
|    ep_rew_mean     | 0.41     |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 34       |
|    time_elapsed    | 14284    |
|    total_timesteps | 490147   |
| train/             |          |
|    actor_loss      | -0.243   |
|    critic_loss     | 0.00126  |
|    ent_coef        | 0.000386 |
|    ent_coef_loss   | 3.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 480146   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 34       |
|    time_elapsed    | 14316    |
|    total_timesteps | 491150   |
| train/             |          |
|    actor_loss      | -0.194   |
|    critic_loss     | 0.00152  |
|    ent_coef        | 0.000368 |
|    ent_coef_loss   | -0.357   |
|    learning_rate   | 0.0003   |
|    n_updates       | 481149   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 34       |
|    time_elapsed    | 14332    |
|    total_timesteps | 491735   |
| train/             |          |
|    actor_loss      | -0.168   |
|    critic_loss     | 0.00121  |
|    ent_coef        | 0.000363 |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 481734   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 34       |
|    time_elapsed    | 14366    |
|    total_timesteps | 492739   |
| train/             |          |
|    actor_loss      | -0.118   |
|    critic_loss     | 0.00152  |
|    ent_coef        | 0.000355 |
|    ent_coef_loss   | -3.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 482738   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 34       |
|    time_elapsed    | 14400    |
|    total_timesteps | 494457   |
| train/             |          |
|    actor_loss      | -0.116   |
|    critic_loss     | 0.000847 |
|    ent_coef        | 0.000363 |
|    ent_coef_loss   | -1.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 484456   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 325      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 34       |
|    time_elapsed    | 14431    |
|    total_timesteps | 496177   |
| train/             |          |
|    actor_loss      | -0.231   |
|    critic_loss     | 0.00193  |
|    ent_coef        | 0.000382 |
|    ent_coef_loss   | 0.992    |
|    learning_rate   | 0.0003   |
|    n_updates       | 486176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 318      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 34       |
|    time_elapsed    | 14452    |
|    total_timesteps | 496989   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.000948 |
|    ent_coef        | 0.000374 |
|    ent_coef_loss   | -0.158   |
|    learning_rate   | 0.0003   |
|    n_updates       | 486988   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 34       |
|    time_elapsed    | 14498    |
|    total_timesteps | 498610   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 0.000998 |
|    ent_coef        | 0.000383 |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 488609   |
---------------------------------
Eval num_timesteps=500000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -0.131   |
|    critic_loss     | 0.000978 |
|    ent_coef        | 0.00038  |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 489999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 334      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 34       |
|    time_elapsed    | 14592    |
|    total_timesteps | 500111   |
| train/             |          |
|    actor_loss      | -0.297   |
|    critic_loss     | 0.00157  |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | 3.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 490110   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 0.41     |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 34       |
|    time_elapsed    | 14628    |
|    total_timesteps | 501115   |
| train/             |          |
|    actor_loss      | -0.134   |
|    critic_loss     | 0.00087  |
|    ent_coef        | 0.000383 |
|    ent_coef_loss   | 0.732    |
|    learning_rate   | 0.0003   |
|    n_updates       | 491114   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 0.41     |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 34       |
|    time_elapsed    | 14653    |
|    total_timesteps | 502302   |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 0.000716 |
|    ent_coef        | 0.000396 |
|    ent_coef_loss   | -0.53    |
|    learning_rate   | 0.0003   |
|    n_updates       | 492301   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 0.39     |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 34       |
|    time_elapsed    | 14690    |
|    total_timesteps | 503804   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000412 |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 493803   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 0.38     |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 34       |
|    time_elapsed    | 14720    |
|    total_timesteps | 504807   |
| train/             |          |
|    actor_loss      | -0.225   |
|    critic_loss     | 0.00136  |
|    ent_coef        | 0.000418 |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 494806   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 0.36     |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 34       |
|    time_elapsed    | 14770    |
|    total_timesteps | 506807   |
| train/             |          |
|    actor_loss      | -0.223   |
|    critic_loss     | 0.00207  |
|    ent_coef        | 0.000409 |
|    ent_coef_loss   | -4.83    |
|    learning_rate   | 0.0003   |
|    n_updates       | 496806   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 0.36     |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 34       |
|    time_elapsed    | 14797    |
|    total_timesteps | 507888   |
| train/             |          |
|    actor_loss      | -0.237   |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000416 |
|    ent_coef_loss   | 4.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 497887   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 347      |
|    ep_rew_mean     | 0.36     |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 34       |
|    time_elapsed    | 14816    |
|    total_timesteps | 508427   |
| train/             |          |
|    actor_loss      | -0.154   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000415 |
|    ent_coef_loss   | -0.418   |
|    learning_rate   | 0.0003   |
|    n_updates       | 498426   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 339      |
|    ep_rew_mean     | 0.38     |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 34       |
|    time_elapsed    | 14833    |
|    total_timesteps | 509073   |
| train/             |          |
|    actor_loss      | -0.201   |
|    critic_loss     | 0.000971 |
|    ent_coef        | 0.000428 |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 0.0003   |
|    n_updates       | 499072   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 321      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 34       |
|    time_elapsed    | 14845    |
|    total_timesteps | 509280   |
| train/             |          |
|    actor_loss      | -0.204   |
|    critic_loss     | 0.00167  |
|    ent_coef        | 0.000432 |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 0.0003   |
|    n_updates       | 499279   |
---------------------------------
Eval num_timesteps=510000, episode_reward=0.20 +/- 0.40
Episode length: 402.10 +/- 195.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 402      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -0.174   |
|    critic_loss     | 0.000679 |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | -0.525   |
|    learning_rate   | 0.0003   |
|    n_updates       | 499999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 34       |
|    time_elapsed    | 14945    |
|    total_timesteps | 510845   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 0.00138  |
|    ent_coef        | 0.000451 |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 500844   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 34       |
|    time_elapsed    | 14982    |
|    total_timesteps | 512346   |
| train/             |          |
|    actor_loss      | -0.109   |
|    critic_loss     | 0.000961 |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 0.0003   |
|    n_updates       | 502345   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 34       |
|    time_elapsed    | 15005    |
|    total_timesteps | 513456   |
| train/             |          |
|    actor_loss      | -0.147   |
|    critic_loss     | 0.0012   |
|    ent_coef        | 0.000429 |
|    ent_coef_loss   | 1        |
|    learning_rate   | 0.0003   |
|    n_updates       | 503455   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 34       |
|    time_elapsed    | 15032    |
|    total_timesteps | 514459   |
| train/             |          |
|    actor_loss      | -0.201   |
|    critic_loss     | 0.00197  |
|    ent_coef        | 0.000426 |
|    ent_coef_loss   | -0.506   |
|    learning_rate   | 0.0003   |
|    n_updates       | 504458   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | 0.42     |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 34       |
|    time_elapsed    | 15062    |
|    total_timesteps | 515960   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 0.000802 |
|    ent_coef        | 0.000442 |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 505959   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 34       |
|    time_elapsed    | 15105    |
|    total_timesteps | 517128   |
| train/             |          |
|    actor_loss      | -0.147   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000455 |
|    ent_coef_loss   | 3.89     |
|    learning_rate   | 0.0003   |
|    n_updates       | 507127   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 300      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 34       |
|    time_elapsed    | 15146    |
|    total_timesteps | 518165   |
| train/             |          |
|    actor_loss      | -0.162   |
|    critic_loss     | 0.00328  |
|    ent_coef        | 0.000443 |
|    ent_coef_loss   | -0.319   |
|    learning_rate   | 0.0003   |
|    n_updates       | 508164   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 34       |
|    time_elapsed    | 15175    |
|    total_timesteps | 519711   |
| train/             |          |
|    actor_loss      | -0.175   |
|    critic_loss     | 0.00176  |
|    ent_coef        | 0.00045  |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 509710   |
---------------------------------
Eval num_timesteps=520000, episode_reward=0.50 +/- 0.50
Episode length: 251.30 +/- 248.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -0.0865  |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000452 |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 509999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 34       |
|    time_elapsed    | 15245    |
|    total_timesteps | 521280   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.0346   |
|    ent_coef        | 0.000444 |
|    ent_coef_loss   | 0.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 511279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 0.44     |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 34       |
|    time_elapsed    | 15267    |
|    total_timesteps | 522403   |
| train/             |          |
|    actor_loss      | -0.17    |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.00044  |
|    ent_coef_loss   | 2.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 512402   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 0.45     |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 34       |
|    time_elapsed    | 15288    |
|    total_timesteps | 523363   |
| train/             |          |
|    actor_loss      | -0.181   |
|    critic_loss     | 0.000973 |
|    ent_coef        | 0.000436 |
|    ent_coef_loss   | -0.572   |
|    learning_rate   | 0.0003   |
|    n_updates       | 513362   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 299      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 34       |
|    time_elapsed    | 15310    |
|    total_timesteps | 524367   |
| train/             |          |
|    actor_loss      | -0.169   |
|    critic_loss     | 0.00173  |
|    ent_coef        | 0.00045  |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 0.0003   |
|    n_updates       | 514366   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 0.47     |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 34       |
|    time_elapsed    | 15353    |
|    total_timesteps | 525454   |
| train/             |          |
|    actor_loss      | -0.354   |
|    critic_loss     | 0.00356  |
|    ent_coef        | 0.000464 |
|    ent_coef_loss   | 0.0443   |
|    learning_rate   | 0.0003   |
|    n_updates       | 515453   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 34       |
|    time_elapsed    | 15385    |
|    total_timesteps | 526547   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.00537  |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | -1.82    |
|    learning_rate   | 0.0003   |
|    n_updates       | 516546   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 290      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 34       |
|    time_elapsed    | 15421    |
|    total_timesteps | 527586   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 0.00195  |
|    ent_coef        | 0.00044  |
|    ent_coef_loss   | 1.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 517585   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | 0.47     |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 34       |
|    time_elapsed    | 15450    |
|    total_timesteps | 528652   |
| train/             |          |
|    actor_loss      | -0.222   |
|    critic_loss     | 0.00157  |
|    ent_coef        | 0.000441 |
|    ent_coef_loss   | -0.965   |
|    learning_rate   | 0.0003   |
|    n_updates       | 518651   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | 0.47     |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 34       |
|    time_elapsed    | 15473    |
|    total_timesteps | 529656   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000427 |
|    ent_coef_loss   | 0.453    |
|    learning_rate   | 0.0003   |
|    n_updates       | 519655   |
---------------------------------
Eval num_timesteps=530000, episode_reward=0.30 +/- 0.46
Episode length: 378.20 +/- 199.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -0.168   |
|    critic_loss     | 0.00192  |
|    ent_coef        | 0.000426 |
|    ent_coef_loss   | 0.895    |
|    learning_rate   | 0.0003   |
|    n_updates       | 519999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 0.47     |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 34       |
|    time_elapsed    | 15556    |
|    total_timesteps | 530933   |
| train/             |          |
|    actor_loss      | -0.17    |
|    critic_loss     | 0.00116  |
|    ent_coef        | 0.000455 |
|    ent_coef_loss   | 0.386    |
|    learning_rate   | 0.0003   |
|    n_updates       | 520932   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 34       |
|    time_elapsed    | 15577    |
|    total_timesteps | 531936   |
| train/             |          |
|    actor_loss      | -0.11    |
|    critic_loss     | 0.00146  |
|    ent_coef        | 0.000461 |
|    ent_coef_loss   | -2.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 521935   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 34       |
|    time_elapsed    | 15606    |
|    total_timesteps | 533119   |
| train/             |          |
|    actor_loss      | -0.131   |
|    critic_loss     | 0.0142   |
|    ent_coef        | 0.000453 |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 523118   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 34       |
|    time_elapsed    | 15633    |
|    total_timesteps | 534518   |
| train/             |          |
|    actor_loss      | -0.139   |
|    critic_loss     | 0.0031   |
|    ent_coef        | 0.000481 |
|    ent_coef_loss   | 0.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 524517   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 277      |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 34       |
|    time_elapsed    | 15670    |
|    total_timesteps | 535563   |
| train/             |          |
|    actor_loss      | -0.296   |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.000478 |
|    ent_coef_loss   | -0.661   |
|    learning_rate   | 0.0003   |
|    n_updates       | 525562   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 34       |
|    time_elapsed    | 15697    |
|    total_timesteps | 536566   |
| train/             |          |
|    actor_loss      | -0.208   |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.00047  |
|    ent_coef_loss   | 3.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 526565   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 34       |
|    time_elapsed    | 15723    |
|    total_timesteps | 537246   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.00285  |
|    ent_coef        | 0.000491 |
|    ent_coef_loss   | -4.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 527245   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 34       |
|    time_elapsed    | 15752    |
|    total_timesteps | 538036   |
| train/             |          |
|    actor_loss      | -0.246   |
|    critic_loss     | 0.00302  |
|    ent_coef        | 0.000488 |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 528035   |
---------------------------------
Eval num_timesteps=540000, episode_reward=0.50 +/- 0.50
Episode length: 298.70 +/- 242.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 299      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000509 |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 0.0003   |
|    n_updates       | 529999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 292      |
|    ep_rew_mean     | 0.47     |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 33       |
|    time_elapsed    | 15898    |
|    total_timesteps | 540036   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00253  |
|    ent_coef        | 0.000507 |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 530035   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | 0.48     |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 33       |
|    time_elapsed    | 15932    |
|    total_timesteps | 541039   |
| train/             |          |
|    actor_loss      | -0.209   |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.000507 |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 531038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 34       |
|    time_elapsed    | 15969    |
|    total_timesteps | 543039   |
| train/             |          |
|    actor_loss      | -0.223   |
|    critic_loss     | 0.011    |
|    ent_coef        | 0.000509 |
|    ent_coef_loss   | -0.128   |
|    learning_rate   | 0.0003   |
|    n_updates       | 533038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 301      |
|    ep_rew_mean     | 0.46     |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 34       |
|    time_elapsed    | 16003    |
|    total_timesteps | 544586   |
| train/             |          |
|    actor_loss      | -0.256   |
|    critic_loss     | 0.0015   |
|    ent_coef        | 0.000504 |
|    ent_coef_loss   | 4.63     |
|    learning_rate   | 0.0003   |
|    n_updates       | 534585   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 34       |
|    time_elapsed    | 16014    |
|    total_timesteps | 544663   |
| train/             |          |
|    actor_loss      | -0.18    |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000511 |
|    ent_coef_loss   | -0.683   |
|    learning_rate   | 0.0003   |
|    n_updates       | 534662   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 34       |
|    time_elapsed    | 16039    |
|    total_timesteps | 546042   |
| train/             |          |
|    actor_loss      | -0.174   |
|    critic_loss     | 0.00251  |
|    ent_coef        | 0.000523 |
|    ent_coef_loss   | -0.554   |
|    learning_rate   | 0.0003   |
|    n_updates       | 536041   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 292      |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 34       |
|    time_elapsed    | 16067    |
|    total_timesteps | 547336   |
| train/             |          |
|    actor_loss      | -0.261   |
|    critic_loss     | 0.00362  |
|    ent_coef        | 0.000525 |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 537335   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | 0.51     |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 34       |
|    time_elapsed    | 16085    |
|    total_timesteps | 547942   |
| train/             |          |
|    actor_loss      | -0.126   |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.00052  |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 537941   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 0.52     |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 34       |
|    time_elapsed    | 16109    |
|    total_timesteps | 549044   |
| train/             |          |
|    actor_loss      | -0.214   |
|    critic_loss     | 0.00166  |
|    ent_coef        | 0.000521 |
|    ent_coef_loss   | -0.357   |
|    learning_rate   | 0.0003   |
|    n_updates       | 539043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 34       |
|    time_elapsed    | 16119    |
|    total_timesteps | 549321   |
| train/             |          |
|    actor_loss      | -0.29    |
|    critic_loss     | 0.00466  |
|    ent_coef        | 0.000518 |
|    ent_coef_loss   | -0.632   |
|    learning_rate   | 0.0003   |
|    n_updates       | 539320   |
---------------------------------
Eval num_timesteps=550000, episode_reward=0.20 +/- 0.40
Episode length: 400.20 +/- 199.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 0.00182  |
|    ent_coef        | 0.000508 |
|    ent_coef_loss   | 0.026    |
|    learning_rate   | 0.0003   |
|    n_updates       | 539999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 33       |
|    time_elapsed    | 16213    |
|    total_timesteps | 550324   |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 0.00194  |
|    ent_coef        | 0.000517 |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 0.0003   |
|    n_updates       | 540323   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 33       |
|    time_elapsed    | 16227    |
|    total_timesteps | 550860   |
| train/             |          |
|    actor_loss      | -0.264   |
|    critic_loss     | 0.00139  |
|    ent_coef        | 0.000524 |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 0.0003   |
|    n_updates       | 540859   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 33       |
|    time_elapsed    | 16249    |
|    total_timesteps | 551141   |
| train/             |          |
|    actor_loss      | -0.262   |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.000529 |
|    ent_coef_loss   | 3.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 541140   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 33       |
|    time_elapsed    | 16295    |
|    total_timesteps | 552642   |
| train/             |          |
|    actor_loss      | -0.148   |
|    critic_loss     | 0.00118  |
|    ent_coef        | 0.000504 |
|    ent_coef_loss   | 0.171    |
|    learning_rate   | 0.0003   |
|    n_updates       | 542641   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 33       |
|    time_elapsed    | 16326    |
|    total_timesteps | 553703   |
| train/             |          |
|    actor_loss      | -0.13    |
|    critic_loss     | 0.00147  |
|    ent_coef        | 0.000508 |
|    ent_coef_loss   | 3.57     |
|    learning_rate   | 0.0003   |
|    n_updates       | 543702   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 33       |
|    time_elapsed    | 16367    |
|    total_timesteps | 555703   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.00129  |
|    ent_coef        | 0.000517 |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 0.0003   |
|    n_updates       | 545702   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 0.52     |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 33       |
|    time_elapsed    | 16410    |
|    total_timesteps | 557266   |
| train/             |          |
|    actor_loss      | -0.136   |
|    critic_loss     | 0.00263  |
|    ent_coef        | 0.000507 |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 547265   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 268      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 33       |
|    time_elapsed    | 16428    |
|    total_timesteps | 557770   |
| train/             |          |
|    actor_loss      | -0.172   |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000524 |
|    ent_coef_loss   | -2.25    |
|    learning_rate   | 0.0003   |
|    n_updates       | 547769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 274      |
|    ep_rew_mean     | 0.52     |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 33       |
|    time_elapsed    | 16460    |
|    total_timesteps | 559347   |
| train/             |          |
|    actor_loss      | -0.102   |
|    critic_loss     | 0.00177  |
|    ent_coef        | 0.000505 |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 0.0003   |
|    n_updates       | 549346   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 268      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 33       |
|    time_elapsed    | 16475    |
|    total_timesteps | 559962   |
| train/             |          |
|    actor_loss      | -0.223   |
|    critic_loss     | 0.00448  |
|    ent_coef        | 0.000506 |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 0.0003   |
|    n_updates       | 549961   |
---------------------------------
Eval num_timesteps=560000, episode_reward=0.20 +/- 0.40
Episode length: 400.50 +/- 199.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -0.107   |
|    critic_loss     | 0.0014   |
|    ent_coef        | 0.000507 |
|    ent_coef_loss   | 0.746    |
|    learning_rate   | 0.0003   |
|    n_updates       | 549999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 33       |
|    time_elapsed    | 16549    |
|    total_timesteps | 561096   |
| train/             |          |
|    actor_loss      | -0.0944  |
|    critic_loss     | 0.00291  |
|    ent_coef        | 0.000537 |
|    ent_coef_loss   | 0.615    |
|    learning_rate   | 0.0003   |
|    n_updates       | 551095   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 33       |
|    time_elapsed    | 16578    |
|    total_timesteps | 562210   |
| train/             |          |
|    actor_loss      | -0.127   |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000529 |
|    ent_coef_loss   | -2.91    |
|    learning_rate   | 0.0003   |
|    n_updates       | 552209   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 0.53     |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 33       |
|    time_elapsed    | 16609    |
|    total_timesteps | 563213   |
| train/             |          |
|    actor_loss      | -0.0734  |
|    critic_loss     | 0.00154  |
|    ent_coef        | 0.000531 |
|    ent_coef_loss   | -0.617   |
|    learning_rate   | 0.0003   |
|    n_updates       | 553212   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 33       |
|    time_elapsed    | 16636    |
|    total_timesteps | 563741   |
| train/             |          |
|    actor_loss      | -0.194   |
|    critic_loss     | 0.00133  |
|    ent_coef        | 0.000545 |
|    ent_coef_loss   | 3.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 553740   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 33       |
|    time_elapsed    | 16661    |
|    total_timesteps | 564485   |
| train/             |          |
|    actor_loss      | -0.189   |
|    critic_loss     | 0.00187  |
|    ent_coef        | 0.000535 |
|    ent_coef_loss   | 4.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 554484   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 33       |
|    time_elapsed    | 16678    |
|    total_timesteps | 564989   |
| train/             |          |
|    actor_loss      | -0.26    |
|    critic_loss     | 0.00229  |
|    ent_coef        | 0.000536 |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 0.0003   |
|    n_updates       | 554988   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 33       |
|    time_elapsed    | 16731    |
|    total_timesteps | 566044   |
| train/             |          |
|    actor_loss      | -0.195   |
|    critic_loss     | 0.00392  |
|    ent_coef        | 0.000551 |
|    ent_coef_loss   | -1.58    |
|    learning_rate   | 0.0003   |
|    n_updates       | 556043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 33       |
|    time_elapsed    | 16762    |
|    total_timesteps | 567587   |
| train/             |          |
|    actor_loss      | -0.248   |
|    critic_loss     | 0.00238  |
|    ent_coef        | 0.00055  |
|    ent_coef_loss   | 2.09     |
|    learning_rate   | 0.0003   |
|    n_updates       | 557586   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 33       |
|    time_elapsed    | 16801    |
|    total_timesteps | 569587   |
| train/             |          |
|    actor_loss      | -0.319   |
|    critic_loss     | 0.0274   |
|    ent_coef        | 0.000549 |
|    ent_coef_loss   | 4.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 559586   |
---------------------------------
Eval num_timesteps=570000, episode_reward=0.40 +/- 0.49
Episode length: 302.90 +/- 241.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 303      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -0.275   |
|    critic_loss     | 0.00228  |
|    ent_coef        | 0.000562 |
|    ent_coef_loss   | 3.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 559999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 33       |
|    time_elapsed    | 16896    |
|    total_timesteps | 571229   |
| train/             |          |
|    actor_loss      | -0.187   |
|    critic_loss     | 0.00353  |
|    ent_coef        | 0.000554 |
|    ent_coef_loss   | 0.681    |
|    learning_rate   | 0.0003   |
|    n_updates       | 561228   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 252      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 33       |
|    time_elapsed    | 16903    |
|    total_timesteps | 571236   |
| train/             |          |
|    actor_loss      | -0.118   |
|    critic_loss     | 0.00182  |
|    ent_coef        | 0.000554 |
|    ent_coef_loss   | -0.238   |
|    learning_rate   | 0.0003   |
|    n_updates       | 561235   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 33       |
|    time_elapsed    | 16934    |
|    total_timesteps | 571899   |
| train/             |          |
|    actor_loss      | -0.209   |
|    critic_loss     | 0.00207  |
|    ent_coef        | 0.000537 |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 561898   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 253      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 33       |
|    time_elapsed    | 16970    |
|    total_timesteps | 573257   |
| train/             |          |
|    actor_loss      | -0.0824  |
|    critic_loss     | 0.00389  |
|    ent_coef        | 0.000534 |
|    ent_coef_loss   | 0.496    |
|    learning_rate   | 0.0003   |
|    n_updates       | 563256   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 259      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 33       |
|    time_elapsed    | 17004    |
|    total_timesteps | 574973   |
| train/             |          |
|    actor_loss      | -0.124   |
|    critic_loss     | 0.00175  |
|    ent_coef        | 0.000532 |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 564972   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 33       |
|    time_elapsed    | 17035    |
|    total_timesteps | 575653   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.0238   |
|    ent_coef        | 0.000533 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 565652   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 0.55     |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 33       |
|    time_elapsed    | 17066    |
|    total_timesteps | 576655   |
| train/             |          |
|    actor_loss      | -0.101   |
|    critic_loss     | 0.00289  |
|    ent_coef        | 0.000537 |
|    ent_coef_loss   | 1.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 566654   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 33       |
|    time_elapsed    | 17090    |
|    total_timesteps | 577715   |
| train/             |          |
|    actor_loss      | -0.132   |
|    critic_loss     | 0.00162  |
|    ent_coef        | 0.000497 |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 567714   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | 0.52     |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 33       |
|    time_elapsed    | 17119    |
|    total_timesteps | 579248   |
| train/             |          |
|    actor_loss      | -0.112   |
|    critic_loss     | 0.00223  |
|    ent_coef        | 0.000503 |
|    ent_coef_loss   | -2.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 569247   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 33       |
|    time_elapsed    | 17134    |
|    total_timesteps | 579827   |
| train/             |          |
|    actor_loss      | -0.178   |
|    critic_loss     | 0.00172  |
|    ent_coef        | 0.000516 |
|    ent_coef_loss   | 3.46     |
|    learning_rate   | 0.0003   |
|    n_updates       | 569826   |
---------------------------------
Eval num_timesteps=580000, episode_reward=0.20 +/- 0.40
Episode length: 400.20 +/- 199.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -0.164   |
|    critic_loss     | 0.00306  |
|    ent_coef        | 0.000521 |
|    ent_coef_loss   | -0.312   |
|    learning_rate   | 0.0003   |
|    n_updates       | 569999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 270      |
|    ep_rew_mean     | 0.56     |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 33       |
|    time_elapsed    | 17216    |
|    total_timesteps | 580698   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00249  |
|    ent_coef        | 0.00052  |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 570697   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 33       |
|    time_elapsed    | 17240    |
|    total_timesteps | 581792   |
| train/             |          |
|    actor_loss      | -0.261   |
|    critic_loss     | 0.00248  |
|    ent_coef        | 0.000503 |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 0.0003   |
|    n_updates       | 571791   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 33       |
|    time_elapsed    | 17261    |
|    total_timesteps | 582297   |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 0.00276  |
|    ent_coef        | 0.000521 |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 572296   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 33       |
|    time_elapsed    | 17302    |
|    total_timesteps | 583465   |
| train/             |          |
|    actor_loss      | -0.155   |
|    critic_loss     | 0.00252  |
|    ent_coef        | 0.000528 |
|    ent_coef_loss   | 0.215    |
|    learning_rate   | 0.0003   |
|    n_updates       | 573464   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 33       |
|    time_elapsed    | 17326    |
|    total_timesteps | 584697   |
| train/             |          |
|    actor_loss      | -0.142   |
|    critic_loss     | 0.00216  |
|    ent_coef        | 0.00052  |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 574696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 262      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 33       |
|    time_elapsed    | 17362    |
|    total_timesteps | 586199   |
| train/             |          |
|    actor_loss      | -0.233   |
|    critic_loss     | 0.00421  |
|    ent_coef        | 0.000497 |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 0.0003   |
|    n_updates       | 576198   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 262      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 33       |
|    time_elapsed    | 17386    |
|    total_timesteps | 587311   |
| train/             |          |
|    actor_loss      | -0.025   |
|    critic_loss     | 0.0033   |
|    ent_coef        | 0.000487 |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 577310   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 260      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 33       |
|    time_elapsed    | 17406    |
|    total_timesteps | 588160   |
| train/             |          |
|    actor_loss      | -0.121   |
|    critic_loss     | 0.00545  |
|    ent_coef        | 0.000501 |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 578159   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 33       |
|    time_elapsed    | 17447    |
|    total_timesteps | 588996   |
| train/             |          |
|    actor_loss      | -0.0985  |
|    critic_loss     | 0.00178  |
|    ent_coef        | 0.000511 |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 578995   |
---------------------------------
Eval num_timesteps=590000, episode_reward=0.20 +/- 0.40
Episode length: 400.30 +/- 199.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -0.084   |
|    critic_loss     | 0.00171  |
|    ent_coef        | 0.000503 |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 579999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 33       |
|    time_elapsed    | 17538    |
|    total_timesteps | 590060   |
| train/             |          |
|    actor_loss      | -0.278   |
|    critic_loss     | 0.00264  |
|    ent_coef        | 0.000505 |
|    ent_coef_loss   | 2.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 580059   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 271      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 33       |
|    time_elapsed    | 17575    |
|    total_timesteps | 591588   |
| train/             |          |
|    actor_loss      | -0.0613  |
|    critic_loss     | 0.00372  |
|    ent_coef        | 0.000511 |
|    ent_coef_loss   | -3.76    |
|    learning_rate   | 0.0003   |
|    n_updates       | 581587   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 273      |
|    ep_rew_mean     | 0.57     |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 33       |
|    time_elapsed    | 17594    |
|    total_timesteps | 592335   |
| train/             |          |
|    actor_loss      | -0.0917  |
|    critic_loss     | 0.00273  |
|    ent_coef        | 0.000513 |
|    ent_coef_loss   | 2.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 582334   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 272      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 33       |
|    time_elapsed    | 17621    |
|    total_timesteps | 593239   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00255  |
|    ent_coef        | 0.00052  |
|    ent_coef_loss   | 1.82     |
|    learning_rate   | 0.0003   |
|    n_updates       | 583238   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 33       |
|    time_elapsed    | 17657    |
|    total_timesteps | 594241   |
| train/             |          |
|    actor_loss      | -0.191   |
|    critic_loss     | 0.00259  |
|    ent_coef        | 0.000514 |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 0.0003   |
|    n_updates       | 584240   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 33       |
|    time_elapsed    | 17682    |
|    total_timesteps | 595276   |
| train/             |          |
|    actor_loss      | -0.1     |
|    critic_loss     | 0.00216  |
|    ent_coef        | 0.000529 |
|    ent_coef_loss   | -0.699   |
|    learning_rate   | 0.0003   |
|    n_updates       | 585275   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 252      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 33       |
|    time_elapsed    | 17709    |
|    total_timesteps | 596385   |
| train/             |          |
|    actor_loss      | -0.266   |
|    critic_loss     | 0.00181  |
|    ent_coef        | 0.000521 |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 586384   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 259      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 33       |
|    time_elapsed    | 17728    |
|    total_timesteps | 597114   |
| train/             |          |
|    actor_loss      | -0.111   |
|    critic_loss     | 0.00339  |
|    ent_coef        | 0.00053  |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 587113   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 263      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 33       |
|    time_elapsed    | 17750    |
|    total_timesteps | 598156   |
| train/             |          |
|    actor_loss      | -0.0555  |
|    critic_loss     | 0.00215  |
|    ent_coef        | 0.000535 |
|    ent_coef_loss   | 0.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 588155   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 259      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 33       |
|    time_elapsed    | 17771    |
|    total_timesteps | 599174   |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 0.00412  |
|    ent_coef        | 0.000547 |
|    ent_coef_loss   | -2.49    |
|    learning_rate   | 0.0003   |
|    n_updates       | 589173   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 33       |
|    time_elapsed    | 17788    |
|    total_timesteps | 599817   |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 0.00163  |
|    ent_coef        | 0.000541 |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 589816   |
---------------------------------
Eval num_timesteps=600000, episode_reward=0.30 +/- 0.46
Episode length: 356.70 +/- 219.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 357      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -0.137   |
|    critic_loss     | 0.00254  |
|    ent_coef        | 0.000551 |
|    ent_coef_loss   | 2.47     |
|    learning_rate   | 0.0003   |
|    n_updates       | 589999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 252      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 33       |
|    time_elapsed    | 17872    |
|    total_timesteps | 600820   |
| train/             |          |
|    actor_loss      | -0.152   |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.000544 |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 590819   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 33       |
|    time_elapsed    | 17893    |
|    total_timesteps | 600861   |
| train/             |          |
|    actor_loss      | -0.0674  |
|    critic_loss     | 0.00256  |
|    ent_coef        | 0.000545 |
|    ent_coef_loss   | 0.636    |
|    learning_rate   | 0.0003   |
|    n_updates       | 590860   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 33       |
|    time_elapsed    | 17923    |
|    total_timesteps | 602484   |
| train/             |          |
|    actor_loss      | -0.215   |
|    critic_loss     | 0.00169  |
|    ent_coef        | 0.00057  |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 592483   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 33       |
|    time_elapsed    | 17946    |
|    total_timesteps | 603531   |
| train/             |          |
|    actor_loss      | -0.211   |
|    critic_loss     | 0.00527  |
|    ent_coef        | 0.000557 |
|    ent_coef_loss   | 0.837    |
|    learning_rate   | 0.0003   |
|    n_updates       | 593530   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 33       |
|    time_elapsed    | 17973    |
|    total_timesteps | 604196   |
| train/             |          |
|    actor_loss      | -0.228   |
|    critic_loss     | 0.00595  |
|    ent_coef        | 0.00055  |
|    ent_coef_loss   | 3.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 594195   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 33       |
|    time_elapsed    | 18015    |
|    total_timesteps | 605417   |
| train/             |          |
|    actor_loss      | -0.107   |
|    critic_loss     | 0.00231  |
|    ent_coef        | 0.000555 |
|    ent_coef_loss   | 0.824    |
|    learning_rate   | 0.0003   |
|    n_updates       | 595416   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 33       |
|    time_elapsed    | 18045    |
|    total_timesteps | 606656   |
| train/             |          |
|    actor_loss      | -0.207   |
|    critic_loss     | 0.00196  |
|    ent_coef        | 0.00056  |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 596655   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 33       |
|    time_elapsed    | 18076    |
|    total_timesteps | 607690   |
| train/             |          |
|    actor_loss      | -0.209   |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.000532 |
|    ent_coef_loss   | 2.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 597689   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 33       |
|    time_elapsed    | 18098    |
|    total_timesteps | 608251   |
| train/             |          |
|    actor_loss      | -0.0795  |
|    critic_loss     | 0.00455  |
|    ent_coef        | 0.000536 |
|    ent_coef_loss   | -0.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 598250   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 0.59     |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 33       |
|    time_elapsed    | 18124    |
|    total_timesteps | 609407   |
| train/             |          |
|    actor_loss      | -0.187   |
|    critic_loss     | 0.0126   |
|    ent_coef        | 0.0005   |
|    ent_coef_loss   | -0.811   |
|    learning_rate   | 0.0003   |
|    n_updates       | 599406   |
---------------------------------
Eval num_timesteps=610000, episode_reward=0.30 +/- 0.46
Episode length: 353.60 +/- 223.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 354      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -0.18    |
|    critic_loss     | 0.00349  |
|    ent_coef        | 0.000506 |
|    ent_coef_loss   | 6.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 599999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 33       |
|    time_elapsed    | 18241    |
|    total_timesteps | 610411   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 0.00233  |
|    ent_coef        | 0.000515 |
|    ent_coef_loss   | -2.91    |
|    learning_rate   | 0.0003   |
|    n_updates       | 600410   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 33       |
|    time_elapsed    | 18259    |
|    total_timesteps | 611218   |
| train/             |          |
|    actor_loss      | -0.133   |
|    critic_loss     | 0.00147  |
|    ent_coef        | 0.000501 |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 601217   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 33       |
|    time_elapsed    | 18266    |
|    total_timesteps | 611294   |
| train/             |          |
|    actor_loss      | -0.0836  |
|    critic_loss     | 0.00322  |
|    ent_coef        | 0.000498 |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 601293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 33       |
|    time_elapsed    | 18286    |
|    total_timesteps | 611847   |
| train/             |          |
|    actor_loss      | -0.0473  |
|    critic_loss     | 0.0013   |
|    ent_coef        | 0.0005   |
|    ent_coef_loss   | 0.696    |
|    learning_rate   | 0.0003   |
|    n_updates       | 601846   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 33       |
|    time_elapsed    | 18303    |
|    total_timesteps | 612410   |
| train/             |          |
|    actor_loss      | -0.117   |
|    critic_loss     | 0.00707  |
|    ent_coef        | 0.000484 |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 602409   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 33       |
|    time_elapsed    | 18316    |
|    total_timesteps | 612728   |
| train/             |          |
|    actor_loss      | -0.159   |
|    critic_loss     | 0.00181  |
|    ent_coef        | 0.000478 |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 602727   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 33       |
|    time_elapsed    | 18333    |
|    total_timesteps | 613386   |
| train/             |          |
|    actor_loss      | -0.187   |
|    critic_loss     | 0.00225  |
|    ent_coef        | 0.000488 |
|    ent_coef_loss   | 0.248    |
|    learning_rate   | 0.0003   |
|    n_updates       | 603385   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 213      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 33       |
|    time_elapsed    | 18367    |
|    total_timesteps | 614508   |
| train/             |          |
|    actor_loss      | -0.113   |
|    critic_loss     | 0.00207  |
|    ent_coef        | 0.000478 |
|    ent_coef_loss   | -0.281   |
|    learning_rate   | 0.0003   |
|    n_updates       | 604507   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 33       |
|    time_elapsed    | 18409    |
|    total_timesteps | 615679   |
| train/             |          |
|    actor_loss      | -0.0716  |
|    critic_loss     | 0.00113  |
|    ent_coef        | 0.000493 |
|    ent_coef_loss   | -3.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 605678   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 33       |
|    time_elapsed    | 18444    |
|    total_timesteps | 616233   |
| train/             |          |
|    actor_loss      | -0.108   |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.000467 |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 606232   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 213      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 33       |
|    time_elapsed    | 18474    |
|    total_timesteps | 617734   |
| train/             |          |
|    actor_loss      | -0.073   |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.000474 |
|    ent_coef_loss   | 1.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 607733   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 33       |
|    time_elapsed    | 18501    |
|    total_timesteps | 618291   |
| train/             |          |
|    actor_loss      | -0.0156  |
|    critic_loss     | 0.00175  |
|    ent_coef        | 0.000466 |
|    ent_coef_loss   | -1.44    |
|    learning_rate   | 0.0003   |
|    n_updates       | 608290   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 33       |
|    time_elapsed    | 18526    |
|    total_timesteps | 619355   |
| train/             |          |
|    actor_loss      | -0.08    |
|    critic_loss     | 0.00314  |
|    ent_coef        | 0.00045  |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 609354   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 33       |
|    time_elapsed    | 18547    |
|    total_timesteps | 619728   |
| train/             |          |
|    actor_loss      | -0.13    |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000461 |
|    ent_coef_loss   | 3.92     |
|    learning_rate   | 0.0003   |
|    n_updates       | 609727   |
---------------------------------
Eval num_timesteps=620000, episode_reward=0.30 +/- 0.46
Episode length: 361.20 +/- 212.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 361      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -0.0395  |
|    critic_loss     | 0.00287  |
|    ent_coef        | 0.000463 |
|    ent_coef_loss   | -4.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 609999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 33       |
|    time_elapsed    | 18638    |
|    total_timesteps | 620362   |
| train/             |          |
|    actor_loss      | -0.162   |
|    critic_loss     | 0.00129  |
|    ent_coef        | 0.00047  |
|    ent_coef_loss   | 0.482    |
|    learning_rate   | 0.0003   |
|    n_updates       | 610361   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 33       |
|    time_elapsed    | 18661    |
|    total_timesteps | 621420   |
| train/             |          |
|    actor_loss      | -0.0276  |
|    critic_loss     | 0.00142  |
|    ent_coef        | 0.000446 |
|    ent_coef_loss   | 0.985    |
|    learning_rate   | 0.0003   |
|    n_updates       | 611419   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 33       |
|    time_elapsed    | 18686    |
|    total_timesteps | 622107   |
| train/             |          |
|    actor_loss      | -0.19    |
|    critic_loss     | 0.00195  |
|    ent_coef        | 0.000459 |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 612106   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 33       |
|    time_elapsed    | 18712    |
|    total_timesteps | 623167   |
| train/             |          |
|    actor_loss      | -0.0612  |
|    critic_loss     | 0.00144  |
|    ent_coef        | 0.000447 |
|    ent_coef_loss   | -0.0803  |
|    learning_rate   | 0.0003   |
|    n_updates       | 613166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 33       |
|    time_elapsed    | 18751    |
|    total_timesteps | 623928   |
| train/             |          |
|    actor_loss      | -0.0201  |
|    critic_loss     | 0.00166  |
|    ent_coef        | 0.000455 |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 613927   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 33       |
|    time_elapsed    | 18765    |
|    total_timesteps | 624432   |
| train/             |          |
|    actor_loss      | -0.025   |
|    critic_loss     | 0.00126  |
|    ent_coef        | 0.00045  |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 0.0003   |
|    n_updates       | 614431   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 33       |
|    time_elapsed    | 18777    |
|    total_timesteps | 624495   |
| train/             |          |
|    actor_loss      | -0.143   |
|    critic_loss     | 0.00226  |
|    ent_coef        | 0.000449 |
|    ent_coef_loss   | 0.526    |
|    learning_rate   | 0.0003   |
|    n_updates       | 614494   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 33       |
|    time_elapsed    | 18794    |
|    total_timesteps | 625096   |
| train/             |          |
|    actor_loss      | -0.0336  |
|    critic_loss     | 0.00136  |
|    ent_coef        | 0.000436 |
|    ent_coef_loss   | -3.67    |
|    learning_rate   | 0.0003   |
|    n_updates       | 615095   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 33       |
|    time_elapsed    | 18829    |
|    total_timesteps | 626666   |
| train/             |          |
|    actor_loss      | -0.0177  |
|    critic_loss     | 0.00119  |
|    ent_coef        | 0.000432 |
|    ent_coef_loss   | -3.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 616665   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 33       |
|    time_elapsed    | 18859    |
|    total_timesteps | 627769   |
| train/             |          |
|    actor_loss      | -0.0719  |
|    critic_loss     | 0.0022   |
|    ent_coef        | 0.000434 |
|    ent_coef_loss   | 3.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 617768   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 33       |
|    time_elapsed    | 18884    |
|    total_timesteps | 628857   |
| train/             |          |
|    actor_loss      | -0.0219  |
|    critic_loss     | 0.00198  |
|    ent_coef        | 0.000429 |
|    ent_coef_loss   | 0.0353   |
|    learning_rate   | 0.0003   |
|    n_updates       | 618856   |
---------------------------------
Eval num_timesteps=630000, episode_reward=0.20 +/- 0.40
Episode length: 407.70 +/- 184.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | 0.2      |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -0.0235  |
|    critic_loss     | 0.00135  |
|    ent_coef        | 0.000422 |
|    ent_coef_loss   | 0.703    |
|    learning_rate   | 0.0003   |
|    n_updates       | 619999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 33       |
|    time_elapsed    | 18986    |
|    total_timesteps | 630397   |
| train/             |          |
|    actor_loss      | -0.165   |
|    critic_loss     | 0.00258  |
|    ent_coef        | 0.00042  |
|    ent_coef_loss   | 3.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 620396   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 33       |
|    time_elapsed    | 19005    |
|    total_timesteps | 631106   |
| train/             |          |
|    actor_loss      | -0.0728  |
|    critic_loss     | 0.00131  |
|    ent_coef        | 0.000437 |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 621105   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 33       |
|    time_elapsed    | 19031    |
|    total_timesteps | 632148   |
| train/             |          |
|    actor_loss      | -0.0593  |
|    critic_loss     | 0.000978 |
|    ent_coef        | 0.000404 |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 0.0003   |
|    n_updates       | 622147   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 33       |
|    time_elapsed    | 19100    |
|    total_timesteps | 634148   |
| train/             |          |
|    actor_loss      | -0.0934  |
|    critic_loss     | 0.00112  |
|    ent_coef        | 0.000417 |
|    ent_coef_loss   | 0.407    |
|    learning_rate   | 0.0003   |
|    n_updates       | 624147   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 33       |
|    time_elapsed    | 19116    |
|    total_timesteps | 634673   |
| train/             |          |
|    actor_loss      | -0.0507  |
|    critic_loss     | 0.00135  |
|    ent_coef        | 0.000424 |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 624672   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 33       |
|    time_elapsed    | 19139    |
|    total_timesteps | 635496   |
| train/             |          |
|    actor_loss      | -0.0222  |
|    critic_loss     | 0.00103  |
|    ent_coef        | 0.000407 |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 625495   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 33       |
|    time_elapsed    | 19153    |
|    total_timesteps | 635703   |
| train/             |          |
|    actor_loss      | -0.0236  |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000406 |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 0.0003   |
|    n_updates       | 625702   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 33       |
|    time_elapsed    | 19164    |
|    total_timesteps | 635738   |
| train/             |          |
|    actor_loss      | -0.00224 |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000405 |
|    ent_coef_loss   | -0.0446  |
|    learning_rate   | 0.0003   |
|    n_updates       | 625737   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 33       |
|    time_elapsed    | 19187    |
|    total_timesteps | 636887   |
| train/             |          |
|    actor_loss      | -0.0577  |
|    critic_loss     | 0.000745 |
|    ent_coef        | 0.000416 |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 626886   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 33       |
|    time_elapsed    | 19200    |
|    total_timesteps | 637483   |
| train/             |          |
|    actor_loss      | -0.0608  |
|    critic_loss     | 0.00168  |
|    ent_coef        | 0.00041  |
|    ent_coef_loss   | 3.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 627482   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 33       |
|    time_elapsed    | 19221    |
|    total_timesteps | 638120   |
| train/             |          |
|    actor_loss      | -0.0772  |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.000429 |
|    ent_coef_loss   | -0.273   |
|    learning_rate   | 0.0003   |
|    n_updates       | 628119   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 33       |
|    time_elapsed    | 19231    |
|    total_timesteps | 638387   |
| train/             |          |
|    actor_loss      | -0.0919  |
|    critic_loss     | 0.00885  |
|    ent_coef        | 0.000424 |
|    ent_coef_loss   | 0.982    |
|    learning_rate   | 0.0003   |
|    n_updates       | 628386   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 33       |
|    time_elapsed    | 19266    |
|    total_timesteps | 639944   |
| train/             |          |
|    actor_loss      | -0.0133  |
|    critic_loss     | 0.000953 |
|    ent_coef        | 0.000426 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 629943   |
---------------------------------
Eval num_timesteps=640000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | 0.0163   |
|    critic_loss     | 0.000833 |
|    ent_coef        | 0.000425 |
|    ent_coef_loss   | -0.202   |
|    learning_rate   | 0.0003   |
|    n_updates       | 629999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 33       |
|    time_elapsed    | 19329    |
|    total_timesteps | 640011   |
| train/             |          |
|    actor_loss      | -0.0282  |
|    critic_loss     | 0.00166  |
|    ent_coef        | 0.000425 |
|    ent_coef_loss   | -0.433   |
|    learning_rate   | 0.0003   |
|    n_updates       | 630010   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 33       |
|    time_elapsed    | 19364    |
|    total_timesteps | 641063   |
| train/             |          |
|    actor_loss      | -0.0284  |
|    critic_loss     | 0.00167  |
|    ent_coef        | 0.000426 |
|    ent_coef_loss   | 0.787    |
|    learning_rate   | 0.0003   |
|    n_updates       | 631062   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 33       |
|    time_elapsed    | 19394    |
|    total_timesteps | 641874   |
| train/             |          |
|    actor_loss      | 0.00346  |
|    critic_loss     | 0.00111  |
|    ent_coef        | 0.000429 |
|    ent_coef_loss   | -0.519   |
|    learning_rate   | 0.0003   |
|    n_updates       | 631873   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 33       |
|    time_elapsed    | 19433    |
|    total_timesteps | 642419   |
| train/             |          |
|    actor_loss      | 0.00589  |
|    critic_loss     | 0.00254  |
|    ent_coef        | 0.000438 |
|    ent_coef_loss   | -0.112   |
|    learning_rate   | 0.0003   |
|    n_updates       | 632418   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 33       |
|    time_elapsed    | 19452    |
|    total_timesteps | 643001   |
| train/             |          |
|    actor_loss      | -0.0454  |
|    critic_loss     | 0.0105   |
|    ent_coef        | 0.000429 |
|    ent_coef_loss   | -1.12    |
|    learning_rate   | 0.0003   |
|    n_updates       | 633000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 33       |
|    time_elapsed    | 19474    |
|    total_timesteps | 643634   |
| train/             |          |
|    actor_loss      | -0.0507  |
|    critic_loss     | 0.00125  |
|    ent_coef        | 0.000425 |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 633633   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 33       |
|    time_elapsed    | 19513    |
|    total_timesteps | 644862   |
| train/             |          |
|    actor_loss      | -0.00551 |
|    critic_loss     | 0.000915 |
|    ent_coef        | 0.000433 |
|    ent_coef_loss   | -0.585   |
|    learning_rate   | 0.0003   |
|    n_updates       | 634861   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 33       |
|    time_elapsed    | 19541    |
|    total_timesteps | 646419   |
| train/             |          |
|    actor_loss      | 0.0106   |
|    critic_loss     | 0.00203  |
|    ent_coef        | 0.000419 |
|    ent_coef_loss   | 2.81     |
|    learning_rate   | 0.0003   |
|    n_updates       | 636418   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 33       |
|    time_elapsed    | 19565    |
|    total_timesteps | 646970   |
| train/             |          |
|    actor_loss      | -0.0283  |
|    critic_loss     | 0.00098  |
|    ent_coef        | 0.000434 |
|    ent_coef_loss   | 0.158    |
|    learning_rate   | 0.0003   |
|    n_updates       | 636969   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 33       |
|    time_elapsed    | 19582    |
|    total_timesteps | 647620   |
| train/             |          |
|    actor_loss      | -0.0211  |
|    critic_loss     | 0.000976 |
|    ent_coef        | 0.000437 |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 637619   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 33       |
|    time_elapsed    | 19602    |
|    total_timesteps | 648624   |
| train/             |          |
|    actor_loss      | -0.0485  |
|    critic_loss     | 0.00113  |
|    ent_coef        | 0.000434 |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 638623   |
---------------------------------
Eval num_timesteps=650000, episode_reward=0.40 +/- 0.49
Episode length: 308.00 +/- 235.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 308      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -0.0598  |
|    critic_loss     | 0.00175  |
|    ent_coef        | 0.000428 |
|    ent_coef_loss   | 2.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 639999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 33       |
|    time_elapsed    | 19694    |
|    total_timesteps | 650222   |
| train/             |          |
|    actor_loss      | -0.0691  |
|    critic_loss     | 0.00174  |
|    ent_coef        | 0.000425 |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 640221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 33       |
|    time_elapsed    | 19718    |
|    total_timesteps | 651350   |
| train/             |          |
|    actor_loss      | -0.0252  |
|    critic_loss     | 0.000949 |
|    ent_coef        | 0.00044  |
|    ent_coef_loss   | 0.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 641349   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 33       |
|    time_elapsed    | 19750    |
|    total_timesteps | 652767   |
| train/             |          |
|    actor_loss      | -0.0499  |
|    critic_loss     | 0.00748  |
|    ent_coef        | 0.000414 |
|    ent_coef_loss   | 0.701    |
|    learning_rate   | 0.0003   |
|    n_updates       | 642766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 33       |
|    time_elapsed    | 19794    |
|    total_timesteps | 654767   |
| train/             |          |
|    actor_loss      | -0.0299  |
|    critic_loss     | 0.0021   |
|    ent_coef        | 0.000412 |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 0.0003   |
|    n_updates       | 644766   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 220       |
|    ep_rew_mean     | 0.64      |
| time/              |           |
|    episodes        | 1960      |
|    fps             | 33        |
|    time_elapsed    | 19821     |
|    total_timesteps | 656193    |
| train/             |           |
|    actor_loss      | -0.000637 |
|    critic_loss     | 0.00123   |
|    ent_coef        | 0.00041   |
|    ent_coef_loss   | -0.101    |
|    learning_rate   | 0.0003    |
|    n_updates       | 646192    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 33       |
|    time_elapsed    | 19848    |
|    total_timesteps | 656854   |
| train/             |          |
|    actor_loss      | -0.0811  |
|    critic_loss     | 0.00121  |
|    ent_coef        | 0.000411 |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 646853   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 33       |
|    time_elapsed    | 19887    |
|    total_timesteps | 658356   |
| train/             |          |
|    actor_loss      | -0.00431 |
|    critic_loss     | 0.00109  |
|    ent_coef        | 0.0004   |
|    ent_coef_loss   | -0.527   |
|    learning_rate   | 0.0003   |
|    n_updates       | 648355   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 33       |
|    time_elapsed    | 19913    |
|    total_timesteps | 659719   |
| train/             |          |
|    actor_loss      | -0.0248  |
|    critic_loss     | 0.0014   |
|    ent_coef        | 0.000374 |
|    ent_coef_loss   | 0.381    |
|    learning_rate   | 0.0003   |
|    n_updates       | 649718   |
---------------------------------
Eval num_timesteps=660000, episode_reward=0.50 +/- 0.50
Episode length: 263.00 +/- 237.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 263      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | 0.00363  |
|    critic_loss     | 0.000996 |
|    ent_coef        | 0.000386 |
|    ent_coef_loss   | 0.72     |
|    learning_rate   | 0.0003   |
|    n_updates       | 649999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 0.58     |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 33       |
|    time_elapsed    | 20013    |
|    total_timesteps | 660722   |
| train/             |          |
|    actor_loss      | -0.0137  |
|    critic_loss     | 0.00128  |
|    ent_coef        | 0.000366 |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 650721   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 32       |
|    time_elapsed    | 20028    |
|    total_timesteps | 660934   |
| train/             |          |
|    actor_loss      | -0.0395  |
|    critic_loss     | 0.00198  |
|    ent_coef        | 0.000362 |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 650933   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 32       |
|    time_elapsed    | 20044    |
|    total_timesteps | 661457   |
| train/             |          |
|    actor_loss      | -0.0607  |
|    critic_loss     | 0.00146  |
|    ent_coef        | 0.000362 |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 651456   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 32       |
|    time_elapsed    | 20060    |
|    total_timesteps | 661870   |
| train/             |          |
|    actor_loss      | 0.0192   |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000359 |
|    ent_coef_loss   | 1.3      |
|    learning_rate   | 0.0003   |
|    n_updates       | 651869   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 32       |
|    time_elapsed    | 20098    |
|    total_timesteps | 662798   |
| train/             |          |
|    actor_loss      | -0.012   |
|    critic_loss     | 0.000634 |
|    ent_coef        | 0.000384 |
|    ent_coef_loss   | -1.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 652797   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 230       |
|    ep_rew_mean     | 0.64      |
| time/              |           |
|    episodes        | 1996      |
|    fps             | 32        |
|    time_elapsed    | 20106     |
|    total_timesteps | 662902    |
| train/             |           |
|    actor_loss      | -0.000516 |
|    critic_loss     | 0.000961  |
|    ent_coef        | 0.000386  |
|    ent_coef_loss   | -2.88     |
|    learning_rate   | 0.0003    |
|    n_updates       | 652901    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 32       |
|    time_elapsed    | 20138    |
|    total_timesteps | 663944   |
| train/             |          |
|    actor_loss      | -0.0591  |
|    critic_loss     | 0.00107  |
|    ent_coef        | 0.00036  |
|    ent_coef_loss   | -0.677   |
|    learning_rate   | 0.0003   |
|    n_updates       | 653943   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 32       |
|    time_elapsed    | 20161    |
|    total_timesteps | 665048   |
| train/             |          |
|    actor_loss      | 0.0157   |
|    critic_loss     | 0.000602 |
|    ent_coef        | 0.000337 |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 655047   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 232      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 32       |
|    time_elapsed    | 20169    |
|    total_timesteps | 665095   |
| train/             |          |
|    actor_loss      | -0.0305  |
|    critic_loss     | 0.000665 |
|    ent_coef        | 0.000337 |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 655094   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 32       |
|    time_elapsed    | 20186    |
|    total_timesteps | 665740   |
| train/             |          |
|    actor_loss      | -0.0483  |
|    critic_loss     | 0.000674 |
|    ent_coef        | 0.000344 |
|    ent_coef_loss   | 0.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 655739   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 32       |
|    time_elapsed    | 20201    |
|    total_timesteps | 666314   |
| train/             |          |
|    actor_loss      | -0.0516  |
|    critic_loss     | 0.000703 |
|    ent_coef        | 0.000352 |
|    ent_coef_loss   | -2.9     |
|    learning_rate   | 0.0003   |
|    n_updates       | 656313   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 33       |
|    time_elapsed    | 20226    |
|    total_timesteps | 667510   |
| train/             |          |
|    actor_loss      | -0.0514  |
|    critic_loss     | 0.000987 |
|    ent_coef        | 0.000364 |
|    ent_coef_loss   | 4.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 657509   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 33       |
|    time_elapsed    | 20256    |
|    total_timesteps | 668557   |
| train/             |          |
|    actor_loss      | -0.00577 |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000356 |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 658556   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 33       |
|    time_elapsed    | 20294    |
|    total_timesteps | 669784   |
| train/             |          |
|    actor_loss      | -0.0386  |
|    critic_loss     | 0.00897  |
|    ent_coef        | 0.000357 |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 659783   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 229       |
|    ep_rew_mean     | 0.65      |
| time/              |           |
|    episodes        | 2032      |
|    fps             | 32        |
|    time_elapsed    | 20303     |
|    total_timesteps | 669870    |
| train/             |           |
|    actor_loss      | -0.000475 |
|    critic_loss     | 0.00131   |
|    ent_coef        | 0.000353  |
|    ent_coef_loss   | 0.00453   |
|    learning_rate   | 0.0003    |
|    n_updates       | 659869    |
----------------------------------
Eval num_timesteps=670000, episode_reward=0.30 +/- 0.46
Episode length: 355.80 +/- 220.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 356      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -0.0541  |
|    critic_loss     | 0.00189  |
|    ent_coef        | 0.000352 |
|    ent_coef_loss   | 3.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 659999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 230      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2036     |
|    fps             | 32       |
|    time_elapsed    | 20379    |
|    total_timesteps | 670575   |
| train/             |          |
|    actor_loss      | -0.034   |
|    critic_loss     | 0.00141  |
|    ent_coef        | 0.000352 |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 660574   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2040     |
|    fps             | 32       |
|    time_elapsed    | 20400    |
|    total_timesteps | 671392   |
| train/             |          |
|    actor_loss      | 0.0131   |
|    critic_loss     | 0.00226  |
|    ent_coef        | 0.000351 |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 661391   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2044     |
|    fps             | 32       |
|    time_elapsed    | 20420    |
|    total_timesteps | 672348   |
| train/             |          |
|    actor_loss      | -0.00568 |
|    critic_loss     | 0.000685 |
|    ent_coef        | 0.000337 |
|    ent_coef_loss   | 6.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 662347   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 32       |
|    time_elapsed    | 20446    |
|    total_timesteps | 673024   |
| train/             |          |
|    actor_loss      | -0.0306  |
|    critic_loss     | 0.00237  |
|    ent_coef        | 0.000342 |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 0.0003   |
|    n_updates       | 663023   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 32       |
|    time_elapsed    | 20476    |
|    total_timesteps | 674479   |
| train/             |          |
|    actor_loss      | -0.015   |
|    critic_loss     | 0.000755 |
|    ent_coef        | 0.000328 |
|    ent_coef_loss   | 1.43     |
|    learning_rate   | 0.0003   |
|    n_updates       | 664478   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 32       |
|    time_elapsed    | 20494    |
|    total_timesteps | 675149   |
| train/             |          |
|    actor_loss      | -0.0331  |
|    critic_loss     | 0.000685 |
|    ent_coef        | 0.000324 |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 665148   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 32       |
|    time_elapsed    | 20522    |
|    total_timesteps | 675279   |
| train/             |          |
|    actor_loss      | -0.0106  |
|    critic_loss     | 0.00079  |
|    ent_coef        | 0.000331 |
|    ent_coef_loss   | 0.802    |
|    learning_rate   | 0.0003   |
|    n_updates       | 665278   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 32       |
|    time_elapsed    | 20546    |
|    total_timesteps | 676283   |
| train/             |          |
|    actor_loss      | -0.0174  |
|    critic_loss     | 0.0025   |
|    ent_coef        | 0.00033  |
|    ent_coef_loss   | -0.732   |
|    learning_rate   | 0.0003   |
|    n_updates       | 666282   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 32       |
|    time_elapsed    | 20591    |
|    total_timesteps | 677375   |
| train/             |          |
|    actor_loss      | -0.0101  |
|    critic_loss     | 0.000684 |
|    ent_coef        | 0.000308 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 667374   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2072     |
|    fps             | 32       |
|    time_elapsed    | 20599    |
|    total_timesteps | 677499   |
| train/             |          |
|    actor_loss      | -0.0177  |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.000309 |
|    ent_coef_loss   | -0.884   |
|    learning_rate   | 0.0003   |
|    n_updates       | 667498   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 2076     |
|    fps             | 32       |
|    time_elapsed    | 20618    |
|    total_timesteps | 678140   |
| train/             |          |
|    actor_loss      | -0.0138  |
|    critic_loss     | 0.000427 |
|    ent_coef        | 0.000318 |
|    ent_coef_loss   | -2.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 668139   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 32       |
|    time_elapsed    | 20656    |
|    total_timesteps | 679273   |
| train/             |          |
|    actor_loss      | -0.0686  |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 669272   |
---------------------------------
Eval num_timesteps=680000, episode_reward=0.60 +/- 0.49
Episode length: 250.00 +/- 239.31
----------------------------------
| eval/              |           |
|    mean_ep_length  | 250       |
|    mean_reward     | 0.6       |
| time/              |           |
|    total_timesteps | 680000    |
| train/             |           |
|    actor_loss      | -0.000942 |
|    critic_loss     | 0.000825  |
|    ent_coef        | 0.000305  |
|    ent_coef_loss   | 1.83      |
|    learning_rate   | 0.0003    |
|    n_updates       | 669999    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 32       |
|    time_elapsed    | 20742    |
|    total_timesteps | 680277   |
| train/             |          |
|    actor_loss      | -0.0395  |
|    critic_loss     | 0.000785 |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 670276   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2088     |
|    fps             | 32       |
|    time_elapsed    | 20780    |
|    total_timesteps | 681304   |
| train/             |          |
|    actor_loss      | -0.0767  |
|    critic_loss     | 0.000882 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 671303   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2092     |
|    fps             | 32       |
|    time_elapsed    | 20831    |
|    total_timesteps | 682376   |
| train/             |          |
|    actor_loss      | -0.0422  |
|    critic_loss     | 0.00054  |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 672375   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 32       |
|    time_elapsed    | 20841    |
|    total_timesteps | 682610   |
| train/             |          |
|    actor_loss      | -0.0686  |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 1.66     |
|    learning_rate   | 0.0003   |
|    n_updates       | 672609   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2100     |
|    fps             | 32       |
|    time_elapsed    | 20859    |
|    total_timesteps | 683238   |
| train/             |          |
|    actor_loss      | -0.0113  |
|    critic_loss     | 0.00077  |
|    ent_coef        | 0.000289 |
|    ent_coef_loss   | -3.45    |
|    learning_rate   | 0.0003   |
|    n_updates       | 673237   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2104     |
|    fps             | 32       |
|    time_elapsed    | 20874    |
|    total_timesteps | 683766   |
| train/             |          |
|    actor_loss      | 0.00877  |
|    critic_loss     | 0.000763 |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 673765   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2108     |
|    fps             | 32       |
|    time_elapsed    | 20887    |
|    total_timesteps | 684271   |
| train/             |          |
|    actor_loss      | -0.0173  |
|    critic_loss     | 0.0011   |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | -0.949   |
|    learning_rate   | 0.0003   |
|    n_updates       | 674270   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2112     |
|    fps             | 32       |
|    time_elapsed    | 20907    |
|    total_timesteps | 684362   |
| train/             |          |
|    actor_loss      | -0.0162  |
|    critic_loss     | 0.000717 |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | 2.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 674361   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 32       |
|    time_elapsed    | 20933    |
|    total_timesteps | 685365   |
| train/             |          |
|    actor_loss      | -0.00112 |
|    critic_loss     | 0.00182  |
|    ent_coef        | 0.000315 |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 675364   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2120     |
|    fps             | 32       |
|    time_elapsed    | 20962    |
|    total_timesteps | 686680   |
| train/             |          |
|    actor_loss      | -0.00256 |
|    critic_loss     | 0.000404 |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 0.576    |
|    learning_rate   | 0.0003   |
|    n_updates       | 676679   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 32       |
|    time_elapsed    | 20978    |
|    total_timesteps | 686774   |
| train/             |          |
|    actor_loss      | -0.12    |
|    critic_loss     | 0.000865 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 0.0309   |
|    learning_rate   | 0.0003   |
|    n_updates       | 676773   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2128     |
|    fps             | 32       |
|    time_elapsed    | 20995    |
|    total_timesteps | 687391   |
| train/             |          |
|    actor_loss      | -0.0103  |
|    critic_loss     | 0.00448  |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | -0.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 677390   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2132     |
|    fps             | 32       |
|    time_elapsed    | 21007    |
|    total_timesteps | 687643   |
| train/             |          |
|    actor_loss      | -0.0905  |
|    critic_loss     | 0.000738 |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | 2.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 677642   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2136     |
|    fps             | 32       |
|    time_elapsed    | 21019    |
|    total_timesteps | 687855   |
| train/             |          |
|    actor_loss      | -0.0122  |
|    critic_loss     | 0.000557 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | 0.22     |
|    learning_rate   | 0.0003   |
|    n_updates       | 677854   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2140     |
|    fps             | 32       |
|    time_elapsed    | 21029    |
|    total_timesteps | 688035   |
| train/             |          |
|    actor_loss      | -0.0178  |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000305 |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 678034   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 163      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2144     |
|    fps             | 32       |
|    time_elapsed    | 21048    |
|    total_timesteps | 688688   |
| train/             |          |
|    actor_loss      | -0.0824  |
|    critic_loss     | 0.00068  |
|    ent_coef        | 0.000314 |
|    ent_coef_loss   | 0.252    |
|    learning_rate   | 0.0003   |
|    n_updates       | 678687   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2148     |
|    fps             | 32       |
|    time_elapsed    | 21076    |
|    total_timesteps | 689394   |
| train/             |          |
|    actor_loss      | -0.02    |
|    critic_loss     | 0.00112  |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 679393   |
---------------------------------
Eval num_timesteps=690000, episode_reward=0.60 +/- 0.49
Episode length: 207.80 +/- 238.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 208      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -0.0749  |
|    critic_loss     | 0.000569 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | 0.805    |
|    learning_rate   | 0.0003   |
|    n_updates       | 679999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2152     |
|    fps             | 32       |
|    time_elapsed    | 21159    |
|    total_timesteps | 690892   |
| train/             |          |
|    actor_loss      | -0.00626 |
|    critic_loss     | 0.000596 |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | -2.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 680891   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2156     |
|    fps             | 32       |
|    time_elapsed    | 21192    |
|    total_timesteps | 691291   |
| train/             |          |
|    actor_loss      | 0.0129   |
|    critic_loss     | 0.000432 |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 681290   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2160     |
|    fps             | 32       |
|    time_elapsed    | 21214    |
|    total_timesteps | 692294   |
| train/             |          |
|    actor_loss      | -0.0352  |
|    critic_loss     | 0.000771 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 682293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 163      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 32       |
|    time_elapsed    | 21226    |
|    total_timesteps | 692597   |
| train/             |          |
|    actor_loss      | -0.056   |
|    critic_loss     | 0.00132  |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 682596   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 163      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2168     |
|    fps             | 32       |
|    time_elapsed    | 21255    |
|    total_timesteps | 693692   |
| train/             |          |
|    actor_loss      | -0.00303 |
|    critic_loss     | 0.0009   |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 0.598    |
|    learning_rate   | 0.0003   |
|    n_updates       | 683691   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2172     |
|    fps             | 32       |
|    time_elapsed    | 21295    |
|    total_timesteps | 694884   |
| train/             |          |
|    actor_loss      | -0.0411  |
|    critic_loss     | 0.000748 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 0.506    |
|    learning_rate   | 0.0003   |
|    n_updates       | 684883   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2176     |
|    fps             | 32       |
|    time_elapsed    | 21326    |
|    total_timesteps | 695719   |
| train/             |          |
|    actor_loss      | -0.0612  |
|    critic_loss     | 0.00409  |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 685718   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2180     |
|    fps             | 32       |
|    time_elapsed    | 21353    |
|    total_timesteps | 696309   |
| train/             |          |
|    actor_loss      | -0.0188  |
|    critic_loss     | 0.000415 |
|    ent_coef        | 0.000298 |
|    ent_coef_loss   | 0.303    |
|    learning_rate   | 0.0003   |
|    n_updates       | 686308   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2184     |
|    fps             | 32       |
|    time_elapsed    | 21369    |
|    total_timesteps | 696869   |
| train/             |          |
|    actor_loss      | -0.0226  |
|    critic_loss     | 0.000651 |
|    ent_coef        | 0.000303 |
|    ent_coef_loss   | -0.377   |
|    learning_rate   | 0.0003   |
|    n_updates       | 686868   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2188     |
|    fps             | 32       |
|    time_elapsed    | 21379    |
|    total_timesteps | 697043   |
| train/             |          |
|    actor_loss      | -0.0199  |
|    critic_loss     | 0.00251  |
|    ent_coef        | 0.000307 |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 0.0003   |
|    n_updates       | 687042   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2192     |
|    fps             | 32       |
|    time_elapsed    | 21394    |
|    total_timesteps | 697384   |
| train/             |          |
|    actor_loss      | -0.0329  |
|    critic_loss     | 0.000577 |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 3.76     |
|    learning_rate   | 0.0003   |
|    n_updates       | 687383   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 2196     |
|    fps             | 32       |
|    time_elapsed    | 21436    |
|    total_timesteps | 698960   |
| train/             |          |
|    actor_loss      | -0.0539  |
|    critic_loss     | 0.000577 |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | 0.246    |
|    learning_rate   | 0.0003   |
|    n_updates       | 688959   |
---------------------------------
Eval num_timesteps=700000, episode_reward=0.70 +/- 0.46
Episode length: 154.10 +/- 226.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 154      |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -0.0284  |
|    critic_loss     | 0.000524 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -4.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 689999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2200     |
|    fps             | 32       |
|    time_elapsed    | 21513    |
|    total_timesteps | 700137   |
| train/             |          |
|    actor_loss      | -0.0223  |
|    critic_loss     | 0.000451 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 0.0003   |
|    n_updates       | 690136   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2204     |
|    fps             | 32       |
|    time_elapsed    | 21534    |
|    total_timesteps | 700691   |
| train/             |          |
|    actor_loss      | -0.0271  |
|    critic_loss     | 0.000523 |
|    ent_coef        | 0.000298 |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 0.0003   |
|    n_updates       | 690690   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2208     |
|    fps             | 32       |
|    time_elapsed    | 21558    |
|    total_timesteps | 701554   |
| train/             |          |
|    actor_loss      | -0.0292  |
|    critic_loss     | 0.000828 |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | 0.991    |
|    learning_rate   | 0.0003   |
|    n_updates       | 691553   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2212     |
|    fps             | 32       |
|    time_elapsed    | 21576    |
|    total_timesteps | 702149   |
| train/             |          |
|    actor_loss      | -0.0427  |
|    critic_loss     | 0.000594 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 692148   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2216     |
|    fps             | 32       |
|    time_elapsed    | 21603    |
|    total_timesteps | 703203   |
| train/             |          |
|    actor_loss      | -0.035   |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 693202   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 169       |
|    ep_rew_mean     | 0.77      |
| time/              |           |
|    episodes        | 2220      |
|    fps             | 32        |
|    time_elapsed    | 21618     |
|    total_timesteps | 703573    |
| train/             |           |
|    actor_loss      | -0.000223 |
|    critic_loss     | 0.00116   |
|    ent_coef        | 0.000301  |
|    ent_coef_loss   | -2.36     |
|    learning_rate   | 0.0003    |
|    n_updates       | 693572    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2224     |
|    fps             | 32       |
|    time_elapsed    | 21659    |
|    total_timesteps | 705573   |
| train/             |          |
|    actor_loss      | -0.0076  |
|    critic_loss     | 0.000511 |
|    ent_coef        | 0.000305 |
|    ent_coef_loss   | -1.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 695572   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2228     |
|    fps             | 32       |
|    time_elapsed    | 21678    |
|    total_timesteps | 706303   |
| train/             |          |
|    actor_loss      | 0.00636  |
|    critic_loss     | 0.000419 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | 0.259    |
|    learning_rate   | 0.0003   |
|    n_updates       | 696302   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2232     |
|    fps             | 32       |
|    time_elapsed    | 21720    |
|    total_timesteps | 707817   |
| train/             |          |
|    actor_loss      | -0.0569  |
|    critic_loss     | 0.0005   |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 697816   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2236     |
|    fps             | 32       |
|    time_elapsed    | 21738    |
|    total_timesteps | 708400   |
| train/             |          |
|    actor_loss      | 0.000294 |
|    critic_loss     | 0.00116  |
|    ent_coef        | 0.000304 |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 0.0003   |
|    n_updates       | 698399   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2240     |
|    fps             | 32       |
|    time_elapsed    | 21755    |
|    total_timesteps | 708466   |
| train/             |          |
|    actor_loss      | -0.0265  |
|    critic_loss     | 0.000482 |
|    ent_coef        | 0.000303 |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 698465   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2244     |
|    fps             | 32       |
|    time_elapsed    | 21787    |
|    total_timesteps | 709595   |
| train/             |          |
|    actor_loss      | -0.0735  |
|    critic_loss     | 0.000503 |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 0.0003   |
|    n_updates       | 699594   |
---------------------------------
Eval num_timesteps=710000, episode_reward=0.40 +/- 0.49
Episode length: 308.30 +/- 235.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 308      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -0.0284  |
|    critic_loss     | 0.00145  |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | -3.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 699999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2248     |
|    fps             | 32       |
|    time_elapsed    | 21855    |
|    total_timesteps | 710641   |
| train/             |          |
|    actor_loss      | -0.0239  |
|    critic_loss     | 0.00114  |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 0.556    |
|    learning_rate   | 0.0003   |
|    n_updates       | 700640   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2252     |
|    fps             | 32       |
|    time_elapsed    | 21872    |
|    total_timesteps | 711278   |
| train/             |          |
|    actor_loss      | -0.0473  |
|    critic_loss     | 0.000595 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 701277   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2256     |
|    fps             | 32       |
|    time_elapsed    | 21888    |
|    total_timesteps | 711850   |
| train/             |          |
|    actor_loss      | 0.0044   |
|    critic_loss     | 0.00258  |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | 0.161    |
|    learning_rate   | 0.0003   |
|    n_updates       | 701849   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2260     |
|    fps             | 32       |
|    time_elapsed    | 21914    |
|    total_timesteps | 712662   |
| train/             |          |
|    actor_loss      | -0.0226  |
|    critic_loss     | 0.000441 |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | -3.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 702661   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2264     |
|    fps             | 32       |
|    time_elapsed    | 21943    |
|    total_timesteps | 713326   |
| train/             |          |
|    actor_loss      | -0.0452  |
|    critic_loss     | 0.000574 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 703325   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2268     |
|    fps             | 32       |
|    time_elapsed    | 21966    |
|    total_timesteps | 714378   |
| train/             |          |
|    actor_loss      | -0.0229  |
|    critic_loss     | 0.000461 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 0.0003   |
|    n_updates       | 704377   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2272     |
|    fps             | 32       |
|    time_elapsed    | 21997    |
|    total_timesteps | 715432   |
| train/             |          |
|    actor_loss      | -0.0374  |
|    critic_loss     | 0.000353 |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -1.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 705431   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2276     |
|    fps             | 32       |
|    time_elapsed    | 22031    |
|    total_timesteps | 715964   |
| train/             |          |
|    actor_loss      | -0.0292  |
|    critic_loss     | 0.000403 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 705963   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2280     |
|    fps             | 32       |
|    time_elapsed    | 22063    |
|    total_timesteps | 716860   |
| train/             |          |
|    actor_loss      | -0.0329  |
|    critic_loss     | 0.000368 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 706859   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2284     |
|    fps             | 32       |
|    time_elapsed    | 22091    |
|    total_timesteps | 717910   |
| train/             |          |
|    actor_loss      | -0.052   |
|    critic_loss     | 0.000814 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | -3.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 707909   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2288     |
|    fps             | 32       |
|    time_elapsed    | 22117    |
|    total_timesteps | 718912   |
| train/             |          |
|    actor_loss      | -0.00309 |
|    critic_loss     | 0.000379 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 0.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 708911   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2292     |
|    fps             | 32       |
|    time_elapsed    | 22143    |
|    total_timesteps | 719983   |
| train/             |          |
|    actor_loss      | -0.0169  |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -0.278   |
|    learning_rate   | 0.0003   |
|    n_updates       | 709982   |
---------------------------------
Eval num_timesteps=720000, episode_reward=0.50 +/- 0.50
Episode length: 284.20 +/- 227.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 284      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -0.0196  |
|    critic_loss     | 0.000529 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -0.907   |
|    learning_rate   | 0.0003   |
|    n_updates       | 709999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2296     |
|    fps             | 32       |
|    time_elapsed    | 22223    |
|    total_timesteps | 721090   |
| train/             |          |
|    actor_loss      | -0.0023  |
|    critic_loss     | 0.00223  |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 2.52     |
|    learning_rate   | 0.0003   |
|    n_updates       | 711089   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2300     |
|    fps             | 32       |
|    time_elapsed    | 22269    |
|    total_timesteps | 722124   |
| train/             |          |
|    actor_loss      | -0.00186 |
|    critic_loss     | 0.000458 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -3.87    |
|    learning_rate   | 0.0003   |
|    n_updates       | 712123   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2304     |
|    fps             | 32       |
|    time_elapsed    | 22304    |
|    total_timesteps | 723167   |
| train/             |          |
|    actor_loss      | -0.0425  |
|    critic_loss     | 0.00229  |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 713166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 0.62     |
| time/              |          |
|    episodes        | 2308     |
|    fps             | 32       |
|    time_elapsed    | 22338    |
|    total_timesteps | 724378   |
| train/             |          |
|    actor_loss      | -0.0594  |
|    critic_loss     | 0.00045  |
|    ent_coef        | 0.000253 |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 714377   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 2312     |
|    fps             | 32       |
|    time_elapsed    | 22376    |
|    total_timesteps | 725939   |
| train/             |          |
|    actor_loss      | 0.00241  |
|    critic_loss     | 0.000437 |
|    ent_coef        | 0.000248 |
|    ent_coef_loss   | -1.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 715938   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 0.61     |
| time/              |          |
|    episodes        | 2316     |
|    fps             | 32       |
|    time_elapsed    | 22405    |
|    total_timesteps | 726463   |
| train/             |          |
|    actor_loss      | -0.0138  |
|    critic_loss     | 0.000327 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | -2.77    |
|    learning_rate   | 0.0003   |
|    n_updates       | 716462   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 0.6      |
| time/              |          |
|    episodes        | 2320     |
|    fps             | 32       |
|    time_elapsed    | 22436    |
|    total_timesteps | 727294   |
| train/             |          |
|    actor_loss      | 0.000608 |
|    critic_loss     | 0.000347 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -0.157   |
|    learning_rate   | 0.0003   |
|    n_updates       | 717293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2324     |
|    fps             | 32       |
|    time_elapsed    | 22452    |
|    total_timesteps | 727799   |
| train/             |          |
|    actor_loss      | -0.0128  |
|    critic_loss     | 0.00109  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -0.464   |
|    learning_rate   | 0.0003   |
|    n_updates       | 717798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2328     |
|    fps             | 32       |
|    time_elapsed    | 22466    |
|    total_timesteps | 728198   |
| train/             |          |
|    actor_loss      | -0.0658  |
|    critic_loss     | 0.000662 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 718197   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2332     |
|    fps             | 32       |
|    time_elapsed    | 22481    |
|    total_timesteps | 728231   |
| train/             |          |
|    actor_loss      | -0.0389  |
|    critic_loss     | 0.000496 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -2.98    |
|    learning_rate   | 0.0003   |
|    n_updates       | 718230   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2336     |
|    fps             | 32       |
|    time_elapsed    | 22497    |
|    total_timesteps | 728855   |
| train/             |          |
|    actor_loss      | 0.0081   |
|    critic_loss     | 0.00067  |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -0.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 718854   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2340     |
|    fps             | 32       |
|    time_elapsed    | 22512    |
|    total_timesteps | 729415   |
| train/             |          |
|    actor_loss      | -0.0247  |
|    critic_loss     | 0.00296  |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -0.899   |
|    learning_rate   | 0.0003   |
|    n_updates       | 719414   |
---------------------------------
Eval num_timesteps=730000, episode_reward=0.80 +/- 0.40
Episode length: 118.00 +/- 191.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 118      |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -0.0134  |
|    critic_loss     | 0.000485 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -3.78    |
|    learning_rate   | 0.0003   |
|    n_updates       | 719999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2344     |
|    fps             | 32       |
|    time_elapsed    | 22557    |
|    total_timesteps | 730045   |
| train/             |          |
|    actor_loss      | -0.013   |
|    critic_loss     | 0.000434 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 720044   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2348     |
|    fps             | 32       |
|    time_elapsed    | 22578    |
|    total_timesteps | 730719   |
| train/             |          |
|    actor_loss      | -0.0135  |
|    critic_loss     | 0.000376 |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | 0.137    |
|    learning_rate   | 0.0003   |
|    n_updates       | 720718   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2352     |
|    fps             | 32       |
|    time_elapsed    | 22622    |
|    total_timesteps | 731298   |
| train/             |          |
|    actor_loss      | -0.0143  |
|    critic_loss     | 0.000923 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -2.02    |
|    learning_rate   | 0.0003   |
|    n_updates       | 721297   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2356     |
|    fps             | 32       |
|    time_elapsed    | 22648    |
|    total_timesteps | 732516   |
| train/             |          |
|    actor_loss      | -0.0162  |
|    critic_loss     | 0.000287 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 722515   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2360     |
|    fps             | 32       |
|    time_elapsed    | 22674    |
|    total_timesteps | 733583   |
| train/             |          |
|    actor_loss      | 0.0055   |
|    critic_loss     | 0.000332 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -3       |
|    learning_rate   | 0.0003   |
|    n_updates       | 723582   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2364     |
|    fps             | 32       |
|    time_elapsed    | 22700    |
|    total_timesteps | 734272   |
| train/             |          |
|    actor_loss      | 0.0051   |
|    critic_loss     | 0.00041  |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 724271   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2368     |
|    fps             | 32       |
|    time_elapsed    | 22720    |
|    total_timesteps | 735325   |
| train/             |          |
|    actor_loss      | -0.0629  |
|    critic_loss     | 0.00106  |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 4.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 725324   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2372     |
|    fps             | 32       |
|    time_elapsed    | 22759    |
|    total_timesteps | 736438   |
| train/             |          |
|    actor_loss      | -0.0756  |
|    critic_loss     | 0.000836 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 5.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 726437   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 0.63     |
| time/              |          |
|    episodes        | 2376     |
|    fps             | 32       |
|    time_elapsed    | 22791    |
|    total_timesteps | 737939   |
| train/             |          |
|    actor_loss      | -0.0351  |
|    critic_loss     | 0.000496 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 727938   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 0.64     |
| time/              |          |
|    episodes        | 2380     |
|    fps             | 32       |
|    time_elapsed    | 22808    |
|    total_timesteps | 738088   |
| train/             |          |
|    actor_loss      | -0.0326  |
|    critic_loss     | 0.000447 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 0.0003   |
|    n_updates       | 728087   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2384     |
|    fps             | 32       |
|    time_elapsed    | 22833    |
|    total_timesteps | 738699   |
| train/             |          |
|    actor_loss      | -0.0413  |
|    critic_loss     | 0.000728 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 0.922    |
|    learning_rate   | 0.0003   |
|    n_updates       | 728698   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2388     |
|    fps             | 32       |
|    time_elapsed    | 22866    |
|    total_timesteps | 739426   |
| train/             |          |
|    actor_loss      | -0.0306  |
|    critic_loss     | 0.000968 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 729425   |
---------------------------------
Eval num_timesteps=740000, episode_reward=0.40 +/- 0.49
Episode length: 308.30 +/- 235.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 308      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -0.0187  |
|    critic_loss     | 0.000474 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | -0.329   |
|    learning_rate   | 0.0003   |
|    n_updates       | 729999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2392     |
|    fps             | 32       |
|    time_elapsed    | 22980    |
|    total_timesteps | 740927   |
| train/             |          |
|    actor_loss      | -0.0237  |
|    critic_loss     | 0.000413 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | -2.42    |
|    learning_rate   | 0.0003   |
|    n_updates       | 730926   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2396     |
|    fps             | 32       |
|    time_elapsed    | 23003    |
|    total_timesteps | 741931   |
| train/             |          |
|    actor_loss      | -0.0291  |
|    critic_loss     | 0.00306  |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | -3.7     |
|    learning_rate   | 0.0003   |
|    n_updates       | 731930   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2400     |
|    fps             | 32       |
|    time_elapsed    | 23033    |
|    total_timesteps | 743087   |
| train/             |          |
|    actor_loss      | -0.046   |
|    critic_loss     | 0.00121  |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -2.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 733086   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2404     |
|    fps             | 32       |
|    time_elapsed    | 23068    |
|    total_timesteps | 743894   |
| train/             |          |
|    actor_loss      | -0.0166  |
|    critic_loss     | 0.000462 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | 0.284    |
|    learning_rate   | 0.0003   |
|    n_updates       | 733893   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2408     |
|    fps             | 32       |
|    time_elapsed    | 23114    |
|    total_timesteps | 744954   |
| train/             |          |
|    actor_loss      | -0.0423  |
|    critic_loss     | 0.000423 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | 2.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 734953   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2412     |
|    fps             | 32       |
|    time_elapsed    | 23144    |
|    total_timesteps | 745610   |
| train/             |          |
|    actor_loss      | -0.0285  |
|    critic_loss     | 0.000419 |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | -2.19    |
|    learning_rate   | 0.0003   |
|    n_updates       | 735609   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2416     |
|    fps             | 32       |
|    time_elapsed    | 23165    |
|    total_timesteps | 746182   |
| train/             |          |
|    actor_loss      | -0.0257  |
|    critic_loss     | 0.000463 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -3.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 736181   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2420     |
|    fps             | 32       |
|    time_elapsed    | 23198    |
|    total_timesteps | 747458   |
| train/             |          |
|    actor_loss      | -0.00031 |
|    critic_loss     | 0.000439 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 0.0003   |
|    n_updates       | 737457   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2424     |
|    fps             | 32       |
|    time_elapsed    | 23220    |
|    total_timesteps | 747583   |
| train/             |          |
|    actor_loss      | -0.0662  |
|    critic_loss     | 0.000691 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | 0.823    |
|    learning_rate   | 0.0003   |
|    n_updates       | 737582   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2428     |
|    fps             | 32       |
|    time_elapsed    | 23249    |
|    total_timesteps | 748783   |
| train/             |          |
|    actor_loss      | -0.00707 |
|    critic_loss     | 0.000468 |
|    ent_coef        | 0.000286 |
|    ent_coef_loss   | 0.541    |
|    learning_rate   | 0.0003   |
|    n_updates       | 738782   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2432     |
|    fps             | 32       |
|    time_elapsed    | 23257    |
|    total_timesteps | 748860   |
| train/             |          |
|    actor_loss      | -0.0675  |
|    critic_loss     | 0.0226   |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | 6.49     |
|    learning_rate   | 0.0003   |
|    n_updates       | 738859   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2436     |
|    fps             | 32       |
|    time_elapsed    | 23267    |
|    total_timesteps | 748981   |
| train/             |          |
|    actor_loss      | -0.0118  |
|    critic_loss     | 0.000799 |
|    ent_coef        | 0.000289 |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 0.0003   |
|    n_updates       | 738980   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2440     |
|    fps             | 32       |
|    time_elapsed    | 23279    |
|    total_timesteps | 749339   |
| train/             |          |
|    actor_loss      | -0.0381  |
|    critic_loss     | 0.000865 |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 0.0003   |
|    n_updates       | 739338   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2444     |
|    fps             | 32       |
|    time_elapsed    | 23303    |
|    total_timesteps | 749844   |
| train/             |          |
|    actor_loss      | -0.0454  |
|    critic_loss     | 0.00199  |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | -1.65    |
|    learning_rate   | 0.0003   |
|    n_updates       | 739843   |
---------------------------------
Eval num_timesteps=750000, episode_reward=0.80 +/- 0.40
Episode length: 110.80 +/- 195.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 111      |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -0.0431  |
|    critic_loss     | 0.00048  |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | -0.262   |
|    learning_rate   | 0.0003   |
|    n_updates       | 739999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2448     |
|    fps             | 32       |
|    time_elapsed    | 23358    |
|    total_timesteps | 750177   |
| train/             |          |
|    actor_loss      | -0.0747  |
|    critic_loss     | 0.00151  |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 0.0003   |
|    n_updates       | 740176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2452     |
|    fps             | 32       |
|    time_elapsed    | 23376    |
|    total_timesteps | 750799   |
| train/             |          |
|    actor_loss      | -0.0349  |
|    critic_loss     | 0.00106  |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 0.0003   |
|    n_updates       | 740798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2456     |
|    fps             | 32       |
|    time_elapsed    | 23391    |
|    total_timesteps | 751398   |
| train/             |          |
|    actor_loss      | -0.014   |
|    critic_loss     | 0.000481 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 3.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 741397   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2460     |
|    fps             | 32       |
|    time_elapsed    | 23423    |
|    total_timesteps | 752404   |
| train/             |          |
|    actor_loss      | -0.0363  |
|    critic_loss     | 0.000479 |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | -0.185   |
|    learning_rate   | 0.0003   |
|    n_updates       | 742403   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2464     |
|    fps             | 32       |
|    time_elapsed    | 23438    |
|    total_timesteps | 752959   |
| train/             |          |
|    actor_loss      | -0.0438  |
|    critic_loss     | 0.00045  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -0.341   |
|    learning_rate   | 0.0003   |
|    n_updates       | 742958   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2468     |
|    fps             | 32       |
|    time_elapsed    | 23495    |
|    total_timesteps | 753731   |
| train/             |          |
|    actor_loss      | -0.0416  |
|    critic_loss     | 0.000382 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | 0.216    |
|    learning_rate   | 0.0003   |
|    n_updates       | 743730   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2472     |
|    fps             | 32       |
|    time_elapsed    | 23509    |
|    total_timesteps | 753762   |
| train/             |          |
|    actor_loss      | -0.025   |
|    critic_loss     | 0.000848 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -1.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 743761   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2476     |
|    fps             | 32       |
|    time_elapsed    | 23536    |
|    total_timesteps | 754302   |
| train/             |          |
|    actor_loss      | -0.0365  |
|    critic_loss     | 0.000511 |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | 0.259    |
|    learning_rate   | 0.0003   |
|    n_updates       | 744301   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2480     |
|    fps             | 32       |
|    time_elapsed    | 23551    |
|    total_timesteps | 754808   |
| train/             |          |
|    actor_loss      | -0.0596  |
|    critic_loss     | 0.000454 |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 744807   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2484     |
|    fps             | 32       |
|    time_elapsed    | 23582    |
|    total_timesteps | 755782   |
| train/             |          |
|    actor_loss      | -0.0104  |
|    critic_loss     | 0.000415 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -5.34    |
|    learning_rate   | 0.0003   |
|    n_updates       | 745781   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2488     |
|    fps             | 32       |
|    time_elapsed    | 23606    |
|    total_timesteps | 756718   |
| train/             |          |
|    actor_loss      | -0.0825  |
|    critic_loss     | 0.00374  |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 2.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 746717   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 159      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 2492     |
|    fps             | 32       |
|    time_elapsed    | 23614    |
|    total_timesteps | 756818   |
| train/             |          |
|    actor_loss      | -0.0692  |
|    critic_loss     | 0.000515 |
|    ent_coef        | 0.000302 |
|    ent_coef_loss   | 0.19     |
|    learning_rate   | 0.0003   |
|    n_updates       | 746817   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2496     |
|    fps             | 32       |
|    time_elapsed    | 23624    |
|    total_timesteps | 756915   |
| train/             |          |
|    actor_loss      | -0.0161  |
|    critic_loss     | 0.00183  |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | 0.447    |
|    learning_rate   | 0.0003   |
|    n_updates       | 746914   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2500     |
|    fps             | 32       |
|    time_elapsed    | 23641    |
|    total_timesteps | 757145   |
| train/             |          |
|    actor_loss      | -0.0499  |
|    critic_loss     | 0.00211  |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | -0.962   |
|    learning_rate   | 0.0003   |
|    n_updates       | 747144   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2504     |
|    fps             | 32       |
|    time_elapsed    | 23673    |
|    total_timesteps | 758720   |
| train/             |          |
|    actor_loss      | -0.0581  |
|    critic_loss     | 0.000564 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 748719   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2508     |
|    fps             | 32       |
|    time_elapsed    | 23688    |
|    total_timesteps | 759318   |
| train/             |          |
|    actor_loss      | -0.0485  |
|    critic_loss     | 0.00195  |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 2.5      |
|    learning_rate   | 0.0003   |
|    n_updates       | 749317   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2512     |
|    fps             | 32       |
|    time_elapsed    | 23709    |
|    total_timesteps | 759959   |
| train/             |          |
|    actor_loss      | -0.0588  |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.000297 |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 0.0003   |
|    n_updates       | 749958   |
---------------------------------
Eval num_timesteps=760000, episode_reward=0.70 +/- 0.46
Episode length: 159.70 +/- 223.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 160      |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -0.00668 |
|    critic_loss     | 0.000784 |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -0.341   |
|    learning_rate   | 0.0003   |
|    n_updates       | 749999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2516     |
|    fps             | 32       |
|    time_elapsed    | 23764    |
|    total_timesteps | 760621   |
| train/             |          |
|    actor_loss      | -0.0177  |
|    critic_loss     | 0.000409 |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | 0.37     |
|    learning_rate   | 0.0003   |
|    n_updates       | 750620   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2520     |
|    fps             | 32       |
|    time_elapsed    | 23787    |
|    total_timesteps | 761663   |
| train/             |          |
|    actor_loss      | -0.0121  |
|    critic_loss     | 0.000465 |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 751662   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2524     |
|    fps             | 32       |
|    time_elapsed    | 23797    |
|    total_timesteps | 761833   |
| train/             |          |
|    actor_loss      | -0.0317  |
|    critic_loss     | 0.000741 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 751832   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2528     |
|    fps             | 32       |
|    time_elapsed    | 23807    |
|    total_timesteps | 761998   |
| train/             |          |
|    actor_loss      | -0.025   |
|    critic_loss     | 0.000364 |
|    ent_coef        | 0.000291 |
|    ent_coef_loss   | -3.86    |
|    learning_rate   | 0.0003   |
|    n_updates       | 751997   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2532     |
|    fps             | 31       |
|    time_elapsed    | 23825    |
|    total_timesteps | 762235   |
| train/             |          |
|    actor_loss      | -0.0424  |
|    critic_loss     | 0.00163  |
|    ent_coef        | 0.00029  |
|    ent_coef_loss   | -1.36    |
|    learning_rate   | 0.0003   |
|    n_updates       | 752234   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2536     |
|    fps             | 32       |
|    time_elapsed    | 23860    |
|    total_timesteps | 763775   |
| train/             |          |
|    actor_loss      | -0.0607  |
|    critic_loss     | 0.000829 |
|    ent_coef        | 0.000298 |
|    ent_coef_loss   | 0.264    |
|    learning_rate   | 0.0003   |
|    n_updates       | 753774   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 153      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2540     |
|    fps             | 32       |
|    time_elapsed    | 23881    |
|    total_timesteps | 764687   |
| train/             |          |
|    actor_loss      | -0.00844 |
|    critic_loss     | 0.000417 |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | 3.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 754686   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 153      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2544     |
|    fps             | 32       |
|    time_elapsed    | 23897    |
|    total_timesteps | 765192   |
| train/             |          |
|    actor_loss      | -0.0242  |
|    critic_loss     | 0.00123  |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 755191   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2548     |
|    fps             | 32       |
|    time_elapsed    | 23933    |
|    total_timesteps | 766767   |
| train/             |          |
|    actor_loss      | -0.0252  |
|    critic_loss     | 0.000535 |
|    ent_coef        | 0.000293 |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 0.0003   |
|    n_updates       | 756766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2552     |
|    fps             | 32       |
|    time_elapsed    | 23965    |
|    total_timesteps | 767770   |
| train/             |          |
|    actor_loss      | -0.0393  |
|    critic_loss     | 0.00228  |
|    ent_coef        | 0.000301 |
|    ent_coef_loss   | -0.335   |
|    learning_rate   | 0.0003   |
|    n_updates       | 757769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2556     |
|    fps             | 32       |
|    time_elapsed    | 23994    |
|    total_timesteps | 768314   |
| train/             |          |
|    actor_loss      | -0.0614  |
|    critic_loss     | 0.000853 |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | 0.442    |
|    learning_rate   | 0.0003   |
|    n_updates       | 758313   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2560     |
|    fps             | 32       |
|    time_elapsed    | 24007    |
|    total_timesteps | 768425   |
| train/             |          |
|    actor_loss      | -0.0351  |
|    critic_loss     | 0.000755 |
|    ent_coef        | 0.000286 |
|    ent_coef_loss   | 0.885    |
|    learning_rate   | 0.0003   |
|    n_updates       | 758424   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2564     |
|    fps             | 32       |
|    time_elapsed    | 24041    |
|    total_timesteps | 769927   |
| train/             |          |
|    actor_loss      | -0.0128  |
|    critic_loss     | 0.000538 |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | 0.622    |
|    learning_rate   | 0.0003   |
|    n_updates       | 759926   |
---------------------------------
Eval num_timesteps=770000, episode_reward=0.50 +/- 0.50
Episode length: 253.10 +/- 246.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 253      |
|    mean_reward     | 0.5      |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -0.0752  |
|    critic_loss     | 0.00055  |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | -0.303   |
|    learning_rate   | 0.0003   |
|    n_updates       | 759999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2568     |
|    fps             | 31       |
|    time_elapsed    | 24131    |
|    total_timesteps | 770984   |
| train/             |          |
|    actor_loss      | -0.0612  |
|    critic_loss     | 0.00143  |
|    ent_coef        | 0.000294 |
|    ent_coef_loss   | -0.278   |
|    learning_rate   | 0.0003   |
|    n_updates       | 760983   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2572     |
|    fps             | 31       |
|    time_elapsed    | 24147    |
|    total_timesteps | 771653   |
| train/             |          |
|    actor_loss      | -0.0112  |
|    critic_loss     | 0.000892 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | -3.44    |
|    learning_rate   | 0.0003   |
|    n_updates       | 761652   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2576     |
|    fps             | 31       |
|    time_elapsed    | 24172    |
|    total_timesteps | 772258   |
| train/             |          |
|    actor_loss      | -0.0752  |
|    critic_loss     | 0.000431 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | -0.0848  |
|    learning_rate   | 0.0003   |
|    n_updates       | 762257   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2580     |
|    fps             | 31       |
|    time_elapsed    | 24195    |
|    total_timesteps | 772827   |
| train/             |          |
|    actor_loss      | -0.00868 |
|    critic_loss     | 0.000641 |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | 0.956    |
|    learning_rate   | 0.0003   |
|    n_updates       | 762826   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2584     |
|    fps             | 31       |
|    time_elapsed    | 24232    |
|    total_timesteps | 773936   |
| train/             |          |
|    actor_loss      | -0.0323  |
|    critic_loss     | 0.000584 |
|    ent_coef        | 0.000286 |
|    ent_coef_loss   | -1.77    |
|    learning_rate   | 0.0003   |
|    n_updates       | 763935   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2588     |
|    fps             | 31       |
|    time_elapsed    | 24241    |
|    total_timesteps | 774024   |
| train/             |          |
|    actor_loss      | -0.0536  |
|    critic_loss     | 0.000661 |
|    ent_coef        | 0.000289 |
|    ent_coef_loss   | -0.702   |
|    learning_rate   | 0.0003   |
|    n_updates       | 764023   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2592     |
|    fps             | 31       |
|    time_elapsed    | 24255    |
|    total_timesteps | 774331   |
| train/             |          |
|    actor_loss      | -0.0639  |
|    critic_loss     | 0.00063  |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | 0.0202   |
|    learning_rate   | 0.0003   |
|    n_updates       | 764330   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2596     |
|    fps             | 31       |
|    time_elapsed    | 24270    |
|    total_timesteps | 774539   |
| train/             |          |
|    actor_loss      | -0.0362  |
|    critic_loss     | 0.000923 |
|    ent_coef        | 0.000295 |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 764538   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2600     |
|    fps             | 31       |
|    time_elapsed    | 24299    |
|    total_timesteps | 775629   |
| train/             |          |
|    actor_loss      | -0.0547  |
|    critic_loss     | 0.00045  |
|    ent_coef        | 0.000296 |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 0.0003   |
|    n_updates       | 765628   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2604     |
|    fps             | 31       |
|    time_elapsed    | 24314    |
|    total_timesteps | 776134   |
| train/             |          |
|    actor_loss      | -0.0195  |
|    critic_loss     | 0.000399 |
|    ent_coef        | 0.000288 |
|    ent_coef_loss   | -0.406   |
|    learning_rate   | 0.0003   |
|    n_updates       | 766133   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2608     |
|    fps             | 31       |
|    time_elapsed    | 24346    |
|    total_timesteps | 777230   |
| train/             |          |
|    actor_loss      | -0.0379  |
|    critic_loss     | 0.000471 |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | -0.446   |
|    learning_rate   | 0.0003   |
|    n_updates       | 767229   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2612     |
|    fps             | 31       |
|    time_elapsed    | 24366    |
|    total_timesteps | 777782   |
| train/             |          |
|    actor_loss      | -0.0362  |
|    critic_loss     | 0.00438  |
|    ent_coef        | 0.00029  |
|    ent_coef_loss   | -0.67    |
|    learning_rate   | 0.0003   |
|    n_updates       | 767781   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2616     |
|    fps             | 31       |
|    time_elapsed    | 24389    |
|    total_timesteps | 778813   |
| train/             |          |
|    actor_loss      | -0.0695  |
|    critic_loss     | 0.000367 |
|    ent_coef        | 0.000292 |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 0.0003   |
|    n_updates       | 768812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2620     |
|    fps             | 31       |
|    time_elapsed    | 24416    |
|    total_timesteps | 779816   |
| train/             |          |
|    actor_loss      | -0.0543  |
|    critic_loss     | 0.00129  |
|    ent_coef        | 0.000299 |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 769815   |
---------------------------------
Eval num_timesteps=780000, episode_reward=0.40 +/- 0.49
Episode length: 313.20 +/- 229.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 313      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -0.0555  |
|    critic_loss     | 0.000449 |
|    ent_coef        | 0.000299 |
|    ent_coef_loss   | -0.555   |
|    learning_rate   | 0.0003   |
|    n_updates       | 769999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2624     |
|    fps             | 31       |
|    time_elapsed    | 24489    |
|    total_timesteps | 780054   |
| train/             |          |
|    actor_loss      | -0.0163  |
|    critic_loss     | 0.000682 |
|    ent_coef        | 0.0003   |
|    ent_coef_loss   | 2.44     |
|    learning_rate   | 0.0003   |
|    n_updates       | 770053   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2628     |
|    fps             | 31       |
|    time_elapsed    | 24520    |
|    total_timesteps | 781582   |
| train/             |          |
|    actor_loss      | -0.0649  |
|    critic_loss     | 0.000577 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -0.878   |
|    learning_rate   | 0.0003   |
|    n_updates       | 771581   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2632     |
|    fps             | 31       |
|    time_elapsed    | 24538    |
|    total_timesteps | 782226   |
| train/             |          |
|    actor_loss      | -0.0725  |
|    critic_loss     | 0.000478 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | -0.0209  |
|    learning_rate   | 0.0003   |
|    n_updates       | 772225   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2636     |
|    fps             | 31       |
|    time_elapsed    | 24554    |
|    total_timesteps | 782846   |
| train/             |          |
|    actor_loss      | -0.0644  |
|    critic_loss     | 0.00115  |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | -3.29    |
|    learning_rate   | 0.0003   |
|    n_updates       | 772845   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2640     |
|    fps             | 31       |
|    time_elapsed    | 24579    |
|    total_timesteps | 783930   |
| train/             |          |
|    actor_loss      | -0.0672  |
|    critic_loss     | 0.000478 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 0.0003   |
|    n_updates       | 773929   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2644     |
|    fps             | 31       |
|    time_elapsed    | 24594    |
|    total_timesteps | 784486   |
| train/             |          |
|    actor_loss      | -0.0504  |
|    critic_loss     | 0.000456 |
|    ent_coef        | 0.000281 |
|    ent_coef_loss   | 5.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 774485   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2648     |
|    fps             | 31       |
|    time_elapsed    | 24627    |
|    total_timesteps | 785744   |
| train/             |          |
|    actor_loss      | -0.0391  |
|    critic_loss     | 0.000568 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 0.0003   |
|    n_updates       | 775743   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2652     |
|    fps             | 31       |
|    time_elapsed    | 24659    |
|    total_timesteps | 786328   |
| train/             |          |
|    actor_loss      | -0.0437  |
|    critic_loss     | 0.000454 |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 0.0003   |
|    n_updates       | 776327   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2656     |
|    fps             | 31       |
|    time_elapsed    | 24675    |
|    total_timesteps | 786857   |
| train/             |          |
|    actor_loss      | -0.0543  |
|    critic_loss     | 0.00181  |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -2.44    |
|    learning_rate   | 0.0003   |
|    n_updates       | 776856   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2660     |
|    fps             | 31       |
|    time_elapsed    | 24704    |
|    total_timesteps | 787495   |
| train/             |          |
|    actor_loss      | -0.0596  |
|    critic_loss     | 0.000472 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.0003   |
|    n_updates       | 777494   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2664     |
|    fps             | 31       |
|    time_elapsed    | 24719    |
|    total_timesteps | 788075   |
| train/             |          |
|    actor_loss      | -0.0702  |
|    critic_loss     | 0.00036  |
|    ent_coef        | 0.000289 |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 778074   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2668     |
|    fps             | 31       |
|    time_elapsed    | 24736    |
|    total_timesteps | 788622   |
| train/             |          |
|    actor_loss      | -0.075   |
|    critic_loss     | 0.000467 |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | 3.18     |
|    learning_rate   | 0.0003   |
|    n_updates       | 778621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2672     |
|    fps             | 31       |
|    time_elapsed    | 24744    |
|    total_timesteps | 788627   |
| train/             |          |
|    actor_loss      | -0.0704  |
|    critic_loss     | 0.00187  |
|    ent_coef        | 0.000283 |
|    ent_coef_loss   | 2.99     |
|    learning_rate   | 0.0003   |
|    n_updates       | 778626   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2676     |
|    fps             | 31       |
|    time_elapsed    | 24765    |
|    total_timesteps | 789659   |
| train/             |          |
|    actor_loss      | -0.039   |
|    critic_loss     | 0.000952 |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 779658   |
---------------------------------
Eval num_timesteps=790000, episode_reward=0.30 +/- 0.46
Episode length: 397.20 +/- 189.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 397      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -0.0466  |
|    critic_loss     | 0.000426 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 779999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2680     |
|    fps             | 31       |
|    time_elapsed    | 24876    |
|    total_timesteps | 791161   |
| train/             |          |
|    actor_loss      | -0.065   |
|    critic_loss     | 0.000642 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 781160   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2684     |
|    fps             | 31       |
|    time_elapsed    | 24906    |
|    total_timesteps | 792501   |
| train/             |          |
|    actor_loss      | -0.0332  |
|    critic_loss     | 0.00205  |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 0.0003   |
|    n_updates       | 782500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2688     |
|    fps             | 31       |
|    time_elapsed    | 24929    |
|    total_timesteps | 793235   |
| train/             |          |
|    actor_loss      | -0.0641  |
|    critic_loss     | 0.000877 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 0.0003   |
|    n_updates       | 783234   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2692     |
|    fps             | 31       |
|    time_elapsed    | 24946    |
|    total_timesteps | 793878   |
| train/             |          |
|    actor_loss      | -0.0386  |
|    critic_loss     | 0.000539 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | 0.921    |
|    learning_rate   | 0.0003   |
|    n_updates       | 783877   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 0.65     |
| time/              |          |
|    episodes        | 2696     |
|    fps             | 31       |
|    time_elapsed    | 24987    |
|    total_timesteps | 794942   |
| train/             |          |
|    actor_loss      | -0.0743  |
|    critic_loss     | 0.000917 |
|    ent_coef        | 0.000286 |
|    ent_coef_loss   | 3.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 784941   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2700     |
|    fps             | 31       |
|    time_elapsed    | 25036    |
|    total_timesteps | 795513   |
| train/             |          |
|    actor_loss      | -0.0406  |
|    critic_loss     | 0.0026   |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | 0.875    |
|    learning_rate   | 0.0003   |
|    n_updates       | 785512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 2704     |
|    fps             | 31       |
|    time_elapsed    | 25053    |
|    total_timesteps | 796122   |
| train/             |          |
|    actor_loss      | -0.035   |
|    critic_loss     | 0.00132  |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | -0.853   |
|    learning_rate   | 0.0003   |
|    n_updates       | 786121   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2708     |
|    fps             | 31       |
|    time_elapsed    | 25070    |
|    total_timesteps | 796853   |
| train/             |          |
|    actor_loss      | -0.0523  |
|    critic_loss     | 0.00233  |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -5.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 786852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 0.67     |
| time/              |          |
|    episodes        | 2712     |
|    fps             | 31       |
|    time_elapsed    | 25087    |
|    total_timesteps | 797428   |
| train/             |          |
|    actor_loss      | -0.0626  |
|    critic_loss     | 0.000534 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | 3.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 787427   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 0.68     |
| time/              |          |
|    episodes        | 2716     |
|    fps             | 31       |
|    time_elapsed    | 25105    |
|    total_timesteps | 798142   |
| train/             |          |
|    actor_loss      | -0.0489  |
|    critic_loss     | 0.000616 |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | -0.617   |
|    learning_rate   | 0.0003   |
|    n_updates       | 788141   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2720     |
|    fps             | 31       |
|    time_elapsed    | 25160    |
|    total_timesteps | 798800   |
| train/             |          |
|    actor_loss      | -0.0325  |
|    critic_loss     | 0.000363 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 0.0003   |
|    n_updates       | 788799   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2724     |
|    fps             | 31       |
|    time_elapsed    | 25181    |
|    total_timesteps | 799610   |
| train/             |          |
|    actor_loss      | -0.0289  |
|    critic_loss     | 0.000684 |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -0.904   |
|    learning_rate   | 0.0003   |
|    n_updates       | 789609   |
---------------------------------
Eval num_timesteps=800000, episode_reward=0.70 +/- 0.46
Episode length: 157.70 +/- 224.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 158      |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -0.0476  |
|    critic_loss     | 0.000385 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 0.0003   |
|    n_updates       | 789999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2728     |
|    fps             | 31       |
|    time_elapsed    | 25250    |
|    total_timesteps | 801112   |
| train/             |          |
|    actor_loss      | -0.0584  |
|    critic_loss     | 0.000444 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | 2.86     |
|    learning_rate   | 0.0003   |
|    n_updates       | 791111   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 0.69     |
| time/              |          |
|    episodes        | 2732     |
|    fps             | 31       |
|    time_elapsed    | 25264    |
|    total_timesteps | 801616   |
| train/             |          |
|    actor_loss      | -0.0428  |
|    critic_loss     | 0.00059  |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 0.567    |
|    learning_rate   | 0.0003   |
|    n_updates       | 791615   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 0.7      |
| time/              |          |
|    episodes        | 2736     |
|    fps             | 31       |
|    time_elapsed    | 25273    |
|    total_timesteps | 801755   |
| train/             |          |
|    actor_loss      | -0.0346  |
|    critic_loss     | 0.000477 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | -0.884   |
|    learning_rate   | 0.0003   |
|    n_updates       | 791754   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2740     |
|    fps             | 31       |
|    time_elapsed    | 25279    |
|    total_timesteps | 801788   |
| train/             |          |
|    actor_loss      | -0.033   |
|    critic_loss     | 0.000719 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | 0.231    |
|    learning_rate   | 0.0003   |
|    n_updates       | 791787   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2744     |
|    fps             | 31       |
|    time_elapsed    | 25289    |
|    total_timesteps | 802113   |
| train/             |          |
|    actor_loss      | -0.0603  |
|    critic_loss     | 0.000405 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -3.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 792112   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2748     |
|    fps             | 31       |
|    time_elapsed    | 25308    |
|    total_timesteps | 802864   |
| train/             |          |
|    actor_loss      | -0.0953  |
|    critic_loss     | 0.0013   |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | -0.274   |
|    learning_rate   | 0.0003   |
|    n_updates       | 792863   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2752     |
|    fps             | 31       |
|    time_elapsed    | 25333    |
|    total_timesteps | 804119   |
| train/             |          |
|    actor_loss      | -0.0411  |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 2        |
|    learning_rate   | 0.0003   |
|    n_updates       | 794118   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 2756     |
|    fps             | 31       |
|    time_elapsed    | 25360    |
|    total_timesteps | 804691   |
| train/             |          |
|    actor_loss      | -0.0663  |
|    critic_loss     | 0.000459 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 1.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 794690   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2760     |
|    fps             | 31       |
|    time_elapsed    | 25394    |
|    total_timesteps | 806222   |
| train/             |          |
|    actor_loss      | -0.0275  |
|    critic_loss     | 0.00037  |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 0.796    |
|    learning_rate   | 0.0003   |
|    n_updates       | 796221   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 2764     |
|    fps             | 31       |
|    time_elapsed    | 25418    |
|    total_timesteps | 806792   |
| train/             |          |
|    actor_loss      | -0.023   |
|    critic_loss     | 0.000361 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | -0.426   |
|    learning_rate   | 0.0003   |
|    n_updates       | 796791   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2768     |
|    fps             | 31       |
|    time_elapsed    | 25443    |
|    total_timesteps | 807845   |
| train/             |          |
|    actor_loss      | -0.0168  |
|    critic_loss     | 0.000424 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | -0.0237  |
|    learning_rate   | 0.0003   |
|    n_updates       | 797844   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2772     |
|    fps             | 31       |
|    time_elapsed    | 25462    |
|    total_timesteps | 808003   |
| train/             |          |
|    actor_loss      | -0.00363 |
|    critic_loss     | 0.00257  |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -4.63    |
|    learning_rate   | 0.0003   |
|    n_updates       | 798002   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 0.71     |
| time/              |          |
|    episodes        | 2776     |
|    fps             | 31       |
|    time_elapsed    | 25478    |
|    total_timesteps | 808647   |
| train/             |          |
|    actor_loss      | -0.0147  |
|    critic_loss     | 0.00058  |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 798646   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2780     |
|    fps             | 31       |
|    time_elapsed    | 25496    |
|    total_timesteps | 808653   |
| train/             |          |
|    actor_loss      | -0.0329  |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 0.0003   |
|    n_updates       | 798652   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 172      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 2784     |
|    fps             | 31       |
|    time_elapsed    | 25527    |
|    total_timesteps | 809660   |
| train/             |          |
|    actor_loss      | -0.00437 |
|    critic_loss     | 0.000601 |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | 0.622    |
|    learning_rate   | 0.0003   |
|    n_updates       | 799659   |
---------------------------------
Eval num_timesteps=810000, episode_reward=0.60 +/- 0.49
Episode length: 208.30 +/- 238.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 208      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -0.0205  |
|    critic_loss     | 0.00136  |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -4.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 799999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2788     |
|    fps             | 31       |
|    time_elapsed    | 25623    |
|    total_timesteps | 810773   |
| train/             |          |
|    actor_loss      | -0.0122  |
|    critic_loss     | 0.000345 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 0.0003   |
|    n_updates       | 800772   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 2792     |
|    fps             | 31       |
|    time_elapsed    | 25652    |
|    total_timesteps | 811529   |
| train/             |          |
|    actor_loss      | 0.00597  |
|    critic_loss     | 0.000519 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -2.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 801528   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 172       |
|    ep_rew_mean     | 0.75      |
| time/              |           |
|    episodes        | 2796      |
|    fps             | 31        |
|    time_elapsed    | 25673     |
|    total_timesteps | 812151    |
| train/             |           |
|    actor_loss      | -0.000962 |
|    critic_loss     | 0.000615  |
|    ent_coef        | 0.000253  |
|    ent_coef_loss   | -2.53     |
|    learning_rate   | 0.0003    |
|    n_updates       | 802150    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 2800     |
|    fps             | 31       |
|    time_elapsed    | 25689    |
|    total_timesteps | 812280   |
| train/             |          |
|    actor_loss      | 0.00545  |
|    critic_loss     | 0.00066  |
|    ent_coef        | 0.000252 |
|    ent_coef_loss   | -1.79    |
|    learning_rate   | 0.0003   |
|    n_updates       | 802279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 2804     |
|    fps             | 31       |
|    time_elapsed    | 25710    |
|    total_timesteps | 812777   |
| train/             |          |
|    actor_loss      | -0.0158  |
|    critic_loss     | 0.000366 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 0.0003   |
|    n_updates       | 802776   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2808     |
|    fps             | 31       |
|    time_elapsed    | 25737    |
|    total_timesteps | 812813   |
| train/             |          |
|    actor_loss      | 0.0135   |
|    critic_loss     | 0.000357 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -1.64    |
|    learning_rate   | 0.0003   |
|    n_updates       | 802812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2812     |
|    fps             | 31       |
|    time_elapsed    | 25749    |
|    total_timesteps | 813048   |
| train/             |          |
|    actor_loss      | -0.0237  |
|    critic_loss     | 0.000386 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 1.84     |
|    learning_rate   | 0.0003   |
|    n_updates       | 803047   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2816     |
|    fps             | 31       |
|    time_elapsed    | 25764    |
|    total_timesteps | 813617   |
| train/             |          |
|    actor_loss      | -0.0316  |
|    critic_loss     | 0.00446  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 0.902    |
|    learning_rate   | 0.0003   |
|    n_updates       | 803616   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2820     |
|    fps             | 31       |
|    time_elapsed    | 25772    |
|    total_timesteps | 813697   |
| train/             |          |
|    actor_loss      | -0.0499  |
|    critic_loss     | 0.00317  |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 0.459    |
|    learning_rate   | 0.0003   |
|    n_updates       | 803696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2824     |
|    fps             | 31       |
|    time_elapsed    | 25797    |
|    total_timesteps | 814546   |
| train/             |          |
|    actor_loss      | -0.0367  |
|    critic_loss     | 0.00133  |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 0.973    |
|    learning_rate   | 0.0003   |
|    n_updates       | 804545   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2828     |
|    fps             | 31       |
|    time_elapsed    | 25816    |
|    total_timesteps | 815307   |
| train/             |          |
|    actor_loss      | -0.0376  |
|    critic_loss     | 0.000761 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | 1.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 805306   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2832     |
|    fps             | 31       |
|    time_elapsed    | 25847    |
|    total_timesteps | 816497   |
| train/             |          |
|    actor_loss      | -0.0222  |
|    critic_loss     | 0.00056  |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | -0.912   |
|    learning_rate   | 0.0003   |
|    n_updates       | 806496   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 154      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2836     |
|    fps             | 31       |
|    time_elapsed    | 25879    |
|    total_timesteps | 817119   |
| train/             |          |
|    actor_loss      | -0.0271  |
|    critic_loss     | 0.00043  |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | -1.67    |
|    learning_rate   | 0.0003   |
|    n_updates       | 807118   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2840     |
|    fps             | 31       |
|    time_elapsed    | 25898    |
|    total_timesteps | 817753   |
| train/             |          |
|    actor_loss      | -0.0164  |
|    critic_loss     | 0.000306 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 0.904    |
|    learning_rate   | 0.0003   |
|    n_updates       | 807752   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2844     |
|    fps             | 31       |
|    time_elapsed    | 25912    |
|    total_timesteps | 817897   |
| train/             |          |
|    actor_loss      | -0.011   |
|    critic_loss     | 0.000441 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 0.186    |
|    learning_rate   | 0.0003   |
|    n_updates       | 807896   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2848     |
|    fps             | 31       |
|    time_elapsed    | 25933    |
|    total_timesteps | 818468   |
| train/             |          |
|    actor_loss      | -0.0362  |
|    critic_loss     | 0.00125  |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 808467   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 154      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2852     |
|    fps             | 31       |
|    time_elapsed    | 25972    |
|    total_timesteps | 819538   |
| train/             |          |
|    actor_loss      | -0.00549 |
|    critic_loss     | 0.00134  |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 0.0003   |
|    n_updates       | 809537   |
---------------------------------
Eval num_timesteps=820000, episode_reward=0.60 +/- 0.49
Episode length: 208.80 +/- 237.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 209      |
|    mean_reward     | 0.6      |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -0.0182  |
|    critic_loss     | 0.000378 |
|    ent_coef        | 0.000254 |
|    ent_coef_loss   | 0.661    |
|    learning_rate   | 0.0003   |
|    n_updates       | 809999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2856     |
|    fps             | 31       |
|    time_elapsed    | 26046    |
|    total_timesteps | 820386   |
| train/             |          |
|    actor_loss      | -0.00415 |
|    critic_loss     | 0.000356 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 810385   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2860     |
|    fps             | 31       |
|    time_elapsed    | 26065    |
|    total_timesteps | 820918   |
| train/             |          |
|    actor_loss      | -0.0361  |
|    critic_loss     | 0.000359 |
|    ent_coef        | 0.000244 |
|    ent_coef_loss   | 0.195    |
|    learning_rate   | 0.0003   |
|    n_updates       | 810917   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2864     |
|    fps             | 31       |
|    time_elapsed    | 26082    |
|    total_timesteps | 821044   |
| train/             |          |
|    actor_loss      | -0.0168  |
|    critic_loss     | 0.000642 |
|    ent_coef        | 0.000249 |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 811043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2868     |
|    fps             | 31       |
|    time_elapsed    | 26090    |
|    total_timesteps | 821127   |
| train/             |          |
|    actor_loss      | 0.0123   |
|    critic_loss     | 0.000413 |
|    ent_coef        | 0.00025  |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 811126   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2872     |
|    fps             | 31       |
|    time_elapsed    | 26107    |
|    total_timesteps | 821565   |
| train/             |          |
|    actor_loss      | -0.0184  |
|    critic_loss     | 0.00105  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 0.0003   |
|    n_updates       | 811564   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2876     |
|    fps             | 31       |
|    time_elapsed    | 26122    |
|    total_timesteps | 822186   |
| train/             |          |
|    actor_loss      | -0.00627 |
|    critic_loss     | 0.00218  |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -1.88    |
|    learning_rate   | 0.0003   |
|    n_updates       | 812185   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2880     |
|    fps             | 31       |
|    time_elapsed    | 26136    |
|    total_timesteps | 822351   |
| train/             |          |
|    actor_loss      | -0.00298 |
|    critic_loss     | 0.000445 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 812350   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2884     |
|    fps             | 31       |
|    time_elapsed    | 26166    |
|    total_timesteps | 823546   |
| train/             |          |
|    actor_loss      | -0.0241  |
|    critic_loss     | 0.00684  |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 813545   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2888     |
|    fps             | 31       |
|    time_elapsed    | 26191    |
|    total_timesteps | 824094   |
| train/             |          |
|    actor_loss      | -0.0411  |
|    critic_loss     | 0.000289 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 0.0003   |
|    n_updates       | 814093   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | 0.82     |
| time/              |          |
|    episodes        | 2892     |
|    fps             | 31       |
|    time_elapsed    | 26206    |
|    total_timesteps | 824637   |
| train/             |          |
|    actor_loss      | -0.0531  |
|    critic_loss     | 0.000725 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 0.673    |
|    learning_rate   | 0.0003   |
|    n_updates       | 814636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2896     |
|    fps             | 31       |
|    time_elapsed    | 26234    |
|    total_timesteps | 825640   |
| train/             |          |
|    actor_loss      | -0.0192  |
|    critic_loss     | 0.000746 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 5.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 815639   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2900     |
|    fps             | 31       |
|    time_elapsed    | 26241    |
|    total_timesteps | 825795   |
| train/             |          |
|    actor_loss      | -0.0235  |
|    critic_loss     | 0.000411 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | 2.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 815794   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2904     |
|    fps             | 31       |
|    time_elapsed    | 26264    |
|    total_timesteps | 826339   |
| train/             |          |
|    actor_loss      | -0.0586  |
|    critic_loss     | 0.000451 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 3.53     |
|    learning_rate   | 0.0003   |
|    n_updates       | 816338   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2908     |
|    fps             | 31       |
|    time_elapsed    | 26280    |
|    total_timesteps | 826894   |
| train/             |          |
|    actor_loss      | 0.00896  |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 0.861    |
|    learning_rate   | 0.0003   |
|    n_updates       | 816893   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2912     |
|    fps             | 31       |
|    time_elapsed    | 26296    |
|    total_timesteps | 827435   |
| train/             |          |
|    actor_loss      | -0.00903 |
|    critic_loss     | 0.000385 |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.0003   |
|    n_updates       | 817434   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2916     |
|    fps             | 31       |
|    time_elapsed    | 26303    |
|    total_timesteps | 827462   |
| train/             |          |
|    actor_loss      | -0.00592 |
|    critic_loss     | 0.000961 |
|    ent_coef        | 0.000257 |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.0003   |
|    n_updates       | 817461   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2920     |
|    fps             | 31       |
|    time_elapsed    | 26326    |
|    total_timesteps | 827992   |
| train/             |          |
|    actor_loss      | -0.0348  |
|    critic_loss     | 0.000887 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | -0.0103  |
|    learning_rate   | 0.0003   |
|    n_updates       | 817991   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2924     |
|    fps             | 31       |
|    time_elapsed    | 26335    |
|    total_timesteps | 828138   |
| train/             |          |
|    actor_loss      | -0.0253  |
|    critic_loss     | 0.000533 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | -0.812   |
|    learning_rate   | 0.0003   |
|    n_updates       | 818137   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2928     |
|    fps             | 31       |
|    time_elapsed    | 26358    |
|    total_timesteps | 828777   |
| train/             |          |
|    actor_loss      | -0.0135  |
|    critic_loss     | 0.000303 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | -0.511   |
|    learning_rate   | 0.0003   |
|    n_updates       | 818776   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2932     |
|    fps             | 31       |
|    time_elapsed    | 26366    |
|    total_timesteps | 828933   |
| train/             |          |
|    actor_loss      | -0.0188  |
|    critic_loss     | 0.000528 |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 818932   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2936     |
|    fps             | 31       |
|    time_elapsed    | 26383    |
|    total_timesteps | 829477   |
| train/             |          |
|    actor_loss      | -0.0537  |
|    critic_loss     | 0.000824 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 5.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 819476   |
---------------------------------
Eval num_timesteps=830000, episode_reward=0.40 +/- 0.49
Episode length: 300.60 +/- 244.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 301      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -0.0245  |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 0.165    |
|    learning_rate   | 0.0003   |
|    n_updates       | 819999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 123      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2940     |
|    fps             | 31       |
|    time_elapsed    | 26446    |
|    total_timesteps | 830055   |
| train/             |          |
|    actor_loss      | -0.0405  |
|    critic_loss     | 0.000414 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | -3.41    |
|    learning_rate   | 0.0003   |
|    n_updates       | 820054   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2944     |
|    fps             | 31       |
|    time_elapsed    | 26489    |
|    total_timesteps | 831185   |
| train/             |          |
|    actor_loss      | -0.037   |
|    critic_loss     | 0.000488 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 0.998    |
|    learning_rate   | 0.0003   |
|    n_updates       | 821184   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2948     |
|    fps             | 31       |
|    time_elapsed    | 26506    |
|    total_timesteps | 831804   |
| train/             |          |
|    actor_loss      | -0.0337  |
|    critic_loss     | 0.000663 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | 2.67     |
|    learning_rate   | 0.0003   |
|    n_updates       | 821803   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2952     |
|    fps             | 31       |
|    time_elapsed    | 26523    |
|    total_timesteps | 831944   |
| train/             |          |
|    actor_loss      | -0.0395  |
|    critic_loss     | 0.00134  |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 821943   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2956     |
|    fps             | 31       |
|    time_elapsed    | 26546    |
|    total_timesteps | 833051   |
| train/             |          |
|    actor_loss      | -0.0184  |
|    critic_loss     | 0.00106  |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | 0.217    |
|    learning_rate   | 0.0003   |
|    n_updates       | 823050   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 122      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2960     |
|    fps             | 31       |
|    time_elapsed    | 26554    |
|    total_timesteps | 833083   |
| train/             |          |
|    actor_loss      | -0.0437  |
|    critic_loss     | 0.00282  |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 0.0003   |
|    n_updates       | 823082   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 122      |
|    ep_rew_mean     | 0.81     |
| time/              |          |
|    episodes        | 2964     |
|    fps             | 31       |
|    time_elapsed    | 26582    |
|    total_timesteps | 833197   |
| train/             |          |
|    actor_loss      | -0.0355  |
|    critic_loss     | 0.00103  |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 4.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 823196   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2968     |
|    fps             | 31       |
|    time_elapsed    | 26611    |
|    total_timesteps | 833865   |
| train/             |          |
|    actor_loss      | -0.013   |
|    critic_loss     | 0.000347 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | -0.113   |
|    learning_rate   | 0.0003   |
|    n_updates       | 823864   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2972     |
|    fps             | 31       |
|    time_elapsed    | 26635    |
|    total_timesteps | 834909   |
| train/             |          |
|    actor_loss      | -0.0408  |
|    critic_loss     | 0.000396 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -0.639   |
|    learning_rate   | 0.0003   |
|    n_updates       | 824908   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 2976     |
|    fps             | 31       |
|    time_elapsed    | 26654    |
|    total_timesteps | 835544   |
| train/             |          |
|    actor_loss      | -0.0318  |
|    critic_loss     | 0.00179  |
|    ent_coef        | 0.000259 |
|    ent_coef_loss   | 0.144    |
|    learning_rate   | 0.0003   |
|    n_updates       | 825543   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 2980     |
|    fps             | 31       |
|    time_elapsed    | 26670    |
|    total_timesteps | 836134   |
| train/             |          |
|    actor_loss      | -0.0414  |
|    critic_loss     | 0.000883 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 826133   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2984     |
|    fps             | 31       |
|    time_elapsed    | 26680    |
|    total_timesteps | 836358   |
| train/             |          |
|    actor_loss      | -0.0549  |
|    critic_loss     | 0.000415 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | 0.0717   |
|    learning_rate   | 0.0003   |
|    n_updates       | 826357   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2988     |
|    fps             | 31       |
|    time_elapsed    | 26704    |
|    total_timesteps | 836981   |
| train/             |          |
|    actor_loss      | 0.00218  |
|    critic_loss     | 0.000678 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -3.81    |
|    learning_rate   | 0.0003   |
|    n_updates       | 826980   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 2992     |
|    fps             | 31       |
|    time_elapsed    | 26719    |
|    total_timesteps | 837544   |
| train/             |          |
|    actor_loss      | -0.0423  |
|    critic_loss     | 0.00137  |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 2.79     |
|    learning_rate   | 0.0003   |
|    n_updates       | 827543   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 126      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 2996     |
|    fps             | 31       |
|    time_elapsed    | 26742    |
|    total_timesteps | 838262   |
| train/             |          |
|    actor_loss      | -0.0145  |
|    critic_loss     | 0.000338 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 828261   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 130      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3000     |
|    fps             | 31       |
|    time_elapsed    | 26759    |
|    total_timesteps | 838789   |
| train/             |          |
|    actor_loss      | -0.0499  |
|    critic_loss     | 0.00052  |
|    ent_coef        | 0.000255 |
|    ent_coef_loss   | -0.796   |
|    learning_rate   | 0.0003   |
|    n_updates       | 828788   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3004     |
|    fps             | 31       |
|    time_elapsed    | 26777    |
|    total_timesteps | 839443   |
| train/             |          |
|    actor_loss      | -0.0345  |
|    critic_loss     | 0.00184  |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 829442   |
---------------------------------
Eval num_timesteps=840000, episode_reward=0.30 +/- 0.46
Episode length: 350.50 +/- 228.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 0.3      |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -0.0293  |
|    critic_loss     | 0.000424 |
|    ent_coef        | 0.000258 |
|    ent_coef_loss   | -0.00822 |
|    learning_rate   | 0.0003   |
|    n_updates       | 829999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3008     |
|    fps             | 31       |
|    time_elapsed    | 26878    |
|    total_timesteps | 840353   |
| train/             |          |
|    actor_loss      | -0.032   |
|    critic_loss     | 0.000673 |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | -0.44    |
|    learning_rate   | 0.0003   |
|    n_updates       | 830352   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 3012     |
|    fps             | 31       |
|    time_elapsed    | 26889    |
|    total_timesteps | 840638   |
| train/             |          |
|    actor_loss      | -0.00136 |
|    critic_loss     | 0.000509 |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.0003   |
|    n_updates       | 830637   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 3016     |
|    fps             | 31       |
|    time_elapsed    | 26898    |
|    total_timesteps | 840738   |
| train/             |          |
|    actor_loss      | -0.0292  |
|    critic_loss     | 0.000669 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 0.228    |
|    learning_rate   | 0.0003   |
|    n_updates       | 830737   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 0.8      |
| time/              |          |
|    episodes        | 3020     |
|    fps             | 31       |
|    time_elapsed    | 26918    |
|    total_timesteps | 841473   |
| train/             |          |
|    actor_loss      | -0.0126  |
|    critic_loss     | 0.000398 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 0.0003   |
|    n_updates       | 831472   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3024     |
|    fps             | 31       |
|    time_elapsed    | 26946    |
|    total_timesteps | 842143   |
| train/             |          |
|    actor_loss      | -0.0542  |
|    critic_loss     | 0.000609 |
|    ent_coef        | 0.000269 |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 832142   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3028     |
|    fps             | 31       |
|    time_elapsed    | 26973    |
|    total_timesteps | 842672   |
| train/             |          |
|    actor_loss      | -0.0222  |
|    critic_loss     | 0.00145  |
|    ent_coef        | 0.000256 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 832671   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 3032     |
|    fps             | 31       |
|    time_elapsed    | 26994    |
|    total_timesteps | 843332   |
| train/             |          |
|    actor_loss      | -0.0154  |
|    critic_loss     | 0.000665 |
|    ent_coef        | 0.000261 |
|    ent_coef_loss   | -0.991   |
|    learning_rate   | 0.0003   |
|    n_updates       | 833331   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 3036     |
|    fps             | 31       |
|    time_elapsed    | 27039    |
|    total_timesteps | 843887   |
| train/             |          |
|    actor_loss      | -0.0316  |
|    critic_loss     | 0.000802 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 0.0003   |
|    n_updates       | 833886   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 3040     |
|    fps             | 31       |
|    time_elapsed    | 27059    |
|    total_timesteps | 844467   |
| train/             |          |
|    actor_loss      | -0.0196  |
|    critic_loss     | 0.0012   |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | -0.798   |
|    learning_rate   | 0.0003   |
|    n_updates       | 834466   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3044     |
|    fps             | 31       |
|    time_elapsed    | 27080    |
|    total_timesteps | 845012   |
| train/             |          |
|    actor_loss      | -0.0662  |
|    critic_loss     | 0.000487 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 2.97     |
|    learning_rate   | 0.0003   |
|    n_updates       | 835011   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3048     |
|    fps             | 31       |
|    time_elapsed    | 27097    |
|    total_timesteps | 845573   |
| train/             |          |
|    actor_loss      | -0.0404  |
|    critic_loss     | 0.000432 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 835572   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 3052     |
|    fps             | 31       |
|    time_elapsed    | 27118    |
|    total_timesteps | 846121   |
| train/             |          |
|    actor_loss      | -0.0418  |
|    critic_loss     | 0.000517 |
|    ent_coef        | 0.000248 |
|    ent_coef_loss   | -0.315   |
|    learning_rate   | 0.0003   |
|    n_updates       | 836120   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 0.79     |
| time/              |          |
|    episodes        | 3056     |
|    fps             | 31       |
|    time_elapsed    | 27141    |
|    total_timesteps | 846833   |
| train/             |          |
|    actor_loss      | -0.0152  |
|    critic_loss     | 0.000459 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 0.0003   |
|    n_updates       | 836832   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.78     |
| time/              |          |
|    episodes        | 3060     |
|    fps             | 31       |
|    time_elapsed    | 27162    |
|    total_timesteps | 847466   |
| train/             |          |
|    actor_loss      | -0.0197  |
|    critic_loss     | 0.000348 |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 0.0003   |
|    n_updates       | 837465   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 3064     |
|    fps             | 31       |
|    time_elapsed    | 27177    |
|    total_timesteps | 847972   |
| train/             |          |
|    actor_loss      | -0.0749  |
|    critic_loss     | 0.00038  |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | -0.146   |
|    learning_rate   | 0.0003   |
|    n_updates       | 837971   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 3068     |
|    fps             | 31       |
|    time_elapsed    | 27212    |
|    total_timesteps | 849473   |
| train/             |          |
|    actor_loss      | -0.0215  |
|    critic_loss     | 0.000661 |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 2.97     |
|    learning_rate   | 0.0003   |
|    n_updates       | 839472   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 3072     |
|    fps             | 31       |
|    time_elapsed    | 27227    |
|    total_timesteps | 849553   |
| train/             |          |
|    actor_loss      | -0.0354  |
|    critic_loss     | 0.00224  |
|    ent_coef        | 0.000265 |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 839552   |
---------------------------------
Eval num_timesteps=850000, episode_reward=0.40 +/- 0.49
Episode length: 302.70 +/- 241.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 303      |
|    mean_reward     | 0.4      |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -0.0699  |
|    critic_loss     | 0.000425 |
|    ent_coef        | 0.000264 |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 839999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 3076     |
|    fps             | 31       |
|    time_elapsed    | 27344    |
|    total_timesteps | 851055   |
| train/             |          |
|    actor_loss      | -0.0591  |
|    critic_loss     | 0.000803 |
|    ent_coef        | 0.00027  |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 0.0003   |
|    n_updates       | 841054   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 150       |
|    ep_rew_mean     | 0.76      |
| time/              |           |
|    episodes        | 3080      |
|    fps             | 31        |
|    time_elapsed    | 27353     |
|    total_timesteps | 851123    |
| train/             |           |
|    actor_loss      | -0.000928 |
|    critic_loss     | 0.000444  |
|    ent_coef        | 0.000269  |
|    ent_coef_loss   | 1.26      |
|    learning_rate   | 0.0003    |
|    n_updates       | 841122    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3084     |
|    fps             | 31       |
|    time_elapsed    | 27367    |
|    total_timesteps | 851374   |
| train/             |          |
|    actor_loss      | -0.0595  |
|    critic_loss     | 0.000417 |
|    ent_coef        | 0.000267 |
|    ent_coef_loss   | 2.05     |
|    learning_rate   | 0.0003   |
|    n_updates       | 841373   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3088     |
|    fps             | 31       |
|    time_elapsed    | 27391    |
|    total_timesteps | 851979   |
| train/             |          |
|    actor_loss      | -0.0132  |
|    critic_loss     | 0.000414 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 0.0003   |
|    n_updates       | 841978   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 3092     |
|    fps             | 31       |
|    time_elapsed    | 27404    |
|    total_timesteps | 852071   |
| train/             |          |
|    actor_loss      | -0.0659  |
|    critic_loss     | 0.000579 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 0.0003   |
|    n_updates       | 842070   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.77     |
| time/              |          |
|    episodes        | 3096     |
|    fps             | 31       |
|    time_elapsed    | 27427    |
|    total_timesteps | 852696   |
| train/             |          |
|    actor_loss      | -0.0349  |
|    critic_loss     | 0.00542  |
|    ent_coef        | 0.000262 |
|    ent_coef_loss   | 0.845    |
|    learning_rate   | 0.0003   |
|    n_updates       | 842695   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3100     |
|    fps             | 31       |
|    time_elapsed    | 27451    |
|    total_timesteps | 853698   |
| train/             |          |
|    actor_loss      | -0.0237  |
|    critic_loss     | 0.00144  |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -0.378   |
|    learning_rate   | 0.0003   |
|    n_updates       | 843697   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3104     |
|    fps             | 31       |
|    time_elapsed    | 27480    |
|    total_timesteps | 854285   |
| train/             |          |
|    actor_loss      | -0.0465  |
|    critic_loss     | 0.000323 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | -0.275   |
|    learning_rate   | 0.0003   |
|    n_updates       | 844284   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3108     |
|    fps             | 31       |
|    time_elapsed    | 27522    |
|    total_timesteps | 854882   |
| train/             |          |
|    actor_loss      | -0.0145  |
|    critic_loss     | 0.000527 |
|    ent_coef        | 0.000263 |
|    ent_coef_loss   | -0.913   |
|    learning_rate   | 0.0003   |
|    n_updates       | 844881   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 149       |
|    ep_rew_mean     | 0.75      |
| time/              |           |
|    episodes        | 3112      |
|    fps             | 31        |
|    time_elapsed    | 27539     |
|    total_timesteps | 855549    |
| train/             |           |
|    actor_loss      | -0.000463 |
|    critic_loss     | 0.000364  |
|    ent_coef        | 0.000272  |
|    ent_coef_loss   | -1.95     |
|    learning_rate   | 0.0003    |
|    n_updates       | 845548    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3116     |
|    fps             | 31       |
|    time_elapsed    | 27556    |
|    total_timesteps | 856196   |
| train/             |          |
|    actor_loss      | -0.0642  |
|    critic_loss     | 0.000585 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 0.0003   |
|    n_updates       | 846195   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 154      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3120     |
|    fps             | 31       |
|    time_elapsed    | 27583    |
|    total_timesteps | 856824   |
| train/             |          |
|    actor_loss      | -0.0475  |
|    critic_loss     | 0.000606 |
|    ent_coef        | 0.000268 |
|    ent_coef_loss   | 0.291    |
|    learning_rate   | 0.0003   |
|    n_updates       | 846823   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3124     |
|    fps             | 31       |
|    time_elapsed    | 27615    |
|    total_timesteps | 857895   |
| train/             |          |
|    actor_loss      | -0.0657  |
|    critic_loss     | 0.000466 |
|    ent_coef        | 0.000266 |
|    ent_coef_loss   | 0.521    |
|    learning_rate   | 0.0003   |
|    n_updates       | 847894   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3128     |
|    fps             | 31       |
|    time_elapsed    | 27639    |
|    total_timesteps | 858687   |
| train/             |          |
|    actor_loss      | 0.00909  |
|    critic_loss     | 0.000995 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | -3.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 848686   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3132     |
|    fps             | 31       |
|    time_elapsed    | 27672    |
|    total_timesteps | 859879   |
| train/             |          |
|    actor_loss      | -0.0364  |
|    critic_loss     | 0.00116  |
|    ent_coef        | 0.00028  |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 0.0003   |
|    n_updates       | 849878   |
---------------------------------
Eval num_timesteps=860000, episode_reward=0.80 +/- 0.40
Episode length: 165.70 +/- 199.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 166      |
|    mean_reward     | 0.8      |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -0.0185  |
|    critic_loss     | 0.000711 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.0003   |
|    n_updates       | 849999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3136     |
|    fps             | 31       |
|    time_elapsed    | 27719    |
|    total_timesteps | 860038   |
| train/             |          |
|    actor_loss      | -0.0219  |
|    critic_loss     | 0.00101  |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | -0.269   |
|    learning_rate   | 0.0003   |
|    n_updates       | 850037   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3140     |
|    fps             | 31       |
|    time_elapsed    | 27756    |
|    total_timesteps | 861094   |
| train/             |          |
|    actor_loss      | -0.0425  |
|    critic_loss     | 0.000369 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | 0.0416   |
|    learning_rate   | 0.0003   |
|    n_updates       | 851093   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3144     |
|    fps             | 31       |
|    time_elapsed    | 27776    |
|    total_timesteps | 861670   |
| train/             |          |
|    actor_loss      | -0.0631  |
|    critic_loss     | 0.000545 |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 851669   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3148     |
|    fps             | 31       |
|    time_elapsed    | 27806    |
|    total_timesteps | 862335   |
| train/             |          |
|    actor_loss      | -0.0543  |
|    critic_loss     | 0.00105  |
|    ent_coef        | 0.000284 |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 0.0003   |
|    n_updates       | 852334   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3152     |
|    fps             | 31       |
|    time_elapsed    | 27822    |
|    total_timesteps | 862739   |
| train/             |          |
|    actor_loss      | -0.0801  |
|    critic_loss     | 0.000681 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 0.0003   |
|    n_updates       | 852738   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3156     |
|    fps             | 31       |
|    time_elapsed    | 27847    |
|    total_timesteps | 863327   |
| train/             |          |
|    actor_loss      | -0.0614  |
|    critic_loss     | 0.000704 |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | 2.8      |
|    learning_rate   | 0.0003   |
|    n_updates       | 853326   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3160     |
|    fps             | 31       |
|    time_elapsed    | 27863    |
|    total_timesteps | 863902   |
| train/             |          |
|    actor_loss      | -0.0297  |
|    critic_loss     | 0.000588 |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | 0.51     |
|    learning_rate   | 0.0003   |
|    n_updates       | 853901   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3164     |
|    fps             | 31       |
|    time_elapsed    | 27898    |
|    total_timesteps | 865048   |
| train/             |          |
|    actor_loss      | -0.0058  |
|    critic_loss     | 0.00187  |
|    ent_coef        | 0.000287 |
|    ent_coef_loss   | -3.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 855047   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3168     |
|    fps             | 31       |
|    time_elapsed    | 27905    |
|    total_timesteps | 865077   |
| train/             |          |
|    actor_loss      | -0.0176  |
|    critic_loss     | 0.000483 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 855076   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3172     |
|    fps             | 31       |
|    time_elapsed    | 27939    |
|    total_timesteps | 866514   |
| train/             |          |
|    actor_loss      | -0.0408  |
|    critic_loss     | 0.000393 |
|    ent_coef        | 0.000285 |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 0.0003   |
|    n_updates       | 856513   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3176     |
|    fps             | 31       |
|    time_elapsed    | 27955    |
|    total_timesteps | 867200   |
| train/             |          |
|    actor_loss      | -0.0523  |
|    critic_loss     | 0.000794 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.0003   |
|    n_updates       | 857199   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3180     |
|    fps             | 31       |
|    time_elapsed    | 27964    |
|    total_timesteps | 867356   |
| train/             |          |
|    actor_loss      | -0.0112  |
|    critic_loss     | 0.000895 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 0.0003   |
|    n_updates       | 857355   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 3184     |
|    fps             | 31       |
|    time_elapsed    | 27987    |
|    total_timesteps | 868285   |
| train/             |          |
|    actor_loss      | -0.0158  |
|    critic_loss     | 0.000634 |
|    ent_coef        | 0.000271 |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 858284   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 3188     |
|    fps             | 31       |
|    time_elapsed    | 28012    |
|    total_timesteps | 868817   |
| train/             |          |
|    actor_loss      | -0.0709  |
|    critic_loss     | 0.000588 |
|    ent_coef        | 0.000273 |
|    ent_coef_loss   | 4.89     |
|    learning_rate   | 0.0003   |
|    n_updates       | 858816   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3192     |
|    fps             | 31       |
|    time_elapsed    | 28031    |
|    total_timesteps | 869373   |
| train/             |          |
|    actor_loss      | -0.0613  |
|    critic_loss     | 0.00237  |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | 5.12     |
|    learning_rate   | 0.0003   |
|    n_updates       | 859372   |
---------------------------------
Eval num_timesteps=870000, episode_reward=0.70 +/- 0.46
Episode length: 153.70 +/- 226.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 154      |
|    mean_reward     | 0.7      |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -0.0362  |
|    critic_loss     | 0.000339 |
|    ent_coef        | 0.000282 |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 0.0003   |
|    n_updates       | 859999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3196     |
|    fps             | 30       |
|    time_elapsed    | 28119    |
|    total_timesteps | 870376   |
| train/             |          |
|    actor_loss      | -0.0464  |
|    critic_loss     | 0.000374 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | 0.81     |
|    learning_rate   | 0.0003   |
|    n_updates       | 860375   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3200     |
|    fps             | 30       |
|    time_elapsed    | 28150    |
|    total_timesteps | 871417   |
| train/             |          |
|    actor_loss      | -0.0948  |
|    critic_loss     | 0.000603 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 861416   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 0.72     |
| time/              |          |
|    episodes        | 3204     |
|    fps             | 30       |
|    time_elapsed    | 28177    |
|    total_timesteps | 872469   |
| train/             |          |
|    actor_loss      | -0.0458  |
|    critic_loss     | 0.000772 |
|    ent_coef        | 0.000278 |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 862468   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3208     |
|    fps             | 30       |
|    time_elapsed    | 28187    |
|    total_timesteps | 872574   |
| train/             |          |
|    actor_loss      | -0.0841  |
|    critic_loss     | 0.000748 |
|    ent_coef        | 0.000279 |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 0.0003   |
|    n_updates       | 862573   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 0.73     |
| time/              |          |
|    episodes        | 3212     |
|    fps             | 30       |
|    time_elapsed    | 28205    |
|    total_timesteps | 873204   |
| train/             |          |
|    actor_loss      | -0.0413  |
|    critic_loss     | 0.00051  |
|    ent_coef        | 0.000276 |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 863203   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 172      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 3216     |
|    fps             | 30       |
|    time_elapsed    | 28214    |
|    total_timesteps | 873360   |
| train/             |          |
|    actor_loss      | -0.033   |
|    critic_loss     | 0.000449 |
|    ent_coef        | 0.000277 |
|    ent_coef_loss   | 0.516    |
|    learning_rate   | 0.0003   |
|    n_updates       | 863359   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 0.75     |
| time/              |          |
|    episodes        | 3220     |
|    fps             | 30       |
|    time_elapsed    | 28227    |
|    total_timesteps | 873440   |
| train/             |          |
|    actor_loss      | -0.0287  |
|    critic_loss     | 0.000301 |
|    ent_coef        | 0.000275 |
|    ent_coef_loss   | 1.82     |
|    learning_rate   | 0.0003   |
|    n_updates       | 863439   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 0.76     |
| time/              |          |
|    episodes        | 3224     |
|    fps             | 30       |
|    time_elapsed    | 28251    |
|    total_timesteps | 874029   |
| train/             |          |
|    actor_loss      | -0.0284  |
|    critic_loss     | 0.000522 |
|    ent_coef        | 0.00026  |
|    ent_coef_loss   | -0.542   |
|    learning_rate   | 0.0003   |
|    n_updates       | 864028   |
---------------------------------
