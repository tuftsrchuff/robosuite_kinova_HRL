What policy would you like to train?
	1. Reach-pick
	2. Pick
	3. Drop
	4. Reach-drop
	5. All but Reach-drop
Training for 500000 steps
Training ReachPick
Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to ./logs/SAC_8
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 4        |
|    fps             | 22       |
|    time_elapsed    | 88       |
|    total_timesteps | 2000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 8        |
|    fps             | 35       |
|    time_elapsed    | 113      |
|    total_timesteps | 4000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 0.167    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 33       |
|    time_elapsed    | 151      |
|    total_timesteps | 5004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 438      |
|    ep_rew_mean     | 0.125    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 34       |
|    time_elapsed    | 203      |
|    total_timesteps | 7004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 33       |
|    time_elapsed    | 267      |
|    total_timesteps | 9004     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 10000    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 458      |
|    ep_rew_mean     | 0.0833   |
| time/              |          |
|    episodes        | 24       |
|    fps             | 17       |
|    time_elapsed    | 612      |
|    total_timesteps | 11004    |
| train/             |          |
|    actor_loss      | -13      |
|    critic_loss     | 0.0324   |
|    ent_coef        | 0.74     |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 0.0003   |
|    n_updates       | 1003     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 0.0714   |
| time/              |          |
|    episodes        | 28       |
|    fps             | 18       |
|    time_elapsed    | 704      |
|    total_timesteps | 13004    |
| train/             |          |
|    actor_loss      | -23.3    |
|    critic_loss     | 0.0486   |
|    ent_coef        | 0.406    |
|    ent_coef_loss   | -6.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 3003     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 20       |
|    time_elapsed    | 749      |
|    total_timesteps | 15004    |
| train/             |          |
|    actor_loss      | -27.4    |
|    critic_loss     | 0.0649   |
|    ent_coef        | 0.224    |
|    ent_coef_loss   | -9.81    |
|    learning_rate   | 0.0003   |
|    n_updates       | 5003     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 472      |
|    ep_rew_mean     | 0.0556   |
| time/              |          |
|    episodes        | 36       |
|    fps             | 20       |
|    time_elapsed    | 834      |
|    total_timesteps | 17004    |
| train/             |          |
|    actor_loss      | -27.2    |
|    critic_loss     | 0.142    |
|    ent_coef        | 0.124    |
|    ent_coef_loss   | -12.9    |
|    learning_rate   | 0.0003   |
|    n_updates       | 7003     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 20       |
|    time_elapsed    | 911      |
|    total_timesteps | 19004    |
| train/             |          |
|    actor_loss      | -26.7    |
|    critic_loss     | 0.135    |
|    ent_coef        | 0.071    |
|    ent_coef_loss   | -13.6    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9003     |
---------------------------------
Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -26      |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.0543   |
|    ent_coef_loss   | -12.7    |
|    learning_rate   | 0.0003   |
|    n_updates       | 9999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.0455   |
| time/              |          |
|    episodes        | 44       |
|    fps             | 19       |
|    time_elapsed    | 1063     |
|    total_timesteps | 21004    |
| train/             |          |
|    actor_loss      | -25.2    |
|    critic_loss     | 0.162    |
|    ent_coef        | 0.0419   |
|    ent_coef_loss   | -11.7    |
|    learning_rate   | 0.0003   |
|    n_updates       | 11003    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0417   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 20       |
|    time_elapsed    | 1112     |
|    total_timesteps | 23004    |
| train/             |          |
|    actor_loss      | -24.1    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.0254   |
|    ent_coef_loss   | -9.9     |
|    learning_rate   | 0.0003   |
|    n_updates       | 13003    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.0385   |
| time/              |          |
|    episodes        | 52       |
|    fps             | 20       |
|    time_elapsed    | 1201     |
|    total_timesteps | 25004    |
| train/             |          |
|    actor_loss      | -23.6    |
|    critic_loss     | 0.16     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -9.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 15003    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.0536   |
| time/              |          |
|    episodes        | 56       |
|    fps             | 21       |
|    time_elapsed    | 1240     |
|    total_timesteps | 26521    |
| train/             |          |
|    actor_loss      | -22.3    |
|    critic_loss     | 0.141    |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -4.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 16520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 21       |
|    time_elapsed    | 1308     |
|    total_timesteps | 28521    |
| train/             |          |
|    actor_loss      | -21.8    |
|    critic_loss     | 0.187    |
|    ent_coef        | 0.00917  |
|    ent_coef_loss   | -1.57    |
|    learning_rate   | 0.0003   |
|    n_updates       | 18520    |
---------------------------------
Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -20.9    |
|    critic_loss     | 0.536    |
|    ent_coef        | 0.00897  |
|    ent_coef_loss   | -0.882   |
|    learning_rate   | 0.0003   |
|    n_updates       | 19999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 0.0469   |
| time/              |          |
|    episodes        | 64       |
|    fps             | 19       |
|    time_elapsed    | 1594     |
|    total_timesteps | 30521    |
| train/             |          |
|    actor_loss      | -20.6    |
|    critic_loss     | 1.33     |
|    ent_coef        | 0.00908  |
|    ent_coef_loss   | 1.42     |
|    learning_rate   | 0.0003   |
|    n_updates       | 20520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.0441   |
| time/              |          |
|    episodes        | 68       |
|    fps             | 19       |
|    time_elapsed    | 1669     |
|    total_timesteps | 32521    |
| train/             |          |
|    actor_loss      | -19.1    |
|    critic_loss     | 0.141    |
|    ent_coef        | 0.00928  |
|    ent_coef_loss   | -0.0123  |
|    learning_rate   | 0.0003   |
|    n_updates       | 22520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 479      |
|    ep_rew_mean     | 0.0417   |
| time/              |          |
|    episodes        | 72       |
|    fps             | 19       |
|    time_elapsed    | 1776     |
|    total_timesteps | 34521    |
| train/             |          |
|    actor_loss      | -18.9    |
|    critic_loss     | 1.06     |
|    ent_coef        | 0.00913  |
|    ent_coef_loss   | -0.806   |
|    learning_rate   | 0.0003   |
|    n_updates       | 24520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.0395   |
| time/              |          |
|    episodes        | 76       |
|    fps             | 19       |
|    time_elapsed    | 1879     |
|    total_timesteps | 36521    |
| train/             |          |
|    actor_loss      | -18.3    |
|    critic_loss     | 0.0902   |
|    ent_coef        | 0.00859  |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 0.0003   |
|    n_updates       | 26520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 470      |
|    ep_rew_mean     | 0.0625   |
| time/              |          |
|    episodes        | 80       |
|    fps             | 19       |
|    time_elapsed    | 1909     |
|    total_timesteps | 37594    |
| train/             |          |
|    actor_loss      | -17.4    |
|    critic_loss     | 0.0853   |
|    ent_coef        | 0.0082   |
|    ent_coef_loss   | -0.669   |
|    learning_rate   | 0.0003   |
|    n_updates       | 27593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 0.0595   |
| time/              |          |
|    episodes        | 84       |
|    fps             | 19       |
|    time_elapsed    | 1995     |
|    total_timesteps | 39594    |
| train/             |          |
|    actor_loss      | -16.5    |
|    critic_loss     | 0.11     |
|    ent_coef        | 0.00783  |
|    ent_coef_loss   | -0.858   |
|    learning_rate   | 0.0003   |
|    n_updates       | 29593    |
---------------------------------
Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -16.3    |
|    critic_loss     | 0.0969   |
|    ent_coef        | 0.00745  |
|    ent_coef_loss   | -2.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.0568   |
| time/              |          |
|    episodes        | 88       |
|    fps             | 18       |
|    time_elapsed    | 2208     |
|    total_timesteps | 41594    |
| train/             |          |
|    actor_loss      | -15.5    |
|    critic_loss     | 0.0584   |
|    ent_coef        | 0.00683  |
|    ent_coef_loss   | -0.16    |
|    learning_rate   | 0.0003   |
|    n_updates       | 31593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 0.0543   |
| time/              |          |
|    episodes        | 92       |
|    fps             | 19       |
|    time_elapsed    | 2282     |
|    total_timesteps | 43594    |
| train/             |          |
|    actor_loss      | -14.7    |
|    critic_loss     | 0.0577   |
|    ent_coef        | 0.00653  |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 33593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 475      |
|    ep_rew_mean     | 0.0521   |
| time/              |          |
|    episodes        | 96       |
|    fps             | 19       |
|    time_elapsed    | 2328     |
|    total_timesteps | 45594    |
| train/             |          |
|    actor_loss      | -13.8    |
|    critic_loss     | 0.0572   |
|    ent_coef        | 0.00601  |
|    ent_coef_loss   | 0.347    |
|    learning_rate   | 0.0003   |
|    n_updates       | 35593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 19       |
|    time_elapsed    | 2386     |
|    total_timesteps | 47594    |
| train/             |          |
|    actor_loss      | -12.7    |
|    critic_loss     | 1.37     |
|    ent_coef        | 0.0056   |
|    ent_coef_loss   | 2        |
|    learning_rate   | 0.0003   |
|    n_updates       | 37593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 20       |
|    time_elapsed    | 2427     |
|    total_timesteps | 49594    |
| train/             |          |
|    actor_loss      | -12.1    |
|    critic_loss     | 0.0336   |
|    ent_coef        | 0.00496  |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 0.0003   |
|    n_updates       | 39593    |
---------------------------------
Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -12      |
|    critic_loss     | 0.0397   |
|    ent_coef        | 0.00478  |
|    ent_coef_loss   | -0.106   |
|    learning_rate   | 0.0003   |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 19       |
|    time_elapsed    | 2655     |
|    total_timesteps | 51594    |
| train/             |          |
|    actor_loss      | -11.2    |
|    critic_loss     | 0.0313   |
|    ent_coef        | 0.00442  |
|    ent_coef_loss   | 0.391    |
|    learning_rate   | 0.0003   |
|    n_updates       | 41593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 19       |
|    time_elapsed    | 2715     |
|    total_timesteps | 53145    |
| train/             |          |
|    actor_loss      | -10.6    |
|    critic_loss     | 0.0295   |
|    ent_coef        | 0.0043   |
|    ent_coef_loss   | 0.496    |
|    learning_rate   | 0.0003   |
|    n_updates       | 43144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 19       |
|    time_elapsed    | 2761     |
|    total_timesteps | 55145    |
| train/             |          |
|    actor_loss      | -10.1    |
|    critic_loss     | 0.039    |
|    ent_coef        | 0.00405  |
|    ent_coef_loss   | -0.378   |
|    learning_rate   | 0.0003   |
|    n_updates       | 45144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 20       |
|    time_elapsed    | 2815     |
|    total_timesteps | 57145    |
| train/             |          |
|    actor_loss      | -9.26    |
|    critic_loss     | 0.0275   |
|    ent_coef        | 0.00357  |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.0003   |
|    n_updates       | 47144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 20       |
|    time_elapsed    | 2891     |
|    total_timesteps | 59145    |
| train/             |          |
|    actor_loss      | -8.66    |
|    critic_loss     | 0.28     |
|    ent_coef        | 0.00341  |
|    ent_coef_loss   | -0.496   |
|    learning_rate   | 0.0003   |
|    n_updates       | 49144    |
---------------------------------
Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -8.37    |
|    critic_loss     | 0.019    |
|    ent_coef        | 0.00338  |
|    ent_coef_loss   | -0.845   |
|    learning_rate   | 0.0003   |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 19       |
|    time_elapsed    | 3081     |
|    total_timesteps | 61145    |
| train/             |          |
|    actor_loss      | -8.03    |
|    critic_loss     | 0.144    |
|    ent_coef        | 0.0034   |
|    ent_coef_loss   | 1.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 51144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 20       |
|    time_elapsed    | 3154     |
|    total_timesteps | 63145    |
| train/             |          |
|    actor_loss      | -7.86    |
|    critic_loss     | 0.0149   |
|    ent_coef        | 0.00377  |
|    ent_coef_loss   | 0.0817   |
|    learning_rate   | 0.0003   |
|    n_updates       | 53144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 20       |
|    time_elapsed    | 3203     |
|    total_timesteps | 65145    |
| train/             |          |
|    actor_loss      | -7.17    |
|    critic_loss     | 0.297    |
|    ent_coef        | 0.00382  |
|    ent_coef_loss   | 3.11     |
|    learning_rate   | 0.0003   |
|    n_updates       | 55144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 481      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 20       |
|    time_elapsed    | 3280     |
|    total_timesteps | 67145    |
| train/             |          |
|    actor_loss      | -7.02    |
|    critic_loss     | 0.0176   |
|    ent_coef        | 0.00397  |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 0.0003   |
|    n_updates       | 57144    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 20       |
|    time_elapsed    | 3346     |
|    total_timesteps | 68959    |
| train/             |          |
|    actor_loss      | -7.14    |
|    critic_loss     | 0.0143   |
|    ent_coef        | 0.00386  |
|    ent_coef_loss   | 2.2      |
|    learning_rate   | 0.0003   |
|    n_updates       | 58958    |
---------------------------------
Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -6.82    |
|    critic_loss     | 0.0138   |
|    ent_coef        | 0.00384  |
|    ent_coef_loss   | -0.989   |
|    learning_rate   | 0.0003   |
|    n_updates       | 59999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 19       |
|    time_elapsed    | 3679     |
|    total_timesteps | 70959    |
| train/             |          |
|    actor_loss      | -6.71    |
|    critic_loss     | 0.021    |
|    ent_coef        | 0.00403  |
|    ent_coef_loss   | -0.745   |
|    learning_rate   | 0.0003   |
|    n_updates       | 60958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 480      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 19       |
|    time_elapsed    | 3765     |
|    total_timesteps | 72959    |
| train/             |          |
|    actor_loss      | -7.07    |
|    critic_loss     | 0.0286   |
|    ent_coef        | 0.00397  |
|    ent_coef_loss   | -0.147   |
|    learning_rate   | 0.0003   |
|    n_updates       | 62958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 19       |
|    time_elapsed    | 3823     |
|    total_timesteps | 74959    |
| train/             |          |
|    actor_loss      | -6.67    |
|    critic_loss     | 0.0247   |
|    ent_coef        | 0.0042   |
|    ent_coef_loss   | -0.0344  |
|    learning_rate   | 0.0003   |
|    n_updates       | 64958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 19       |
|    time_elapsed    | 3862     |
|    total_timesteps | 76959    |
| train/             |          |
|    actor_loss      | -6.72    |
|    critic_loss     | 0.1      |
|    ent_coef        | 0.00423  |
|    ent_coef_loss   | 0.868    |
|    learning_rate   | 0.0003   |
|    n_updates       | 66958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 20       |
|    time_elapsed    | 3932     |
|    total_timesteps | 78959    |
| train/             |          |
|    actor_loss      | -6.74    |
|    critic_loss     | 0.0144   |
|    ent_coef        | 0.00425  |
|    ent_coef_loss   | -0.35    |
|    learning_rate   | 0.0003   |
|    n_updates       | 68958    |
---------------------------------
Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -6.97    |
|    critic_loss     | 0.0159   |
|    ent_coef        | 0.00416  |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 69999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 19       |
|    time_elapsed    | 4117     |
|    total_timesteps | 80959    |
| train/             |          |
|    actor_loss      | -6.77    |
|    critic_loss     | 0.278    |
|    ent_coef        | 0.00397  |
|    ent_coef_loss   | -0.646   |
|    learning_rate   | 0.0003   |
|    n_updates       | 70958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 19       |
|    time_elapsed    | 4224     |
|    total_timesteps | 82959    |
| train/             |          |
|    actor_loss      | -6.8     |
|    critic_loss     | 0.133    |
|    ent_coef        | 0.00416  |
|    ent_coef_loss   | 2.56     |
|    learning_rate   | 0.0003   |
|    n_updates       | 72958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 19       |
|    time_elapsed    | 4272     |
|    total_timesteps | 84959    |
| train/             |          |
|    actor_loss      | -6.62    |
|    critic_loss     | 0.0154   |
|    ent_coef        | 0.00368  |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 0.0003   |
|    n_updates       | 74958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 20       |
|    time_elapsed    | 4327     |
|    total_timesteps | 86959    |
| train/             |          |
|    actor_loss      | -6.3     |
|    critic_loss     | 0.0575   |
|    ent_coef        | 0.00335  |
|    ent_coef_loss   | 2.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 76958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 20       |
|    time_elapsed    | 4367     |
|    total_timesteps | 88959    |
| train/             |          |
|    actor_loss      | -6.15    |
|    critic_loss     | 0.0757   |
|    ent_coef        | 0.00265  |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 78958    |
---------------------------------
Eval num_timesteps=90000, episode_reward=0.10 +/- 0.30
Episode length: 452.50 +/- 142.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 452      |
|    mean_reward     | 0.1      |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -5.99    |
|    critic_loss     | 0.00612  |
|    ent_coef        | 0.00257  |
|    ent_coef_loss   | -0.455   |
|    learning_rate   | 0.0003   |
|    n_updates       | 79999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 19       |
|    time_elapsed    | 4576     |
|    total_timesteps | 90959    |
| train/             |          |
|    actor_loss      | -5.79    |
|    critic_loss     | 0.108    |
|    ent_coef        | 0.00247  |
|    ent_coef_loss   | -0.614   |
|    learning_rate   | 0.0003   |
|    n_updates       | 80958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 19       |
|    time_elapsed    | 4650     |
|    total_timesteps | 92959    |
| train/             |          |
|    actor_loss      | -5.45    |
|    critic_loss     | 0.0751   |
|    ent_coef        | 0.00208  |
|    ent_coef_loss   | 1.72     |
|    learning_rate   | 0.0003   |
|    n_updates       | 82958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 196      |
|    fps             | 20       |
|    time_elapsed    | 4716     |
|    total_timesteps | 94959    |
| train/             |          |
|    actor_loss      | -5.23    |
|    critic_loss     | 0.116    |
|    ent_coef        | 0.00207  |
|    ent_coef_loss   | 0.0232   |
|    learning_rate   | 0.0003   |
|    n_updates       | 84958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 200      |
|    fps             | 20       |
|    time_elapsed    | 4774     |
|    total_timesteps | 96959    |
| train/             |          |
|    actor_loss      | -5.03    |
|    critic_loss     | 0.00499  |
|    ent_coef        | 0.00189  |
|    ent_coef_loss   | -3.92    |
|    learning_rate   | 0.0003   |
|    n_updates       | 86958    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 20       |
|    time_elapsed    | 4851     |
|    total_timesteps | 98959    |
| train/             |          |
|    actor_loss      | -4.71    |
|    critic_loss     | 0.00725  |
|    ent_coef        | 0.00161  |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 0.0003   |
|    n_updates       | 88958    |
---------------------------------
Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -4.54    |
|    critic_loss     | 0.0965   |
|    ent_coef        | 0.00165  |
|    ent_coef_loss   | -2.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 89999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 19       |
|    time_elapsed    | 5045     |
|    total_timesteps | 100616   |
| train/             |          |
|    actor_loss      | -4.47    |
|    critic_loss     | 0.0126   |
|    ent_coef        | 0.00154  |
|    ent_coef_loss   | 3.39     |
|    learning_rate   | 0.0003   |
|    n_updates       | 90615    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 20       |
|    time_elapsed    | 5117     |
|    total_timesteps | 102506   |
| train/             |          |
|    actor_loss      | -4.11    |
|    critic_loss     | 0.0629   |
|    ent_coef        | 0.00149  |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 0.0003   |
|    n_updates       | 92505    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 20       |
|    time_elapsed    | 5146     |
|    total_timesteps | 104506   |
| train/             |          |
|    actor_loss      | -3.91    |
|    critic_loss     | 0.00668  |
|    ent_coef        | 0.00131  |
|    ent_coef_loss   | 0.864    |
|    learning_rate   | 0.0003   |
|    n_updates       | 94505    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 20       |
|    time_elapsed    | 5203     |
|    total_timesteps | 106506   |
| train/             |          |
|    actor_loss      | -3.63    |
|    critic_loss     | 0.00412  |
|    ent_coef        | 0.0012   |
|    ent_coef_loss   | 0.695    |
|    learning_rate   | 0.0003   |
|    n_updates       | 96505    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 20       |
|    time_elapsed    | 5256     |
|    total_timesteps | 108506   |
| train/             |          |
|    actor_loss      | -3.45    |
|    critic_loss     | 0.00423  |
|    ent_coef        | 0.00119  |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.0003   |
|    n_updates       | 98505    |
---------------------------------
Eval num_timesteps=110000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -3.28    |
|    critic_loss     | 0.0381   |
|    ent_coef        | 0.0011   |
|    ent_coef_loss   | 4.02     |
|    learning_rate   | 0.0003   |
|    n_updates       | 99999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 20       |
|    time_elapsed    | 5524     |
|    total_timesteps | 110506   |
| train/             |          |
|    actor_loss      | -3.19    |
|    critic_loss     | 0.00255  |
|    ent_coef        | 0.00123  |
|    ent_coef_loss   | 0.57     |
|    learning_rate   | 0.0003   |
|    n_updates       | 100505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 20       |
|    time_elapsed    | 5574     |
|    total_timesteps | 112506   |
| train/             |          |
|    actor_loss      | -3.04    |
|    critic_loss     | 0.00234  |
|    ent_coef        | 0.00127  |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 102505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 20       |
|    time_elapsed    | 5644     |
|    total_timesteps | 114506   |
| train/             |          |
|    actor_loss      | -2.88    |
|    critic_loss     | 0.00802  |
|    ent_coef        | 0.0012   |
|    ent_coef_loss   | 0.655    |
|    learning_rate   | 0.0003   |
|    n_updates       | 104505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 20       |
|    time_elapsed    | 5727     |
|    total_timesteps | 116506   |
| train/             |          |
|    actor_loss      | -2.65    |
|    critic_loss     | 0.032    |
|    ent_coef        | 0.0012   |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 0.0003   |
|    n_updates       | 106505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 20       |
|    time_elapsed    | 5813     |
|    total_timesteps | 118506   |
| train/             |          |
|    actor_loss      | -2.58    |
|    critic_loss     | 0.00246  |
|    ent_coef        | 0.00118  |
|    ent_coef_loss   | -0.715   |
|    learning_rate   | 0.0003   |
|    n_updates       | 108505   |
---------------------------------
Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -2.62    |
|    critic_loss     | 0.00208  |
|    ent_coef        | 0.00126  |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 0.0003   |
|    n_updates       | 109999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 19       |
|    time_elapsed    | 6061     |
|    total_timesteps | 120506   |
| train/             |          |
|    actor_loss      | -2.51    |
|    critic_loss     | 0.00393  |
|    ent_coef        | 0.0014   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 0.0003   |
|    n_updates       | 110505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 252      |
|    fps             | 19       |
|    time_elapsed    | 6133     |
|    total_timesteps | 122506   |
| train/             |          |
|    actor_loss      | -2.47    |
|    critic_loss     | 0.0937   |
|    ent_coef        | 0.0015   |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.0003   |
|    n_updates       | 112505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 256      |
|    fps             | 20       |
|    time_elapsed    | 6188     |
|    total_timesteps | 124506   |
| train/             |          |
|    actor_loss      | -2.41    |
|    critic_loss     | 0.0581   |
|    ent_coef        | 0.00148  |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 114505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 260      |
|    fps             | 20       |
|    time_elapsed    | 6250     |
|    total_timesteps | 126506   |
| train/             |          |
|    actor_loss      | -2.59    |
|    critic_loss     | 0.00201  |
|    ent_coef        | 0.00145  |
|    ent_coef_loss   | -0.328   |
|    learning_rate   | 0.0003   |
|    n_updates       | 116505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 264      |
|    fps             | 20       |
|    time_elapsed    | 6350     |
|    total_timesteps | 128506   |
| train/             |          |
|    actor_loss      | -2.48    |
|    critic_loss     | 0.00259  |
|    ent_coef        | 0.00138  |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 0.0003   |
|    n_updates       | 118505   |
---------------------------------
Eval num_timesteps=130000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -2.5     |
|    critic_loss     | 0.0025   |
|    ent_coef        | 0.00129  |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 0.0003   |
|    n_updates       | 119999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 268      |
|    fps             | 19       |
|    time_elapsed    | 6559     |
|    total_timesteps | 130506   |
| train/             |          |
|    actor_loss      | -2.37    |
|    critic_loss     | 0.0363   |
|    ent_coef        | 0.00123  |
|    ent_coef_loss   | 0.587    |
|    learning_rate   | 0.0003   |
|    n_updates       | 120505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 272      |
|    fps             | 19       |
|    time_elapsed    | 6655     |
|    total_timesteps | 132506   |
| train/             |          |
|    actor_loss      | -2.39    |
|    critic_loss     | 0.00279  |
|    ent_coef        | 0.0011   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 0.0003   |
|    n_updates       | 122505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 276      |
|    fps             | 19       |
|    time_elapsed    | 6752     |
|    total_timesteps | 134506   |
| train/             |          |
|    actor_loss      | -2.28    |
|    critic_loss     | 0.00209  |
|    ent_coef        | 0.000982 |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 0.0003   |
|    n_updates       | 124505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 19       |
|    time_elapsed    | 6852     |
|    total_timesteps | 136506   |
| train/             |          |
|    actor_loss      | -2.21    |
|    critic_loss     | 0.028    |
|    ent_coef        | 0.000918 |
|    ent_coef_loss   | -0.369   |
|    learning_rate   | 0.0003   |
|    n_updates       | 126505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 19       |
|    time_elapsed    | 6963     |
|    total_timesteps | 138506   |
| train/             |          |
|    actor_loss      | -2.04    |
|    critic_loss     | 0.0107   |
|    ent_coef        | 0.000771 |
|    ent_coef_loss   | -1.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 128505   |
---------------------------------
Eval num_timesteps=140000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -1.9     |
|    critic_loss     | 0.0012   |
|    ent_coef        | 0.000768 |
|    ent_coef_loss   | -0.437   |
|    learning_rate   | 0.0003   |
|    n_updates       | 129999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 19       |
|    time_elapsed    | 7215     |
|    total_timesteps | 140506   |
| train/             |          |
|    actor_loss      | -1.84    |
|    critic_loss     | 0.00136  |
|    ent_coef        | 0.000717 |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 130505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 19       |
|    time_elapsed    | 7291     |
|    total_timesteps | 142506   |
| train/             |          |
|    actor_loss      | -1.73    |
|    critic_loss     | 0.00317  |
|    ent_coef        | 0.000662 |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 0.0003   |
|    n_updates       | 132505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 19       |
|    time_elapsed    | 7376     |
|    total_timesteps | 144506   |
| train/             |          |
|    actor_loss      | -1.71    |
|    critic_loss     | 0.00198  |
|    ent_coef        | 0.000628 |
|    ent_coef_loss   | -0.0601  |
|    learning_rate   | 0.0003   |
|    n_updates       | 134505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 19       |
|    time_elapsed    | 7414     |
|    total_timesteps | 146506   |
| train/             |          |
|    actor_loss      | -1.59    |
|    critic_loss     | 0.00127  |
|    ent_coef        | 0.000661 |
|    ent_coef_loss   | -0.599   |
|    learning_rate   | 0.0003   |
|    n_updates       | 136505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 495      |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 19       |
|    time_elapsed    | 7480     |
|    total_timesteps | 148506   |
| train/             |          |
|    actor_loss      | -1.52    |
|    critic_loss     | 0.00126  |
|    ent_coef        | 0.000869 |
|    ent_coef_loss   | -3.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 138505   |
---------------------------------
Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -1.44    |
|    critic_loss     | 0.0113   |
|    ent_coef        | 0.000783 |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 139999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 19       |
|    time_elapsed    | 7782     |
|    total_timesteps | 150506   |
| train/             |          |
|    actor_loss      | -1.49    |
|    critic_loss     | 0.00731  |
|    ent_coef        | 0.000762 |
|    ent_coef_loss   | -2.89    |
|    learning_rate   | 0.0003   |
|    n_updates       | 140505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 312      |
|    fps             | 19       |
|    time_elapsed    | 7818     |
|    total_timesteps | 152506   |
| train/             |          |
|    actor_loss      | -1.34    |
|    critic_loss     | 0.00673  |
|    ent_coef        | 0.000705 |
|    ent_coef_loss   | -0.0141  |
|    learning_rate   | 0.0003   |
|    n_updates       | 142505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 316      |
|    fps             | 19       |
|    time_elapsed    | 7879     |
|    total_timesteps | 154506   |
| train/             |          |
|    actor_loss      | -1.34    |
|    critic_loss     | 0.00104  |
|    ent_coef        | 0.000696 |
|    ent_coef_loss   | 0.822    |
|    learning_rate   | 0.0003   |
|    n_updates       | 144505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 320      |
|    fps             | 19       |
|    time_elapsed    | 7934     |
|    total_timesteps | 156506   |
| train/             |          |
|    actor_loss      | -1.25    |
|    critic_loss     | 0.000745 |
|    ent_coef        | 0.000597 |
|    ent_coef_loss   | 1.91     |
|    learning_rate   | 0.0003   |
|    n_updates       | 146505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 324      |
|    fps             | 19       |
|    time_elapsed    | 7977     |
|    total_timesteps | 158506   |
| train/             |          |
|    actor_loss      | -1.19    |
|    critic_loss     | 0.000526 |
|    ent_coef        | 0.000563 |
|    ent_coef_loss   | -0.26    |
|    learning_rate   | 0.0003   |
|    n_updates       | 148505   |
---------------------------------
Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -1.13    |
|    critic_loss     | 0.000536 |
|    ent_coef        | 0.000517 |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 0.0003   |
|    n_updates       | 149999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 328      |
|    fps             | 19       |
|    time_elapsed    | 8240     |
|    total_timesteps | 160506   |
| train/             |          |
|    actor_loss      | -1.14    |
|    critic_loss     | 0.00182  |
|    ent_coef        | 0.000515 |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 0.0003   |
|    n_updates       | 150505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 332      |
|    fps             | 19       |
|    time_elapsed    | 8298     |
|    total_timesteps | 162506   |
| train/             |          |
|    actor_loss      | -1.05    |
|    critic_loss     | 0.000718 |
|    ent_coef        | 0.000405 |
|    ent_coef_loss   | -3.38    |
|    learning_rate   | 0.0003   |
|    n_updates       | 152505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 19       |
|    time_elapsed    | 8370     |
|    total_timesteps | 164079   |
| train/             |          |
|    actor_loss      | -0.996   |
|    critic_loss     | 0.000498 |
|    ent_coef        | 0.000414 |
|    ent_coef_loss   | 0.378    |
|    learning_rate   | 0.0003   |
|    n_updates       | 154078   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 19       |
|    time_elapsed    | 8417     |
|    total_timesteps | 166079   |
| train/             |          |
|    actor_loss      | -0.99    |
|    critic_loss     | 0.000366 |
|    ent_coef        | 0.000378 |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 0.0003   |
|    n_updates       | 156078   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 344      |
|    fps             | 19       |
|    time_elapsed    | 8468     |
|    total_timesteps | 167311   |
| train/             |          |
|    actor_loss      | -0.915   |
|    critic_loss     | 0.000395 |
|    ent_coef        | 0.000369 |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 0.0003   |
|    n_updates       | 157310   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 348      |
|    fps             | 19       |
|    time_elapsed    | 8527     |
|    total_timesteps | 169311   |
| train/             |          |
|    actor_loss      | -0.92    |
|    critic_loss     | 0.000252 |
|    ent_coef        | 0.00035  |
|    ent_coef_loss   | -0.0483  |
|    learning_rate   | 0.0003   |
|    n_updates       | 159310   |
---------------------------------
Eval num_timesteps=170000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -0.879   |
|    critic_loss     | 0.000423 |
|    ent_coef        | 0.000322 |
|    ent_coef_loss   | 0.499    |
|    learning_rate   | 0.0003   |
|    n_updates       | 159999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 352      |
|    fps             | 19       |
|    time_elapsed    | 8743     |
|    total_timesteps | 171311   |
| train/             |          |
|    actor_loss      | -0.834   |
|    critic_loss     | 0.000291 |
|    ent_coef        | 0.00031  |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 0.0003   |
|    n_updates       | 161310   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    episodes        | 356      |
|    fps             | 19       |
|    time_elapsed    | 8798     |
|    total_timesteps | 173311   |
| train/             |          |
|    actor_loss      | -0.795   |
|    critic_loss     | 0.00109  |
|    ent_coef        | 0.000274 |
|    ent_coef_loss   | -4.96    |
|    learning_rate   | 0.0003   |
|    n_updates       | 163310   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 360      |
|    fps             | 19       |
|    time_elapsed    | 8865     |
|    total_timesteps | 174813   |
| train/             |          |
|    actor_loss      | -0.743   |
|    critic_loss     | 0.000266 |
|    ent_coef        | 0.000272 |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 0.0003   |
|    n_updates       | 164812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 364      |
|    fps             | 19       |
|    time_elapsed    | 8958     |
|    total_timesteps | 176813   |
| train/             |          |
|    actor_loss      | -0.697   |
|    critic_loss     | 0.00312  |
|    ent_coef        | 0.00023  |
|    ent_coef_loss   | -2.72    |
|    learning_rate   | 0.0003   |
|    n_updates       | 166812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 368      |
|    fps             | 19       |
|    time_elapsed    | 9027     |
|    total_timesteps | 178813   |
| train/             |          |
|    actor_loss      | -0.61    |
|    critic_loss     | 0.000147 |
|    ent_coef        | 0.000208 |
|    ent_coef_loss   | 3.98     |
|    learning_rate   | 0.0003   |
|    n_updates       | 168812   |
---------------------------------
Eval num_timesteps=180000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -0.577   |
|    critic_loss     | 9.94e-05 |
|    ent_coef        | 0.000209 |
|    ent_coef_loss   | 1.89     |
|    learning_rate   | 0.0003   |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 372      |
|    fps             | 19       |
|    time_elapsed    | 9259     |
|    total_timesteps | 180813   |
| train/             |          |
|    actor_loss      | -0.544   |
|    critic_loss     | 0.00146  |
|    ent_coef        | 0.000199 |
|    ent_coef_loss   | 0.126    |
|    learning_rate   | 0.0003   |
|    n_updates       | 170812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 376      |
|    fps             | 19       |
|    time_elapsed    | 9351     |
|    total_timesteps | 182813   |
| train/             |          |
|    actor_loss      | -0.526   |
|    critic_loss     | 0.000153 |
|    ent_coef        | 0.000187 |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 0.0003   |
|    n_updates       | 172812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    episodes        | 380      |
|    fps             | 19       |
|    time_elapsed    | 9423     |
|    total_timesteps | 184813   |
| train/             |          |
|    actor_loss      | -0.477   |
|    critic_loss     | 0.000396 |
|    ent_coef        | 0.000196 |
|    ent_coef_loss   | 0.4      |
|    learning_rate   | 0.0003   |
|    n_updates       | 174812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 384      |
|    fps             | 19       |
|    time_elapsed    | 9473     |
|    total_timesteps | 186315   |
| train/             |          |
|    actor_loss      | -0.438   |
|    critic_loss     | 0.000198 |
|    ent_coef        | 0.000163 |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 0.0003   |
|    n_updates       | 176314   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 388      |
|    fps             | 19       |
|    time_elapsed    | 9532     |
|    total_timesteps | 187853   |
| train/             |          |
|    actor_loss      | -0.412   |
|    critic_loss     | 0.000127 |
|    ent_coef        | 0.000168 |
|    ent_coef_loss   | -2.91    |
|    learning_rate   | 0.0003   |
|    n_updates       | 177852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 19       |
|    time_elapsed    | 9605     |
|    total_timesteps | 189853   |
| train/             |          |
|    actor_loss      | -0.393   |
|    critic_loss     | 0.000109 |
|    ent_coef        | 0.000173 |
|    ent_coef_loss   | -5.59    |
|    learning_rate   | 0.0003   |
|    n_updates       | 179852   |
---------------------------------
Eval num_timesteps=190000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -0.386   |
|    critic_loss     | 0.000123 |
|    ent_coef        | 0.000171 |
|    ent_coef_loss   | -0.0318  |
|    learning_rate   | 0.0003   |
|    n_updates       | 179999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 396      |
|    fps             | 19       |
|    time_elapsed    | 9903     |
|    total_timesteps | 191853   |
| train/             |          |
|    actor_loss      | -0.375   |
|    critic_loss     | 0.000279 |
|    ent_coef        | 0.0002   |
|    ent_coef_loss   | -0.32    |
|    learning_rate   | 0.0003   |
|    n_updates       | 181852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 400      |
|    fps             | 19       |
|    time_elapsed    | 9980     |
|    total_timesteps | 193853   |
| train/             |          |
|    actor_loss      | -0.353   |
|    critic_loss     | 0.000146 |
|    ent_coef        | 0.000168 |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 0.0003   |
|    n_updates       | 183852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 404      |
|    fps             | 19       |
|    time_elapsed    | 10092    |
|    total_timesteps | 195853   |
| train/             |          |
|    actor_loss      | -0.326   |
|    critic_loss     | 8.07e-05 |
|    ent_coef        | 0.00018  |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 0.0003   |
|    n_updates       | 185852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 19       |
|    time_elapsed    | 10291    |
|    total_timesteps | 197853   |
| train/             |          |
|    actor_loss      | -0.316   |
|    critic_loss     | 0.000756 |
|    ent_coef        | 0.000175 |
|    ent_coef_loss   | -4.31    |
|    learning_rate   | 0.0003   |
|    n_updates       | 187852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 19       |
|    time_elapsed    | 10372    |
|    total_timesteps | 199853   |
| train/             |          |
|    actor_loss      | -0.301   |
|    critic_loss     | 0.000281 |
|    ent_coef        | 0.000142 |
|    ent_coef_loss   | -3.4     |
|    learning_rate   | 0.0003   |
|    n_updates       | 189852   |
---------------------------------
Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -0.315   |
|    critic_loss     | 0.000822 |
|    ent_coef        | 0.000142 |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.0003   |
|    n_updates       | 189999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 416      |
|    fps             | 19       |
|    time_elapsed    | 10580    |
|    total_timesteps | 201853   |
| train/             |          |
|    actor_loss      | -0.281   |
|    critic_loss     | 0.000247 |
|    ent_coef        | 0.000142 |
|    ent_coef_loss   | -0.715   |
|    learning_rate   | 0.0003   |
|    n_updates       | 191852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 420      |
|    fps             | 19       |
|    time_elapsed    | 10678    |
|    total_timesteps | 203853   |
| train/             |          |
|    actor_loss      | -0.274   |
|    critic_loss     | 0.000346 |
|    ent_coef        | 0.000128 |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 0.0003   |
|    n_updates       | 193852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 424      |
|    fps             | 19       |
|    time_elapsed    | 10769    |
|    total_timesteps | 205853   |
| train/             |          |
|    actor_loss      | -0.272   |
|    critic_loss     | 0.000424 |
|    ent_coef        | 0.00012  |
|    ent_coef_loss   | -2.81    |
|    learning_rate   | 0.0003   |
|    n_updates       | 195852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 428      |
|    fps             | 19       |
|    time_elapsed    | 10816    |
|    total_timesteps | 207853   |
| train/             |          |
|    actor_loss      | -0.234   |
|    critic_loss     | 0.000227 |
|    ent_coef        | 0.000112 |
|    ent_coef_loss   | 0.989    |
|    learning_rate   | 0.0003   |
|    n_updates       | 197852   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 473      |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 19       |
|    time_elapsed    | 10887    |
|    total_timesteps | 209853   |
| train/             |          |
|    actor_loss      | -0.242   |
|    critic_loss     | 8.42e-05 |
|    ent_coef        | 0.00013  |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 0.0003   |
|    n_updates       | 199852   |
---------------------------------
Eval num_timesteps=210000, episode_reward=0.00 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 0        |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -0.246   |
|    critic_loss     | 9.91e-05 |
|    ent_coef        | 0.000137 |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 0.0003   |
|    n_updates       | 199999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    episodes        | 436      |
|    fps             | 18       |
|    time_elapsed    | 11222    |
|    total_timesteps | 211853   |
| train/             |          |
|    actor_loss      | -0.247   |
|    critic_loss     | 0.000326 |
|    ent_coef        | 0.000213 |
|    ent_coef_loss   | 0.683    |
|    learning_rate   | 0.0003   |
|    n_updates       | 201852   |
---------------------------------
